# Lowest common ancestor (LCA)

Presi due nodi di un albero, dire qual'e il primo antenato comune. Quindi il nodo in cui si sono separati i percorsi radice-nodo.

Algoritmo di Harel-Tarjan, calcola `lca(x,y)` in $O(1)$.
Tarjan è quello dell'algoritmo per le scc.

## Pattern matching alternativo bis

Prima, per avere l'intuizione sulla struttura dati, vediamo shift-and (che usa gli array di bit) per cercare $P$ in $T$ (solito pattern matching). Sarà anche l'intuizione per il pattern matching approssimato.

Ipotesi: $|P|$ entra in "una" parola di memoria. In questo caso non intendiamo che una parola siano almeno $\log(|P|)$ bit, ma proprio $|P|$.

Costruiamo una matrice di bit, le righe corrispondono ai *simboli* del pattern, le colonne a quelli del testo. Alla posizione $M(i,j)$ inseriamo $0$ se c'è un mismatch, e $1$ se sono uguali.
C'è un'occorrenza del pattern se c'è una diagonale (messa così: `\`) di tutti $1$. Se abbiamo una diagonale al contrario (così: `/`) compare la sequenza in reverse.
I biologi plottano la matrice in un dot plot (puntino nero se 1 bianco se 0), e cercano visivamente cose diagonalose.

Con l'ipotesi che $|P|$ entra in una parola di memoria, possiamo inserire una colonna della matrice in un vettore di bit. Calcolare quello successivo, fare uno shift di quello vecchio, metterli in and e usare il risultato come vettore vecchio. Se dopo $|P|$ passi ho 1 nell'ultima posizione ho trovato una diagonale.
In questo modo, anche se la matrice è grande, dobbiamo mantenerne solo due colonne alla volta.

Costruiamo una seconda matrice $\mathfrak{M}$ in cui ogni bit alla posizione $\mathfrak{M}(i,j)=1$ sse tra $M(0,i-j)$ e $M(i,j)$ (nell'altra matrice) c'è una diagonale parziale di $1$.
L'ultima riga della matrice ha un 1 per ogni 

Definiamo il vettore di bit $U_x[i]$ dove $x$ è un carattere:
$$
U_x[i]=\begin{cases}
1&P[i]=x\\
0&P[i]\neq x
\end{cases}
$$

Visto che $|\Sigma|\in O(1)$ possiamo calcolare gli $U$ velocemente.

Quindi definiamo $\mathfrak{M}$ tale che $\mathfrak{M}(i,j)=1$ sse:
1. (Se esiste) $\mathfrak{M}(i-1,j-1)=1$
   * Se non esiste perché $i=0$ conta come valida
   * `Shift` della colonna precedente
   * Lo shift deve introdurre un $1$ in cima alla colonna per il caso $i=0$
2. $T[j]=P[i]$
   * `And` della colonna shiftata e il vettore $U_{T[j]}$

Sembra (congettura) che non si possa risolvere questa cosa in tempo meglio che quadratico, cioè senza spazzare tutta la matrice $M$.
Ovviamente con la nostra ipotesi che $|P|$ sia piccolo, l'algoritmo è efficiente.

## Tarjan-Harel

> ***Problema***: LCA
>
> ***Input***:
> * $T$ albero finito con $n=|T|$ nodi e altezza $d=h(T)$
> * $a,y$ nodi in $T$
>
> ***Output***: Lowest common ancestor di $a,y$ in $T$

Risolviamo prima nel caso che $T$ sia un albero binario completo $B$, poi generalizziamo.

Usiamo le operazioni bitwise, ma mostreremo che se anche non le abbiamo a disposizione, otteniamo la stessa efficienza. I nostri vettori di bit sono di dimensione $\log(n)$

### Caso semplice

$B$ è un albero binario completo con:
* $p$ foglie ($n=2p-1$)
* Altezza $d=\log_2(p)$

Assegno ad ogni nodo il numero corrispondente alla loro visita in ordine (scritto in binario).

L'etichetta inizia con il percorso per raggiungere il nodo, poi ci sara un 1 (least significant bit) e poi tutti zeri (il percorso non continua, ma l'etichetta è lunga $d-1$ bit).

Facendo uno xor tra le etichette di due numeri nodi possiamo trovare il primo passaggio diverso, e quindi il punto a cui fermarsi per trovare LCA.

Con le operazioni bitwise prendiamo la prima parte di uno dei due nodi fino al msb dello xor, e in quella posizione mettiamo 1 e tutti 0 dopo.
Si può fare in tempo costante giocando con le operazioni bitwise.

### Idea caso generale

Mappiamo un generico albero $T$ in un albero $B$ di altezza $\log(n)$.

La mappa non sarà iniettiva (più nodi di $T$ andranno nello stesso nodo di $B$). Risolviamo in $B$ e poi mappiamo indietro.

Non è ovvio che si può fare perché non è iniettiva. Ma si può fare. "È una delle cose più incasinati che ho visto".

Prendiamo un albero d'esempio. Partiamo da fare il DFS numbering di $T$ ed osserviamo le sue proprietà:

* 0001
  * 0101
    * 1000
      * 1010
      * 1001
    * 0111
    * 0110
  * 0010
  * 0100
  * 0011

Notiamo che perdiamo le proprietà comode che avevamo negli alberi binari. Il numero non indica il percorso, e la parte in comune delle etichette non trova l'antenato, per questo dobbiamo mapparlo in un albero $B$.

Notiamo che dfs-number in $T(x)$ costituiscono un intervallo senza buchi. E.g. il sottoalbero $T(5)$ (0101 in binario) contiene i numeri da $5$ a $10$

Definizioni:
* $h(k)$ è la posizione (da destra) dell'1 meno significativo
  * Corrisponde all'altezza del nodo
  * Assumiamo di poterlo ottenere in $O(1)$
* $I(v)=h$ tale che $\exist w\in T(v).h=h(w)$ ed è massimo
  * È una *buona definizione*? Nel senso che possono esserci due $w$ diversi con la stessa altezza che è massima.

> ***Dimostrazione***: $I(v)$ è una buona definizione.
>
> Per assurdo $\exist w,u\in T(v).w\neq u\land h(w)=h(u)$ e sono massimi
>
> Allora esiste un terzo $z$ tale che i loro number sono della forma (ordine $uwz$):
> | "...  | 1 | ?... | 1 | ... | 0 |
> | ----  | - | ---- | - | --- | - |
> | "...  | 0 | ?... | 1 | ... | 0 |
> | "...  | 1 | 0... | 0 | ... | 0 |
> 
> Quindi il nodo $z$ ha una altezza maggiore, quindi $u$ e $w$ non erano massimi, che è assurdo.

In generale, $I(v)$ è calcolato bottom-up scegliendo il nodo di altezza massima tra i figli ed il nodo stesso. Implicitamente, lo facciamo in tempo $O(n)$.
$I(v)$ cresce muovendosi lungo la radice. $I(root)$ è il nodo di altezza massima.

Le collezioni di nodi aventi lo stesso $I(v)$ sono dei cammini (run) tali che $I(v)$ è il più basso in $T(V)$ tra i nodi del cammino.

Riprendiamo l'albero di prima:
* 0001 -> 1000
  * 0101 -> 1000
    * 1000 -> 1000
      * 1010 -> 1010
      * 1001 -> 1001
    * 0111 -> 0111
    * 0110 -> 0110
  * 0010 -> 0100
    * 0100 -> 0100
    * 0011 -> 0011

Notiamo che le foglie hanno come $I(v)$ se stesse.
Notiamo che si formano delle run che vanno "verso destra". Ad esempio quelle sui nodi $1$, $5$ ed $8$ (0001, 0101, 1000).

Questo preprocessing (che non è ancora tutto) può essere fatto in $O(n)$. Una visita DFS per etichettare i nodi, e risalire dalle foglie per trovare $I$. Possiamo farlo in una unica visita DFS.

Dato un nodo $v$, prendiamo il nodo più in alto della sua run, lo chiamiamo leader e lo indichiamo con $L(v)$.
Per ogni nodo $v$ identifichiamo la sua run come la collezione $[I(v),...,L(v)]$.

Una run è una collezione massimale di nodi che vengono mappati nello stesso nodo in $B$.

> Per ogni $v\in T$ creo un bit array $A_v$ di dimensione $\log n$.
>
> $A_v[i]=1\iff\exist w.$ antenato di $v$ che $I$ mappa in un nodo di altezza $i$ in  in $B$.\
> Quindi: $A_v[i]=1\iff\exist w\in T.v\in T(w)\land h(I(w))=i$

> ***Lemma***: $x\in T(z)\Rightarrow I(x)\in B(I(z))$

Mappiamo il nodo $x\in T$ in $w\in T(x)$ tale che nell'albero $B$, $w$ è il più in alto tra i candidati. Quindi, tra i nodi in $T(x)$, w ha l'lsb più a sinistra.

> ***Lemma***:
> $x\in T(z)\Rightarrow I(x)\in B(I(z))$
>
> Mantiene la relazione antenato-discendente.
> Non implica che $I$ sia 1:1
>
> ***Dimostrazione***:
> Se $I(x)=I(z)$ banale. Altrimenti sicuramente $h(I(z))>h(I(x))$ per definizione di $I$.

### Algoritmo $O(1)$

> ***Teorema 1***:
> $z=lca(x,y)$ e conosco $h(I(z))$, posso determinare $z$ in $O(1)$

> ***Teorema 2***:
> $h(I(z))=\min\{k|k\geq h(lca_B(I(x),I(y)))\land A_z[k]=A_y[k]=1\}$

Algoritmo per passi (dopo aver annotato $T$ in $O(n)$):
1. Trova il $lca_B(I(x),I(y))=b$
   1. Mappo `x,y`
   2. In $B$ sappiamo trovare `lca`
2. Trova il minimo $j\geq h(b)$ tale che $A_x[j]=A_y[j]=1$, sappiamo che $j=h(I(z))$ (teorema 2)
   1. `and` bitwise delle due etichette
   2. `mask` della parte a destra ($\geq h(b)$)
   3. `lsb`
3. Trova $\overline x$ primo nodo nel cammino da $x$ a $z$ che si trova nel run di $z$ (teorema 1)
4. Trova $\overline y$ come sopra
5. Se $\overline x<\overline y$, allora $z=\overline x$, altrimenti $z=\overline y$

> ***Dimostrazione 1***:
> 1. $j=h(I(z))$ noto.
> 2. $\overline x,\overline y$ definiti come nell'algoritmo
> 3. Se $h(I(x))=j$ allora $x=\overline x$ ($x$ è sul run di $z$)
> 4. Altrimenti, sia $w$ il predecessore di $\overline x$ nel cammino da $x$ a $z$, allora $h(I(w))$ è la posizione del primo $1$ a destra di $j$ in $A_x$, sappiamo che $w$ è il leader del suo run
> 5. $I(w)$ è $I(x)$ a sinistra di $h(I(w))$, quindi abbiamo $I(w)$, quindi abbiamo $L(I(w))=w$
> 6. Con $w$ trovo $\overline x$
> 7. Ripeto per $y$ da `3.`
> 8. Passo `5.` dell'algoritmo principale

### Operazioni bitwise

Per ottenere questa complessità devo poter eseguire in $O(1)$ alcune operazioni bitwise. Ma si può fare con qualsiasi linguaggio.

Gli shift sono facili:
* `SHIFT left i` moltiplico per $2^i$ (ignoro l'overflow)
* `SHIFT right i` divido per $2^i$ (ignoro il resto)

Per lsp e mask abbiamo un trucco:
* `RIGHTMOST1` costruisco una lookup table per tutti i valori, occupa spazio $O(n)$
* `LEFTMOST1` lookup table
* `MASK` lookup table

Per `AND`, `OR` e `XOR` non possiamo usare una tabella semplice perché sarebbe $n\times n$. Però se invece che voler fare una singola operazione su input $\log n$, le implementiamo come un numero costante di operazioni su input $\frac{\log n}{2}$, ci viene una tabella $\sqrt n\times\sqrt n$ che è $O(n)$.