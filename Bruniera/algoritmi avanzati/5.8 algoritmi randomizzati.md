# Algoritmi randomizzati

Libro: Raghavan Motvani "An introduction to randomized algorithms"

Caratteristiche degli algoritmi randomizzati:
* Run diverse, risultati diversi
* Il modello di calcolo ha un generatore di randomness, che ha un costo
* Esistono algoritmi Las Vegas e Monte Carlo

Intuizioni
* RandQS: portare l'ipotesi di uniformità dentro l'algoritmo
* Min-Cut: barattiamo complessità con probabilità di errore
  * Stiamo cercando il taglio di cardinalità minima in un grafo
  * Usiamo un algoritmo montecarlo, riproviamo più volte e man mano la probabilità che la soluzione sia sbagliata, diminuisce arbitrariamente
* RandAuto

## Randomized quicksort

Conosciamo qs classico. Assumendo che tutte le configurazioni siano equiprobabili, il caso medio di qs è $O(n\log n)$ (nel caso pessimo è $=(n^2)$). RandQS avrà come caso medio $O(n\log n)$ senza bisogno di alcuna assunzione.

Succederà spesso che gli algoritmi randomizzati raggiungono la complessità che algoritmi non random raggiungono con qualche assunzione, senza bisogno di fare assunzioni.

## Min-Cut

\\TODO

## RandAuto

> ***Problema generico***:
> 
> Dati $n$ segmenti in  $\R^2$ *non* intersecantesi $S=s_1,...,s_n$, voglio determinare una partizione del piano ottenuta mediante rette, semirette, segmenti, tale che ogni cella contenga un segmento di $S$ o una sua porzione.

In particolare, non cerchiamo qualsiasi suddivisione, ma una Binary Planar Partition (BPP).
Una BPP è ottenuta dividendo prima il piano in due semipiani con una retta, e ogni semipiano può essere a sua volta tagliato in due da una semiretta.
Forma una sorta di struttura ad albero binario.

> ***Definizione***:
>
> Una BPP è un albero binario in cui i nodi sono coppie $(l,r)$ con $r$ regione, e $l$ linea che partizione $r$ in $r_{left}$ e $r_{right}$. E la cui radice ha $r=\R^2$.
>
> Se $r_{left}$ o $r_{right}$ non contengono parte di $S$, la suddivisione è inutile. Cerchiamo le suddivisioni di cardinalità minima in cui ogni sezione foglia contiene solo un segmento o parte di esso.

Applicazione dei BPP: painter's algorithm. Organizziamo gli oggetti in ordine dal più "distante" al più "vicino", per ottimizzare il calcolo dell'occlusione.\
Un'altra applicazione è per decidere quali sezioni di una scena ridisegnare quando viene modificato un'oggetto.

Si chiama RandAuto perché non trova una qualsiasi BPP, ma una auto-partizione, ovvero una BPP in cui le linee coincidono con i segmenti di $S$

Algoritmo:
* Scelgo una permutazione $\pi$ di $s_1,...,s_n$
* While una regione contiene più di un segmento (o parti), taglio la regione con il primo segmento in $\pi$ che interseca $r$
* L'output è l'autopartizione $P_\pi$

> ***Teorema***: La dimensione attesa dell'output di RandAuto è $O(|S|\log|S|)$
>
> ***Corollario***: Esiste una autopartizione di dimensione $O(|S|\log|S|)$

Esercizio: dimostrare che la complessità con valore atteso di RandAuto è  $O(n\log n)$

> ***Dimostrazione***: Dati $u,v\in S$, definiamo $index(u,v)=i$ sse $l(u)$ interseca $i-1$ segmenti prima di intersecare $v$. $index(u,v)=\infty$ se $l(u)$ non interseca $v$.
>
> Indichiamo che $l(u)$ taglia $v$ con $u\dashv v$.
>
> Mi interessa stimare quanti segmenti vengono tagliati dall'introduzione delle $l$ che costituiscono la BPP.
>
> Nota: $u\dashv v$ solo se $u$ occorre prima di $u_1,...,u_{i-1}v$ in $\pi$. Questo avviene con probabilità $\frac{1}{i+1}$
>
> Calcolo il valore atteso di $|P_\pi|$:
> 
> $$E[|P_\pi|]=\\n+E[\sum_u\sum_{v\neq u}C_{u\dashv v}]=\\n+\sum_u\sum_{v\neq u}E[C_{u\dashv v}]=\\n+\sum_u\sum_{v\neq u}P[u\dashv v]=\\n+\sum_u\sum_{v\neq u}\frac{1}{index(u,v)+1}\leq\\n+\sum_u\sum_i\frac{2}{i+1}\leq\\n+n2H_i\in\\O(n\log n)$$

## Macchine di Turing "randomizzate"

Sono macchine di Turing normali, più un certo numero di "random bit" a piacere.

Quindi oltre alle classiche operazioni da macchina di Turing (muovi, scrivi, ...) abbiamo anche l'operazione flip, che lancia una moneta ed ha un esito casuale.

Ricordiamo la classica funzione di transizione delle macchine di Turing $\delta:(S\times\Sigma)\mapsto(S\cup\{halt,yes,no\})\times\Sigma\times\{\leftarrow,\rightarrow,stay\}$. Lo stato va in $halt$ per terminare nelle macchine *funzionali* e va in $yes$ o $no$ per terminare nelle macchine decisionali.

Definizione formale $M=(S,\Sigma,\delta,s)$:
* $S$ stati
* $\Sigma$ alfabeto
* $s$ stato iniziale
* $\delta:(S\times\Sigma)\mapsto(S\cup\{halt,yes,no\})\times\Sigma\times\{\leftarrow,\rightarrow,stay\}$
  * La "segnatura" è classica
  * Quando la definiamo, ad ogni passo posso anche generare *un* random bit che fa scegliere tra due output casuali della funzione di transizione
  * All'atto pratico, si usa una funzione pseudorandom con un "seed" che arriva da sorgenti esterne alla macchina

La macchina segue un ramo di un albero delle computazioni in modo simile ad una macchina non deterministica, ma segue un solo ramo, ed alla fine ha una certa probabilità che l'output sia corretto.
La complessità è l'altezza dell'albero.

Un algoritmo può essere:
* Las Vegas: la soluzione è corretta sempre, ma può non terminare
  * Ci interessa l'altezza media
* Monte Carlo: la soluzione può essere sbagliata ma termina sempre
  * Ci interessa la probabilità che sia corretto il $si$ e che sia corretto il $no$
  * Si dividono ulteriormente tra quelli che sbagliano solo sul $si$ o sul $no$, e quelli che sbagliano su entrambi

Quindi dobbiamo studiare un albero di computazioni, che intuitivamente ricorda il non determinismo.

### Modelli di costo

* Un passo = costo 1
  * È comodo, ma non è realistico, come per le macchine RAM
* Un passo = costo $\log(n)$
  * Più operazioni casuali faccio, più costa
  * Se ho ottenuto $O(f(n))$ col modello costo 1, con questo modello sarà sempre minore o uguale ad $O(f(n)\log(n))$, coincide col costo reale quando faccio $O(n)$ operazioni casuali

Una MdT-computazione di lunghezza polinomiale è sempre simulabile da una RAM-computazione di lunghezza polinomiale, *e viceversa* (random access machine).\
Giustifica l'interesse per le classi $P$, $NP$, etc...

### Classi di complessità

Classi importanti:
* $P$ classe de linguaggi $L$ per cui esiste un algoritmo $A(\circ)$ di complessità polinomiale tale che:
  * $x\in L\iff A(x)=yes$
  * $x\notin L\iff A(x)=no$
  * Non è ammesso che non si fermi
* $NP$ " " " " $A(\circ,\circ)$ di complessità polinomiale tale che
  * $x\in L\iff \exists y\in\Sigma^*.A(x,y)=yes\land|y|$ è polinomiale rispetto ad $|x|$
  * $x\notin L\iff \forall y\in\Sigma^*.A(x,y)=no$ senza altri requisiti

Definizioni importanti:
* Riduzione polinomiale di $L_1$ ad $L_2$: è una funzione $f:\Sigma^*\mapsto\Sigma^*$ tale che:
  * $f$ è polinomiale
  * $\forall x\in\Sigma^*.(x\in L_1\iff f(x)\in L_2)$
  * Se esiste una riduzione si scrive $L_1\preceq L_2$
* Hardness: $L$ è $NP$-hard (o qualsiasi altra classe) se $\forall L'\in NP.L'\preceq L$ 

> La classe $RP$ è la classe dei linguaggi $L$ per cui esiste un algoritmo randomizzato $A(\circ)$ che nel caso pessimo è polinomiale e tale che:
> * $x\in L\Rightarrow P[A(x)=yes]\geq\frac12$
> * $x\notin L\Rightarrow P[A(x)=yes]=0$
>
> Questi $A(\circ)$ algoritmi con one-sided error (se non appartiene non sbaglia).
>
> Sono problemi che ammettono un algoritmo Monte Carlo polinomiale nel caso pessimo e che sbaglia solo in un caso ($x\in L$).
>
> Quel $\frac12$ è arbitrario, possiamo reiterare l'algoritmo quanto vogliamo per abbassare la probabilità. Come min cut. Funziona solo perché è one-sided

> La classe co-$RP$ è la classe dei linguaggi $L$ tali che $\overline L\in RP$, ovvero quelli per cui esiste un algoritmo  tale che:
> * $x\in L\Rightarrow P[A(x)=no]=0$
> * $x\notin L\Rightarrow P[A(x)=no]\geq\frac12$

Ovviamente, se non commetto errori i nessuno dei due casi, è Las Vegas.

> La classe $ZPP$ (zero-probabilistic polynomial time) è la classe dei linguaggi $L$ per cui esiste un algoritmo $A(\circ)$ tale che $A(x)=yes\iff x\in L$ e $A(x)=not\iff x\notin L$, ed il *valore atteso* dell complessità è polinomiale

> La classe $PP$ (probabilistic polynomial) è la classe dei linguaggi $L$ per cui esiste un algoritmo randomizzato $A(\circ)$ che nel caso pessimo è polinomiale e tale che:
> * $x\in L\Rightarrow P[A(x)=yes]>\frac12$
> * $x\notin L\Rightarrow P[A(x)=yes]<\frac12$
>
> Per questi non funziona la tecnica di ripetere più volte per ridurre la probabilità di errore. Restano puramente probabilistici.
> Per questo viene considerata insoddisfacente.

> La classe (più popolare) $BPP$ (bounded probabilistic polynomial) è la classe dei linguaggi $L$ per cui esiste un algoritmo randomizzato $A(\circ)$ che nel caso pessimo è polinomiale e tale che:
> * $x\in L\Rightarrow P[A(x)=yes]\geq\frac34$
> * $x\notin L\Rightarrow P[A(x)=yes]\leq\frac14$
>
> Torna a funzionare la tecnica delle ripetizioni.
>
> La probabilità $\frac34$ vs $\frac14$ è arbitraria

Nascono un sacco di problemi aperti.

## "The law of disorder"

Libro: Gamow (1947) "one, two, three,... infinity". Il libro contiene molti problemi tra cui questo, contiene anche la torre di Hanoi.

> Immaginiamo una piazza con al centro un lampione ed attaccato un ubriaco. Ad un certo punto l'ubriaco decide che è ora di tornare a casa. Da buon ubriaco non si muoverà dritto, ma in modo disordinato.
>
> Dopo un certo tempo, sapendo che fa un passo al secondo, posso dire a che distanza dal lampione sarà?
>
> Esiste un teorema per sapere se prima o poi abbandonerà la piazza?

La risposta è si, il teorema esiste, e la distanza probabile è $\sqrt n$ ($n$ sono i passi/secondi)

Come ce ne convinciamo?

> Supponiamo che l'$i$-esimo passo mi porti $x_i$ metri in direzione $x$ ed $y_i$ metri in direzione $y$. Sia $R$ il raggio dal lampione all'ubriaco, abbiamo che (norma del raggio) $R^2=(x_1+...+x_n)^2+(y_1+...+y_n)^2=x_1^2+x_1x_2+...+y^2$.
> Notiamo che se i movimenti sono davvero casuali, per ogni $x_ix_j$ c'è una probabilita di trovare un valore uguale di segno opposto, gli unici componenti che non possono scomparire sono quelli del tipo $x_i^2$ ed $y_i^2$. Quindi per $n$ abbastanza grandi $R^2\approx n(x^2+y^2)\approx n$ quindi segue che $R\approx\sqrt n$

Se la griglia ha dimensione 2, si ritorna al punto di partenza infinite volte. Se ne ha di più, no.

## 2SAT

Spiegazione di SAT omessa. In questo caso è con formule proposizionali qualunque.

Se una formula si può scrivere come una disgiunzione di congiunzioni di letterali (disjunctive normal form $\bigvee\limits_{i=1}^n\bigwedge\limits_{j=1}^ml_{ij}$) il problema è facile.

In forma CNF invece è difficile $\bigwedge\limits_{i=1}^n\bigvee\limits_{j=1}^ml_{ij}$

Se provo a ridurre una formula da cnf a dnf diventa molto più grande, esponenzialmente.

Risultato interessante: è possibile, dato $\Phi\in SAT$ produrre $\Phi'$ in cnf che ha dimensione polinomiale in $|\Phi|$. Quindi CNF-SAT è difficile quanto SAT.

Altro risultato interessante: 3-CNF-SAT è difficile quanto SAT $\bigwedge\limits_{i=1}^nl_{i1}\lor l_{i2}\lor l_{i3}$

2-CNF è polinomiale, come lo risolviamo? Ricordiamo che $(P\lor Q)\land(\lnot Q\lor R)\iff(P\lor R)$. Se cominciamo a dedurre tutte le clausole con questa tecnica possiamo trovarci solo in poche situazioni: o con la clausola vuota (insoddisfacibile) o con una clausola con una sola soluzione.
Questo metodo ha costo quadratico. Si chiama "risoluzione" ed è stata sviluppata da Davis e Putnam.

Esiste anche un algoritmo lineare per 2-CNF che usa i grafi, ma risolve sempre in tempo lineare anche un problema più difficile: Quantified Boolean 2-CNF (QB-2-CNF).

Sia $\Phi(P_1,...,P_n)$ una formula proposizionale, $P_i$ hanno dominio $\{true,false\}$. Consideriamo la formula $Q_1P_1.Q_2P_2.~...~Q_nP_n.\Phi(P1,...,P_n)$ dove $Q_i$ è un quantificatore $\exist$ o $\forall$. QBF cerca di verificare che questa formula sia vera. QB-2-CNF in cui la formula è una congiunzione di clausole, e 2-CNF è un caso particolare in cui $Q_1=...=Q_n=\exist$. La difficoltà aumenta con le alternanze di quantificatori diversi.
QBF è PSPACE-completo.

La soluzione lineare è:
1. Consideriamo che $(u\lor v)\equiv\overline u\rightarrow v\equiv\overline v\rightarrow u$
2. Costruiamo un grafo in cui gli archi mimano le clausole (come le implicazioni del punto 1)
3. Studiamo le componenti fortemente connesse
4. Si costruiscono delle condizioni che devono essere rispettate all'interno delle componenti
5. Si verificano queste condizioni

Ciascuno di questi passaggi è lineare, ma è difficile da implementare ed ha bisogno di strutture dati complicate e un costo di spazio lineare.

### 2SAT randomizzato

Osservazione: Dato un assegnamento, se la formula è soddisfacibile, ma non da questo assegnamento, se prendiamo una delle clausole non soddisfatte questa contiene un errore, uno dei due letterali dovrebbe essere reso vero, però non sappiamo quale.

Algoritmo:
1. Scegliamo un assegnamento
2. Se sono soddisfatte tutte le clausole ho finito
3. Altrimenti scelgo casualmente una clausola non soddisfatta
4. Scelgo casualmente uno dei letterali della clausola e lo rendo vero
5. Torno a 2

Due esercizi sui random walk su un grafo completo $K_n$:
1. Valore atteso del numero di passi che devo eseguire su $K_n$ per andare da $u$ a $v$ (hitting time)
   1. La probabilità di raggiungerlo con $i$ passi è $(1-\frac1{n-1})^{i-1}\frac1{n-1}$
   2. Il valore atteso è la soluzione di $\sum\limits_{i=1}^\omega t(1-P)^{t-1}P$ con $P=\frac1{n-1}$
   3. Il valore atteso sono $n-1$ passi
2. Valore atteso del numero di passi per visitare tutto $K_n$ (cover time)
   1. Indico con $\tau_i$ la variabile casuale del numero di passi necessario ad esplorare $i$ nodi
   2. $\tau_0=0$ $\tau_1=1<\tau_2<...<\tau_n$.
   3. Mi interessa $\tau_{i+1}-\tau_{i}$, il numero di passi tra la visita dell'iesimo e l'(i+1)esimo nodo. Vedi esercizio 1, evento favorevole con probabilità $\frac{n-i}{n-1}$ ($p_i$)
   4. Per la linearità del valore atteso $E[\tau_n]=\sum\limits_{i=0}^{n-1}E[\tau_{i+1}-\tau_i]$
   5. Viene $E[\tau_n]=\sum\limits_{i=0}^\omega\frac{n-1}{n-i}=(n-1)\sum\limits_{i=0}^\omega\frac{1}{n-i}\approx n H_n$ dove $H_n$ è l'hitting time

Osservazione: come scelgo quando fermarmi? Usando la disuguaglianza di Markov: $P[X\geq a]\leq\frac{E[X]}a$. Se $X$ è il numero di passi necessari a completare la visita, la probabilità che $X$ sia maggiore od uguale ad $a$ è la probabilità di "sbagliare strada".
Se faccio $an^2$ passi, la probabilità che abbia sbagliato e non abbia coperto tutto è $\frac1a$.





## Catene di Markov




$f_{ij}=\sum_{t>0} r_{ij}^{(t)}$ è la probabilità di raggiungere $j$ da $i$. Ma mediamente in quanti passi? $h_{ij}=\sum_{t>0}tr_{ij}^{(t)}$. Quando $f_{ij}<1$ significa che ho una probabilità di entrare in una regione del grafo da cui non ho nessuna possibilità di uscire e raggiungere $j$, se succede abbiamo $h_{ij}=\infty$, è una implicazione non un sse.

Se abbiamo $f_{ii}<1$ si dice che $i$è *transiente*. Se invece $f_{ii}=1$ si dice *persistente*.
Se è persistente ma con $h_{ii}=\infty$ si dice *persistente nullo*.

In un grafo, la relazione di mutua raggiungibilità definisce delle classi di equivalenza in cui tutti i nodi hanno le stesse proprietà (tutti transienti, tutti persistenti nulli, etc). Lavorando con classi finite gli stati possono essere solo persistenti non-nulli o transienti.

Ci interessano le componenti fortemente connesse dei grafi.

Data una catena (grafo orientato con extra) ragiono sulle scc del grafo. Il grafo delle scc è un DAG. Una SCC è finale se è un pozzo del dag (priva di archi uscenti). Una catena è irriducibile sse ha una sola scc (finale).

State probability vector: $\vec q^{(t)}=(q_1^{(t)},...,q_n^{(t)})$ tale che ogni $q_i^{(t)}$ rappresenta la probabilità di trovarci nello stato $q_i$. Per noi, poter dire qualcosa sulla catena significa conoscere questo vettore.

$\vec q^{(t+1)}=\vec q^{t}P$ dove $P$ è la matrice delle probabilità. Una distribuzione $\vec\pi$ sugli stati della catena $D$ è *stazionaria* quando è un punto fisso. $\vec\pi=\vec\pi P$. I biologi lo chiamano steady state behaviour.

Periodicità. È una rottura di scatole. Non aggiunge e non toglie informazioni. Il libro dice di non preoccuparsene troppo perché si risolverà.

> ***Definizione*** periodicità: La periodicità di uno stato $I$ è definita come il massimo $T\in\N$ tale cje $\exist\vec q^{(0)}.\exist a\in\N.$ tali che ogni volta che $q_i^{(0)}>0$ si ha $t\in\{a+Tk:k>0\}$
>
> Diciamo che uno stato è periodico sse ha periodicità $T>1$. Ci piacciono i nodi di periodicità 1.
>
> Se ogni stato della catena è aperiodico allora la catena si dice aperiodica.

> ***Definizione*** ergodico: Uno stato è ergodico sse è aperiodico, non nullo e persistente. Una Catena è ergodica se ogni stato è ergodico.

> ***Teorema*** fondamentale sulle MC:
>
> Ogni catena irriducibile finita e aperiodica ha le seguenti proprietà:
> * È ergodica
> * Esiste unica una distribuzione stazionaria $\pi$ tale che $\forall i\in\{1,...,n\}.\pi_i>0$
> * $\forall i\in\{1,...,n\}.f_{ii}=1\land h_{ii}=\frac1\pi_i$
> Se $N(i,t)$ numero medio di volte per cui la catena visita $i$ in $t$ passi, abbiamo $\lim_{i\rightarrow\infty}\frac{N(i,t)}{t}=\pi_i$

## Random walks

Vogliamo sapere il tempo atteso della visita di un grafo.

Dato $G(V,E)$ connesso non orientato e non bipartito. Definiamo $M_G$ la catena di markov associata a $G$in cui gli stati sono i nodi di $G$, e $\forall u,v\in V.P_{i,j}=\begin{cases}\frac1{d_i}&(u,v)\in E\\0&(u,v)\notin E\end{cases}$

È sicuramente irriducibile.

SE $T$ è la periodicità di $v$ allora $T$ è il MCD della lunghezza di ogni cammino da $v$ a $v$. Ma $u$...
$\implies\exist!\vec\pi$

### Mischiare le carte

#### Top in random

Prendiamo una carta da sopra e la mettiamo sotto in una posizione random. Quante di queste operazioni devo fare per garantire che il mazzo abbia tutte le carte in posizione random?

La chiave è la carta sotto. All'inizio ho $p=\frac1{52}$ di metterci qualcosa sotto. Man mano diventa sempre più alta. Le carte sotto di essa sono sicuramente in una posizione random.

$O(52\log52)$ genericamente $O(k\log k)$.

> ***Lemma***: Sia $M_G$ associata a $G$ connesso orientato non bipartito. Allora $\forall v.\pi_v=\frac{d(v)}{2n}$
>
> ***Corollario***: $\forall v\in V.h_{vv}=\frac1{\pi_v}=\frac{2m}{d(v)}$

