# Controllo della congestione e allocazione delle risorse

Bisogna implementare una forma di controllo della congestione. Ovvero, fare in modo che tutti i dispositivi che i nostri messaggii attraversano, riescano a gestirli tutti.
In pratica, il limite è la memoria di questi dispositivi, dal momento che finché i messaggi non vengono gestiti, devono stare in una coda di messaggi in attesa.
Quando la memoria finisce vengono buttatu via dei pacchetti.

Si noti che la capacità complessiva di tutto il percorso, è limitata dalla capacità del dispositivo peggiore.

Quindi le prestazioni del collegamento sono date dal link peggiore del percorso, e dal dispositivo ricevente.

Controllo ed allocazione sono due facce della stessa cosa. Due metodi per permettere alla rete di gestire la congestione:
* Controllare quando si verifica e comportarsi di conseguenza
* Richiedere le risorse prima di usarle, per essere sicuri che siano disponibili

Generalmente, allocare le risorse non è possibile, perché la rete Internet è troppo eterogenea.
Si poteva fare con le reti telefoniche, ci sa esattamente quante banda richiede una chiamata telefonica, quindi si cerca un percorso che possa fornire quella, e non gliene viene allocata altra.

L'approccio congestion control prevede di di lasciare che le applicazionie mandino tutti i pacchetti che possono, e poi prendere contromisure quando si verifica.
È molto semplice, ma vengono scartati molti pacchetti.

Un terzo approccio è la congestion avoidance, una via di mezzo. Lascio che le applicazioni mandino i pacchetti che vogliono, quando noto che la congestione potrebbe avvenire, rallento per evitarlo, prima che succeda.
È la strategia migliore, ma anche la più difficile.

Tutte e tre le strategie sono compatibili tra di loro. Possiamo avere alcuni router che implementano una, ed altri che implementano l'altra.

Dove possono essere implementati?
* Dispositivi di rete
  * A livello 2 negli switch
  * A livello 3 nei router
* Negli host finali
  * Si rallenta l'invio dei dati per evitare la congestione
  * Generalmente a livello 4

Se ho due dispositivi connessi con un link a 100Mbps ad un router connesso alla rete globale con un link a 1.5Mbps

Gli host non sanno con che rete è connesso il router, ma potrebbero inviare quasi 200Mb di dati al router ogni secondo, però quest'ultimo non riuscirà mai a gestirli.

## Connectionless Flow

Anche se non c'è stato un handshake, perché usiamo UDP o perché siamo a livello 3, comunque abbiamo un flusso di pacchetti tra le due destinazioni.
Controllando anche le porte, posso notare un flusso anche tra le applicazioni, non solo tra gli host.

Il flusso è unidirezionale, ma possono esserci due flussi.

Il router misura delle caratteristiche di questi flussi, come la dimensione dei pacchetti, il bitrate, ed il rate di invio dei pacchetti.
Queste informazioni sono usare per allocare risorse ai pacchetti dello stesso flusso. Questo stato si chiama soft state.

La differenza tra soft e hard state è che in hard state, le risorse sono decise deterministicamente colllaborando con gli altri router. Mentre in soft state ogni router decide per se, senza allocazioni esplicite.

Il router deve funzionare anche senza flusso, infatti i router economici non hanno questi meccanismi. Ma il flusso viene usato per funzionare meglio.

## Allocazione delle risorse

Router-host centric
* Router centric design
  * Ogni router si prende la responsabilità di decidere quando scartare i pacchetti e di informare gli host che generano troppi pacchetti
* Host centric design
  * Gli host devono accorgersi che stanno generando troppi pacchetti

I due apporocci sono compatibili, ed è bene implementarli entrambi quando possibile.

Reservation-feedback based
* Reservation based approach
  * Una entità chiede alla rete di allocare risorse per un flusso
  * Tutti i router che ricevono questa allocazione si preparano a ricevere il flusso
  * Se un router non è in grado di soddisfare la richiesta, rifiuta l'allocazione
    * Si può ritentare chiedendo meno risorse
  * Deve essere l'applicazione a sapere di cosa ha bisogno
  * Se un router non implementa il protocollo... non lo segue
  * Si implementa solo su piccoli AS
* Feedback based approach
  * I router non collaborano se chiedo risorse, o le scartano o le accettano e non rispettano
  * Si sfrutta un feedback implicito od esplicito
    * Esplicito: il router mi da un feedback se perde pacchetti, con ICMP
    * Implicito: osservo altri effetti, ad esempio gli ACK od altre informazioni dall'interlocutore
  * Si rallenta od accelera di conseguenza

### Efficacia delle allocazioni

Criteri di valutazione:
* L'efficacia della rete sono misurate come throughput e delay
  * In sistemi realtime è più importante la varianza del delay
  * Vogliamo il Throughput più alto possibile, col delay minimo, non possiamo avere entrambi
* Se aumentiamo il throughput aumentano le code nei router e quindi i ritardi
* Se diminuisco il throughput le code restano piccole ed il delay diminuisce, ma ho dovuto diminuire la banda
* Non bastano per valutare l'efficacia

Una analisi completa richiede di studiare teoria delle code (probabilità e statistica 2).

Esempio:
Consideriamo un flusso random di richieste ad un esrver senza memoria. Finché non gestisce i pacchetti si incodano (coda M/M/1)

I parametri sono:
* $\lambda$ rate di arrivo dei messaggi medio (richieste/secondi)
* $S$ tempo medio di servizio (secondi/richieste)

Risultati:
* Tempo medio di residenza nel server $R=S/(1-\lambda S)$
* Utilizzo del server $\rho=\lambda S$
* Lunghezza media della coda $Q=\lambda R$
* Tempo di attesa medio del cliente prima di essre servito $W=R-S=S\rho/(1-\rho)$

Per valutare l'efficacia complessiva utilizziamo la misura Power=Throughput/Delay.
Nel caso delle code M/M/1 di prima è $Power=\lambda/s.\lambda^2$.
È una parabola covnessa.

In situazioni reali, la curva di potenza assomiglia a quella dell'efficienza dei sistemi operativi all'aumentare dei processi (non a caso sono entrembi gestiti da code).
Ad un certo rate si ha un picco di efficienza, miriamo ad avere quel rate di pacchetti.

### Allocazione equa delle risorse

Non basta l'efficacia per valutare lo schema di allocazione delle risorse, bisogna valutare anche l'equità. Ma cosa significa equità?

In un sistema a prenotazione, lo schema fornisce un modo esplicito per creare una inequità controllata, perché non tutti i servizi hanno le stesse esigenze, ad una mail bastano poche risorse.

Criteri di valutazione:
* In assenza di informazioni esplicite sui flussi che condividono un link, vorremmo che tutti avessro la stesa capacità di banda.
* Questo assume che condivisione equa e condivisione uguale, siano la stessa cosa
* Non è così
* Valutiamo anche la lunghezza dei percorsi
  * Supponiamo 4 router e 4 flussi
    * I router sono connessi in sequenza
    * un flusso attraversa tutti
    * Gli altri flussi entranociascuno da un router diverso ed escono da quello a destra
  * Il flusso che attraversa tutti i router ha più risorse degli altri

Per misurare l'equità di un sistema di a congestion control usiamo l'indice di Jain:
$$f(x_1,x_2,...,x_n)=\frac{(\sum\limits^n_{i=1}x_i)^2}{n\sum\limits^n_{i=1}x_i^2}$$
La serie $x$ sono i throughput dei flussi misurati in bps. Assomiglia ad una varianza scalata, misura quanto sono discrepanti i flussi tra di loro.

Più si avvicina ad 1, più è equo. Quando un solo flusso prende tutte le risorse si ha indice 1/n.

Si può applicare anche ad altri tipi di risorse, come memoria o potenza.

Nell'esempio di prima otteniamo 0.867. Si considera buono quando siamo sopra 0.9, questo è un po' più basso.

## Tecnice di accodamento e drop

### FIFO Tail Drop

First In First Out

È la tecnica più ovvia e più semplice. Invio i pacchetti nell'ordine in cui mi sono arrivati. Se è piena la coda droppo l'ultimo arrivato.

Viene mantenuto l'ordinamento e vengono avvantaggiati i pacchetti vecchi.

### Priority tail drop

Ad ogni pacchetto viene associata una priorità (non è specificato come, si può usare un campo od altre politiche).
Il router implementa una coda FIFO pe ogni livello di priorità. Svuota in ordine la coda di priorità più alta e poi le altre.

Possono essere usati i TOS e DSCP dei protocolli IP per decidere la priorità.

Viene comunque fatto tail drop per i pacchetti dello stesso livello di priorità.

### Accodamento equo

Nessuna di queste politiche considera i flussi di pacchetti.

La tecnica FQ (Fair Queueing) mantiene una coda per ogni flusso corrente, poi svuota le code inuna sorta di round robin.

Bilancia un po' le risorse, ma abbiamo visto che non basta questo per avere veramente condivisione equa. Anche percé non tutti i pacchetti sono grandi uguali.

Se un flusso ha solo pacchetti da 64k e gli altri 20, un round robin normale darebbe molta più banda a quel flusso.
Il FQ usa un algoritmo di RR che cerca di bilanciare meglio la banda approssimando il tempo di trasferimento dei pacchetti.

Algoritmo:
* Let
  * $P_i$ la lunghezza dell'iesimo pacchetto del flusso (in tempo di trasferimento)
  * $S_i$ il tempo in cui il router inizia a trasmettere l'iesimo pacchetto
  * $F_i$ il tempo in cui il router finisce di trasmettere l'iesimo pacchetto
  * $S_i=F_{i-1}$
  * $F_i=S_i+P_i$
* Per ogni flusso di pacchetti calcoliamo il timestamp $F_i$ relativo al flusso
* Quando invio scelgo il pacchetto con il timestamp più basso

Se abbiamo un flusso di pacchetti da 1000B e tre flussi da 100B, l'algoritmo sceglierà di inviare prima 10 pacchetti da ciascuno dei flussi piccoli, ogni volta che invia un pacchetto del flusso grande.
Quando i pacchetti hanno lo stesso timestamp fa un round robin, l'ordine non influenza la fairness.

La fairness è 1, divide equamente la banda del router.

Si usa un meccanismo di aging per impedire che nuovi flussi di pochi pacchetti mandino in starvation i flussi grandi già presenti.

## Congestion control e TCP

Il controllo della congestione è stato introdotto nei tardi anni '80 da Van Jacobson. Circa 8 anni dopo il TCP.

Prima il TCP inviava quando voleva, e la rete era sovraccarica di congestione.
Si verificava congestion collapse, un processo in cui gli host inviano pacchetti attraverso internet quanto la finestra permette, la rete scarta tutti i pacchetti, quindi scadono i timeout degli host, che reinviano i pacchetti o droppano la connessione.

Per controllare questo fenomeno bisogna considerare, oltre alla finestra dell'host, una "finestra di congestione" data dalla capacità della rete Internet.

Esistono molti algoritmi per questo, su Wikipedia se ne trovano più di 30, alcuni sono ottimizzati per alcuni carichi di lavoro. Sui sistemi operativi ne troviamo implementati qualcuno, solo di quelli general purpose.
Sulle macchine linux è un modulo del kernel, quindi si possono cambiare se serve.

I più famosi sono:
* CUBIC
  * Default su linux dalla versione 2.6.19 (2006)
* Compound TCP
  * Default su windows da Vista e da Serve 2008
* PRR
  * Disponibile su linux dalla versione 3.2 (2012)
* BBR
  * Disponibile su linux per il controllo della congestione vasato su modelli dalla versione 4.9 (2016)

Vedremo alcune tecniche utilizzate negli algoritmi classici (1990).

### Finestre

* Finestra di congestione
  * È una finestra "virtuale" data dalla capacità della rete
  * Corrisponde alla quantità di byte che posso inviare senza che i pacchetti vengano scartati
  * Varia nel tempo molto rapidamente, perché dipende dal carico di tutti i router attraversati

* Finestra e ffettiva MaxWindow
  * È il minimo tra la AdvertisedWindow e la CongestionWindow
* Il difficile è calcolare questa
* I router non ce la dicono e non sappiamo quanti router sono
* Non possiamo fidarci troppo di quello che ci dicono i router

La finestra di congestione è stimata partendo dalla congestione che il TCP "percepisce".
In genere si aumenta la finestra man mano e la si rimpicciolisce quando si percepisce congestione. AIMD (additive increase/multiplicative decrease)

### AIMD

additive increase/multiplicative decrease

Formula:
* Let
  * w(t) finestra di congestione al tempo t
  * a > 0 parametro additivo (di solito 1)
  * 0 < b < 1 parametro moltiplicativo (di solito 0.5)
* Si aumenta la finestra di congestione del parametro a ad ogni t
  * w(t) = a + w(t-1)
* Quando si percepisce congestione si moltiplica per b
  * w(t) = b * w(t-1)
  * Diminuisce perché b < 1

Quando si decresce? Quando si perde un pacchetto, questo se assumiamo che la principale causa della perdita di pacchetti sia la congestione.
Non è vero ora, perché i router hanno molta memoria, ed è molto più facile perdere un pacchetto a causa del wireless che per la congestione.

Si considera perso il pacchetto se non arriva un ACK entro un timeout.

Per dimensione si intende il numero di MSS nel segmento. Per comodità possiamo vederlo come numero di pacchetti.

Algoritmo:
1. W(0) = 1
2. Parto con t = 0
3. Invio w(t) pacchetti
4. Attendo w(t) ack
5. Se arrivano tutti gli ACK
   1. w(t+1) += a
6. Altrimenti
   1. w(t+1) *= b
7. t++
8. Salta a 3

Esempio con valori di a e b default e finestra di congestione 3 (non nota):
* Invio 1
* Ricevo 1
* Invio 2
* Riveco 2
* Invio 3
* Ricevo 3
* Invio 4
* Ricevo 3
* Invio 2
* Ricevo 2
* Invio 3
* Ricevo 3
* Invio 4
* Ricevo 3
* Invio 2
* ...

Nel tempo forma un pattern sawtooth, in cui incrementa linearmente, poi scatta in basso e ricomincia a incrementare.

### Slow start

Il modello AIMD ha un problema fondamentale: ci mette molto a raggiungere la finestra.

Vogliamo un meccanismo per arrivare a regime più velocemente, e per capirci meglio lo chiamiamo partenza lenta.

Inizia con un incremento esponenziale. Si chiama lenta perché l'altra soluzione era iniziare con un AdvertisedWindow e diminuire man mano.

Ad ogni round la finestra raddoppia (se tutto va bene).
Viene usata all'inizio della connessione per trovare velocemente la finestra.
Viene anche usata dopo che viene perso un pacchetto, ma con più informazioni su quando smettere di incrementare.

Quando incontriamo la congestione viene impostata una ssthreshold, (metà di quando abbiamo incontrato la congestione), quando viene raggiunga procede con l'additivo.

TCP Tahoe

### Fast retransmit

I timeout del TCP sono troppo lunghi, causano dei periodi di non-trasmissione di anche secondi, in cui la connessione non viene utilizzata mentre attendo che arrivino degli ACK che forse non arriveranno mai.

Questo meccanismo euristico prevede di provare a reinviare il messaggio che forse è stato perso, anche se non è sicuro. Riempie la rete di pacchetti inutili se non si fa attenzione, ma funziona.

Come capiamo che pacchetto può essere stato perso? Ogni volta che TCP riceve un segmento manda un ACK, ma se la finestra ha un buco (pacchetti fuori ordine) manda un ACK di un pacchetto precedente a quello arrivato.
Se quel pacchetto precedente è stato perso, continuo a mandare lo stesso ACK, ogni volta che arriva un nuovo pacchetto finché non arriva quello vecchio e posso mandare l'ACK di tutti i pacchetti ricevuti.

Quindi, se ricevo lo stesso ACK tre volte (Reno) di sequito, non è detto che il pacchetto sia perso il pacchetto appena successivo (magari è solo in ritardo), ma se è perso succede sicuramente. Quindi, invece che aspettare il timeout, dichiaro il pacchetto perso e riparto con la slow start (Tahoe).

L'idea degli ACK ripetuti è di Tahoe, l'implementazione utilizzata (Tahoe and Reno) prevede di aspettare di rivedere l'ACK 3 volte.

TCP Tahoe and Reno 1988

### Fast Recovery

Forse se ricevo un ACK duplicato la rete non è messa male, può essere stato un caso, magari un errore momentaneo. Posso ancora recuperare la connessione.

Quando arriva un ACK triplo si imposta la ssthreshold a metà della finestra attuale. Ma non riparto da 0, riparto dalla ssthreshold direttamente in modalità additiva. In pratica Taglia la parte slow start.
Se il timeout scade e l'ACK continua a non arrivare, allora dichiaro perso il pacchetto e ricomincio con la slow start.

TCP Reno 

### ALtro

Ci sono molti altri algoritmi, decine. Alcuni non sono mai implementati in quasi nessun sistema. Questi sono solo alcuni dei meccanismi di base.

## Congestion avoidance

### Random Early Detection (RED)

Inventato da Jacobson negli anni '90. È un meccanismo implementato sui router, quindi lavora al livello 3.

Quando il router nota che le sue code diventano troppo lunghe, scarta un pacchetto a caso e manda un ICMP al mittente.
Se è implementato fast recovery, non ripartirà da 0, perché probabilmente riceverà gli ack duplicati, in ogni caso, ha informazioni sulla congestione.

Il router non va in congestione perché ha droppato i pacchetti prima di riempire la coda.

Algoritmo:
* Viene calcolata costantemente la lunghezza media della coda con una media pesata di media precedente e lunghezza istantanea.
  * $AvgLen=(1-w)\times AvgLen+w\times SampleLen$
* Vengono mantenuti due valori MinThresh e MaxThresh
  * Se $AvgLen\leq MinThresh$
    * Incoda
  * Se $MinThresh<AvgLen<MaxThresh$
    * Calcola la probabilità di drop
      * $P(drop)=MaxPtimes(AvgLen-MinThresh)/(MaxThresh-MinThresh)$
      * Scala la probabilita massima (impostata in precedenza) in base a dove si  trova AvgLen rispetto a Max e Min
    * Fa un test casuale sulla probabilità per decidere se incodare
  * Se $MaxThresh\leq AvgLen$
    * Droppa sempre

### Source-based Congestion Avoidance

Cercare di capire delle infomrazioni sulla rete che possono darci un idea che le code dei ruouter si stanno accumulando.
A contrario del RED, questo viene fatto sull'host mittente, non sul router.

Ad esempio, se le code si riempiono, aumente il RTT: la maggior parte del tempo i pacchetti sono in coda. Se noto un sostanziale aumento del RTT, diminuisco l'output di pacchetti.

Algoritmo sul RTT (non usato):
* La finestra aumenta a modo suo, ma ogni due RTT controllo l'RTT attuale per vedere se è maggiore della media di minimo e massimo visti finora
* Se lo è diminuisci la finestra di un ottavo

Algoritmo sul RTT (usato):
* Ogni due RTT si aggiunsta la finestra
  * Calcolo $(CurWin-OldWin)\times(CurRTT-OldRTT)$
    * Nota che se il primo fattore diminuisce, la trasmissione peggiora
    * Nota che se il secondo fattore aumenta, la trasmissione peggiora
  * Se positivo una è migliorata e l'altra peggiorata (sospetto)
    * Diminuisco la finestra di un ottavo
  * Se negativo o 0 la rete è stabile o più veloce
    * Aumento la finestra di un MSP
* La finestra oscilla attorno alla sua dimensione ottimale
* Si può evitare di controllare la perdita di pacchetti per riconoscere la congestione
  * Molto carino
  * Si usano sue varianti in alcuni algoritmi reali (Vegas, BBR, ...)