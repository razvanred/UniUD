# Livello di trasporto

## Limitazioni dei protocolli di rete

* I protocolli di rete implementano un servizio host-to-host best-effort
  * Non garantisce che il servizio funzioni, fa il possibile per provare a  onsegnare il pacchetto
  * Permette solo di mettere in comunicazione due host, non due programmi
* Tipiche limitazioni di cui si occupa il livello di trasporto:
  * Pacchetti scartati
  * Pacchetti fuori ordine
  * Pacchetti duplicati
  * Limiti alla dimensione dei singoli pacchetti
  * Ritardi arbitrari nell'invio
* In generale ai programmatori i servisi offerti da IP non bastano

Prima ogni programmatore si costruiva un sistema per risolvere le limitazioni, eventualmente è stato sviluppato un protocollo standard per risolverli una volta per tutte.

## Protocolli end-to-end

Proprietà comuni che ci si aspetta di avere fornite:
* Garantisce la consegna del messaggio
  * Quando mandi un messaggio IP non sai mai se arriva
* Consegna i messaggi nello stesso ordine in cui sono inviati
  * Se i messaggi IP prendono strade diverse possono arrivare in disordine
* Supporta messaggi di qualsiasi dimensione
* Sincronizza mittente e destinatario
* Permette al ricevente di applicare controllo di flusso al mittente
  * Rallentare il mittente se va troppo veloce
* Supportare multiple comunicazioni sullo stesso host
  * Il livello 3 supporta solo comunicazioni verso l'host, non verso le applicazioni

L'obbiattivo dei protocolli di trasporto è creare protocolli che utilizzando il livello 3 con tutte le sue problematiche, forniscano i servizi di alto livello richiesti dai programmatori.

Alcuni servizi particolari richiedono collaborazione tra i livelli di rete e di trasporto. Ad esempio: sicurezza, controllo della congestione, QoS, etc...

## Porte per il modello client server

A livello 4 vengono connessi processi, non host, sono loro i nostri peer. Ad esempio, mette in comunicazione il browser con il server web, e l'applicazione teams con il server microsoft.

Come indirizziamo il singolo processo all'interno della macchina? Un modo sarebbe con i PID, ma i PID non sono omogenei tra i sistemi operativi, quindi non vanno bene.
Usiamo i numeri di porta. Sono numeri a 16bit (0-65535). Vengono richiesti al sistema operativo ed assegnati ad una solo processo.
Le porte sono interne al dispositivo, quindi il processo nella rete viene identificato dalla coppia IP:porta


* Per iniziare la comunicazione, il cliente deve conoscere la porta del server
  * Il server impara la porta del client, quando viene contattato
* Spesso si usano delle porte well-known, così il client sà già che porta usare
  * 80 per il web, 25 per email, ...
* Il client usa porte ephemeral, o dinamiche
  * Sono scelte a caso per ogni comunicazione
  * Non è necessario che sia nota in anticipo

### Range di porte IANA

* Well known ports
  * Usate da server ufficiali, si possono associare solo a processi amministratori
    * Se contatto un server fidato su una porta, sono sicuro che chi ha lanciato il processo era stato lanciato da un admin, quindi perché sia "farlocco" deve essere stato compromesso l'admin
  * 0-1023
* Registered ports
  * Possono essere standard, ma non richiedono i permessi di amministratore
  * 1024-49151
* Dynamic/ephimeral posts
  * Libere per qualsiasi servizio. Sono quelle che vengono assegnate automaticamente dal sistema operativo ai processi client
  * 49152
* Troviamo l'elenco dei servizi in /etc/services, standard RFC 1700

## Due tipi di comunicazione

* Connection oriented
  * Significa che bisogna stabilire una connessione prima di scambiare dati
  * Permette di avere un controllo molto più preciso sulla comunicazione, più affidabile
  * Esiste una variante non affidabile, ma comunque orientata, ma non la usa nessuno
  * Nello stack TCP/IP è implementata da TCP (e SCTP)
  * In certi casi è poco efficace, perché è costoso
* Connectionless
  * Ogni datagram è inviato senza aprire esplicitamente una connessione
  * Molto veloce
  * Non è affidabile, non abbiamo mai la certezza che il messaggio arrivi, e non abbiamo controllo sulla comunicazione
  * Nello stack TCP/IP è implementata da UDP

Entrambi questi protocolli si trovano al livello di trasporto, sono due alternative.

Esistono altri tipi di comunicazione, ma in genere non vengono utilizzati o nemmeno implementati:
* Reliable connectionless
  * Teoricamente possibile, mai implementato
  * Si può simulare attraverso TCP, o aggiungendo una conferma ad UDP
  * Nello stack TCP/IP è implementato da RUDP o RDP
* Request/reply
  * Ogni richiesta del client è seguita sa una risposta corrispondente dal server
  * Ogni richiesta è indipendente dalle altre
  * Nello stack TCP/IP è generalmente implementata a livello applicativo (RPC, RMI, SOAP, REST)

## User Datagam Protocol (UDP)

Fa solo da multiplexer delle comunicazioni tra le applicazioni. Un singolo host può eseguire diverse applicazioni, ma il protocollo IP permette di indirizzare solamente l'host.
L'UDP permette di separare il traffico in base alle porte.

Intestazione 8B:
* 16b Porta sorgente
* 16b Porta destinazione
* 16b Lunghezza UDP totale in word di 16 bit
  * Si aggiunge padding se serve
* 16b Checksum
  * Viene calcolato come Intestazine UDP + Dati + intestazione pseudo-IP
  * Intestazione pseudo-IP 12B:
    * 32b IP mittente
    * 32b IP destinatario
    * 8b must be zero
    * 8b protocollo
    * 16b lunghezza UDP totale

L'intestazione è particolarmente semplice, perché non offere nessun servizio.
L'intestazione pseudo-IP non viene trasmessa, viene generata dalle informazioni del protocollo IP.
La tupla con i due IP e le due porte rappresenta la comunicazione.

Il NAT di solito disabilita i checksum per non doverli ricalcolare

### API per UDP

Quando si fa il bind di un processo viene legato il processo ad una porta e vengono create una coda in uscita ed una coda in ingresso.

Con la recvmsg (bloccante) il programma preleva un intero messaggio dalla coda, altrimenti viene bloccato.
Un modulo del sistema operativo legge i messaggi UDP che arrivano dal livello 3, legge la porta e li inserisce nella coda del programma, se la coda era vuota e c'è un processo bloccato in lettura, lo sveglia.

Con la sendmsg (non bloccante) posso aggiungere un massaggio alla coda. Se la coda è piena, un messaggio viene scartato.
Un modulo del sistema operativo legge tutte le code dei programmi e quando trova pacchetti, li incapsula in un pacchetto IP e li passa al livello 3.

### Semplice demultiplexer UDP

Quando il livello tre separa i messaggi UDP in arrivo, un modulo del kernel (demultiplexer) controlla se ha una coda associata alla porta richiesta.
Se non è occupata dovrebbe inviare un pacchetto ICMP per segnalarlo.

Altrimenti controlla il checksum ed inserisce il messaggio in coda esattamente come gli è arrivato. Senza controlare l'ordine.

I datagrammi sono accodati in un unico messaggio.
La coda non ha un limite standard di messaggi, ma il sistema operativo può decidere quanto deve essere grande.
Se la coda si riempie, un datagramma viene scartato.

Non controlla da chi arriva il messaggio, se bisogna smistarli in base al mittente se ne deve occupare l'applicazione.

Non fa controllo di flusso.

Non fa conferma.

Incapsula e basta, e poi IP può frammentare all'occorrenza.

### Funzioni di UDP

UDP sembrà meno allettante di TCP, ma in realtà la sua semplicità lo rende estremamente veloce, ed utile per sistemi con risorse limitate.
Oltre che per avere una base per implementare algoritmi simil-trasporto a livelli più alti.

* Comunicazione senza connessione
  * Non serve creare il canale in anticipo
* I pacchetti sono controllati singolarmente
* Richiede pochissime risorse
  * Si può implementare in poche righe anche se non abbiamo uno stack completo (BIOS)
  * Molti dispositivi hanno un server DHCP e TFTP nel BIOS per configurare la rete e scaricare il sistema operativo via rete senza disco (deve essere piccolo)
    * Per questo si usa UDP
* Privo di stato
  * Ottimo per grandi quantità di client, come nel caso dello streaming o IPTV, quando il server non riuscirebbe a gestire la quantità di stati

È utile per:
* Applicazion realtime
  * VoIP
  * Giochi online
  * Live Streaming
* Comunicazioni unidirezionali
  * Broadcast e multicast
    * Non si può usare multicast TCP non possiamo attendere la conferma da tutti i membri di un gruppo, di cui magari non conosciamo nemmeno i membri
  * Servizi di discovery
* Viene usato per implementare servixi end-to-end a livello di trasporto (QUIC, RPC)

## Transport Control Protocol (TCP)

Svilupppato da Vinton Cerf e Robert Kahn.
Volevano implementare un servizio affidabile (tutti i dati arrivano sicuramente, in ordine, ed una volta sola) orientato alla connessione (prima di inviare si crea una sorta di "canale virtuale"), ed orientato al flusso di byte byte (non al datagramma come UDP).
Le connessioni TCP non hanno una durata limite, ci sono alcune connessioni che restano attive per anni, come quelle tra speaker BGP.

TCP è bidirezionale, ma negli esempi vediamo solo una direzione, dando per scontato che l'altra funziona uguale.
Il canale di comunicazione virtuale non esiste. La macchina non è collegata direttamente, ma attraverso la rete, non è nemmeno detto che la strada che percorrono i singoli pacchetti sia sempre la stessa.

Il TCP deve occuparsi di due problemi:
* Controllo di flusso
  * Il destinatario ha un buffer limitato, il mittente deve rallentare per non riempirlo
  * UDP non lo faceva, se il buffer era pieno si buttava via un datagramma
* Congestion control
  * Ogni dispositivo della rete sottostante ha una memoria limitata, e deve gestire diverse connessioni
  * Può succedere che la memoria finisca, quindi deve buttare via un pacchetto
  * Bisogna trovare un modo per non inviare nella rete più pacchetti di quelli che può gestire
  * Di conseguenza la banda end-to-end è limitata dal link più lento nel percorso, che purtroppo non è noto a priori

Per risolvere il problema del controllo di flusso si utilizza l'algoritmo delle porte scorrevoli (sliding windows algorithm) già visto al capitolo 2. Però non basta, deve essere modificato.
Ogni host fa in modo che l'altro end sappia che risors e ha a disposizione.

### Segmenti TCP

Per la congestione serve un meccanismo più complicato, perché non si può conoscere la capacità della rete, nessuno la sà.

Il TCP, essendo orientato al byte, permette di consumare i dati come voglio, non ci sono "limiti del messaggio", solo l'ordine dei byte è preservato.
Ovviamente non vengono inviati i singoli byte, ma un po' per volta, raggruppati in segmenti.
Esiste un altro protocollo affidabile (SCTP) che invece è orientato al messaggio, ma non lo usa nessuno.

Nel mittente è mantenuto un buffer di byte che l'applicazione continua a riempire. Il TCP preleva alcuni byte, forma un segmento e lo invia.
Nel mittente vengono raccolti i segmenti e si riempie un altro buffer con i byte nei segmenti. L'applicazione preleva i byte da questo buffer quando gli servono.

Ognuno di questi buffer è una sliding window, implementata come buffer circolare di dimensione prestabilita a seconda dell'implementazione (spesso in relazione alla memoria totale).

Se una applicazione prova a leggere 10 byte, ma nel buffer ci sono solo 5 byte, l'implementazione può comportarsi in due modi:
* Restisuisce i 5 byte, l'applicazione nota che gliene mancano altri 5 e riprova più tardi
* BLocca l'applicazione finché non ha 10 byte da restituire, poi restituisce quelli

Il buffer del mittente è diviso in 3 parti:
* Libera
* Non inviata
* Inviata ma in attesa di conferma

Il mittente può scrivere liberamente sulla parte libera, ma non può scrivere sulle altre due, nemmeno nella parte in attesa di conferma, potrebbe succedere che serve reinviarla.

Quando la parte libera è finita il processo viene bloccato finché non si libera abbastanza spazio nella parte in attesa di conferma.

### Intestazione TCP

L'intestazione contiene sia informazioni che servono per inviare i dati al destinatario, sia informazioni che servono per il flusso nel senso opposto, dal destinatario verso il mittente.
Destinatario e mittente non sono assoluti, ogni host vede se stesso come mittente e l'altro come destinatario, i due flussi continuano in parallelo.

Intestazione:
* 16b porta mittente
* 16b porta destinatario
* 32b sequence number
  * Indica la posizione del ptimo byte del segmento all'interno del flusso
  * Serve per posizionare i byte del segmento nella sequenza giusta
  * Un segmento ha seq=100 e dimensione 50, il successivo avrà seq=150, etc...
  * La dimensione la si scopre dal livello IP, non dall'intestazione TCP
* 32b acknowledgment number
  * Posizione dell'ultimo byte ricevuto dal destinatario all'interno del flusso
  * Sono numerati in modo diverso da quelli che invio verso il destinatario
* 4b hlen
  * Lunghezza intestazione in parole da 32 bit, normalmente è impostato a 5
* 6b riservati
* 6b flags
  * URG (urgent)
    * 1 l'urgent pointer è valorizzato
  * ACK
    * 1 l'acknowledgment number è valorizzato
  * PSH (push)
    * 1 il mittente richiede che il ricevitore consumi velocemente i dati (non sempre si può fare)
  * RST (reset)
    * 1 abortire la connessione (si usa quando il protocollo sbaglia)
  * SYN
    * Si usa nell'handshake
  * FIN
    * Si usa nella finalizzazione
* 16b window size
  * Quanti byte sono ancora liberi nel buffer di ricezione
  * Nel protocollo originario la dimensione massima del buffer er a 64k
  * Nelle implementazioni moderne quando comincia la comunicazione si scambiano un moltiplicatore della dimensione del buffer, per averlo più grande
* 16b checksum
  * Calcolato come nell'UDP
* 16b urgent pointer
  * Indica che una frazione del payload è urgente
  * Deve arrivare al mittente prima di tutti i byte inviati o già nel buffer
  * È l'unico caso in cui si cambia l'ordine dei byte
  * Si usa molto poco, serve per inviare comandi prioritari
  * Su SCTP esiste la sua evoluzione che permette di avere più flussi con più priorità
* ?w32b opzioni e padding
* ?B payload

È inefficiente avere un messaggio speciale per l'ACK, si mandano insieme dati per il destinatario, e l'ACK dei messaggi ricevuti. (Tecnica del piggybacking).
Se non ho dati da inviare invio solo l'header con l'ACK.

### Diagramma di stato del TCP

Una comunicazione orientata alla connessione deve mantenere delle informazioni sullo stato attuale della cominicazione (stateful).
Quste informazioni e questi passaggi di stato sono gestiti dalla socket.

Ogni socket TCP può essere in tre fasi:
* Handshaking
  * Quando inizia la connessione
* Data transfer
  * Quando la connessione è aperta
  * Questa fase dura un tempo indeterminato
* Closing
  * Quando sta terminando la connessione

Il passaggio di stato del TCP è una maccina a stati finiti deterministica; una macchina di Mealy, in particolare.

Macchina a stati:
* Handshaking
  * Closed (stato iniziale)
    * Passa a listen se viene messa in passive open (imposto il Transmission Control Block TCB)
    * Passa a SYN-sent se imposta il TCB e viene messa in active open, inivia un syn per aprire la connessione
  * Listen
    * Passa a SYN-received se riceve un syn per aprire una connessione
  * SYN-sent
    * Passa SYN-received se riceve un syn in risposta e invia un ACK (apertura simultanea)
    * Passa ad established se riceve un syn ed un ack
  * SYN-received
    * Passa ad established se riceve un ack
* Data transfer
  * Established
    * Passa a fin-wait-1 se si lancia la close, ed invia un fin
    * Passa close-wait se riceve un fin ed invia un ack
* Closing
  * fin-wait-1
    * Passa a fin-wait-2 se riceve un ack per il fin
    * passa a closing se riceve un fin, ed invia un ack
  * close-wait
    * Passa a last-ack **dopo aver atteso il close dell'applicazione** ed invia un fin
  * last-ack
    * passa a closed se riceve un ack per il fin
  * fin-wait-2
    * Passa a time-wait se riceve fin ed invia un ack
  * closing
    * Passa a time-wait se riceve un ack per il fin
  * time-wait
    * Passa a closed dopo un timer

### Handshaking

Il TCP ha una struttura stile client-server (meglio initiator-responder), in cui una delle macchine (l'initiator) apre passivamente la comunicazione, e l'altra (il responder) apre la comunicazione attivamente verso la macchina passiva.

Inizialmente la comunicazione è chiusa.
Una delle macchine esegue la accept, crea il TCB (che viene mostrato da ntestat). E resta in attesa del syn dal client (passive open).
L'altra macchina crea un TCB e invia (active open) il syn ad una macchina aperta.
Quando il responder riceve il syn, risponde con un ack+syn.
Quando l'initiator riceve il syn+ack del responder, risponde con un ack ed inizia (anche subito) la comunicazione.

Vengono scambiati 3 messaggi, per questo si chiama three-way handshake.

I numeri di sequenza non partono da 0, sono scelti in maniera casuale. Non significa che se sceglie 8000 parte dall'8000-simo byte, il sequence number è relativo ai pacchetti inviati prima. Serve per evitare collisioni con messaggi precedenti che potrebbero avere lo stesso seq.
Ovviamente il primo messaggio syn dall'host attivo ha un ack, ed il flag di ACK è a 0. L'host passivo genera un sequence number casuale ed invia nello stesso segmento il suo syn e l'ack del syn attivo.
A quel punto l'attivo invia l'ack del syn e nessun syn. Dopo di che le comunicazioni possono cominciare.

N.B. l'ack è sempre 1+seq, del messaggio precedente, ma se non ci sono dati il seq number del messaggio successivo ha lo stesso seq.

Esiste un caso particolare in cui due host tentano l'apertura attiva contemporaneamente. Quindi mentre ognuno attende l'ack+syn, riceve un ack. Se succede entrambi mandano un ack e restano in attesa che arrivi l'ack dell'altro.
È molto raro, ma lo permettiamo.

### Data transfer

Dopo la fase di handshaking, si perde il concetto di iniziatore/risponditore, attivo/passivo, client/server. Entrambi gli host sono peer di pari livello.
Ciascuno dei due può mandare dati all'altro.

Esempio:

Diciamo che un host era stato inizializzato con seq 8000 e l'altro con 15000.
Il primo manderà i dati numerati da 8001 a 9000, quindi con se1 8001 Con l'ack dell'inizializzazione che è 15001.
Poi manda altri byte, numerati da 9001 a 10000 e lo stesso ack.
Il secondo host risponde con l'ack, che è 10001 (la numerazione del prossimo byte), ed i byte numerati da 15001 a 17000. 
L'altro riceve, ma non ha altri dati da inviare, quindi invia un segmanto con seq 10000 e ack 17001, per confermare l'arrivo senza inviare altri dati.

### Close

Dopo un po' l'applicazione di uno dei due peer effettua una chiamata close.
Significa che non potrà più inviare dati, ma può ancora ricevere gli ultimi messaggi ed inviare ack. A volte i client chiudono la connessione, se devono solo ricevere dati dal server, e viceversa.

Quando riceve il fin, l'altro peer invia un ack del fin, passa a close-wait e continua con la sua esecuzione, attendendo che la sua applicazione lanci il close.
Eventualmente invia anche questo un fin+ack, può anche mandarlo subito se riceve subito la close.
A questo punto, il secondo host attende l'ack del suo fin dal primo, e può fermarsi.

Vengono scambiati 4 messaggi, per questo si chiama 4-way closing.
Se il secondo host chiude appena riceve il fin, viene detto 3-way closing.

Anche stavolta può succedere che cerchino di chiudere contemporaneamente. Allo stesso modo dell'apertura, entrambi mandano un ack per il fin ed attendono l'ack dell'altro.

Quando il chiusore passivo riceve il fin del chiusore attivo, e passa in close-wait, può continuare ad inviare dati come se fosse in established. L'altro (in fase fin-wait-2) continua a ricevere e consumare dati.
Come nello stato established, non c'è limite a quanto può durare questa fase.
Entrambe questa fase e la fase established possono durare 0 segmenti, è il caso in cui invio direttamente il fin+ack del syn (apertura), o quando invio il fin+ack del fin subito dopo il fin (chiusura).

La fase time-wait serve per assicurarsi che sia arrivato l'ack al chiusore passivo. Prima di chiudersi del tutto l'attivo attende in po', per vedere se l'altro rimanda il suo fin.
Se questo fin arrivasse dopo che una nuova connessione con lo stesso host è iniziata, potrebbe creare problemi.
La durata del timer è il doppio del tempo di vita massimo di un segmento nella rete (è un parametro della rete, non un'euristica).

###  Sliding Window Revisited

SI tratta della variante di TCP dell'algoritmo sliding window, che soddisfa tre scopi:
* Garantisce la consegna affidabile dei dati
* Assicura l'ordine dei dati
* Forza il controllo di flusso tra sender e receiver

Ricordiamo che noi parliamo di una macchina come sender e dell'altra come receiver, ma in realtà sono entrambe sender e receiver, la comunicazione va in entrambi i sensi.

L'applicazione sender mantiene un buffer di tutti i byte da inviare e confermare, ed un puntatore all'ultimo byte confermato ed all'ultimo byte invato. Ed un puntatore all'ultimo byte scritto sul buffer dall'applicazione.

L'applicazione receiver mantiene un buffer con tutti i dati ricevuti e non consumati, con un puntatore all'ultimo byte consumato, l'ultimo byte ricevuto, il prossimo byte atteso, e l'ultimo byte ricevuto.
Servono sia un ultimo byte ricevuto che un prossimo byte atteso, perché potrebbero essere arrivati fuori ordine, o può essersi perso un segmento. Formando un buco nel buffer.

L'applicazione receiver può consumare i dati comrpesi tra lastbyteread e nextbyteexpected, ma non quelli fino a lastbytercvd, perché potrebbero esserci buchi. nextbyteexpected punta al primo buco, che sia prima o corrispondente a lastbytercvd.
nextbyteexpected è l'ack che viene inviato.

Invarianti:
* Sender
  * LastByteSent $\leq$ LastByteWritten
  * LastByteAcked $\leq$ LastByteSent
* Receiver
  * NextByteExpected $\leq$ LastByteRcvd+1
  * LastByteRead $<$ NextByteExpected
* LastByteWritten $-$ LastByteAcked $\leq$ MaxSenderBuffer
* LastByteRcvd $-$ LastByteRead $\leq$ MaxRcvBuffer

Per evitare che il buffer del ricevente si riempia, invio la dimensione del buffer libero (AdvertisedWindow), per informare il sendere di quanto può inviarmi.
L'unica parte del buffer che verametne non posso usare è quella tra LastByteRead e NextByteExpected. Tutto il resto posso usarlo per i messaggi che arrivano, se serve.

Il sender farà in modo che lo spazio tra LastByteAcked e LastByteSent sia sempre minore od uguale all'AdvertisedWindow. Perché altrimenti il ricevitore non riuscirà a gestirla.

La finestra di invio effettiva è la AdvertisedWindow $-$ (LastByteSent $-$ LastByteAcked). Quindi è il limite effettivo dei dati che in questo momento il sender può provare ad inviare.

Se la comunicazione di ferma perché si riempie la finestra del receiver, ed il receiver non invia niente al sender (attraverso la connessione opposta) non notifica mai che la finestra si è svuotata.
Per questo il sender, dopo un timeout, invia un segmento probe di 1 byte, per farsi mandare un ack con la dimensione della finestra. Oltre alla dimensione della finestra, se l'ack è lo stesso del seq, so che non ha nemmeno memorizzato il byte.
Il timeout aumenta esponenzialmente come nell'algoritmo di backoff.