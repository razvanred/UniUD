# Tecnologia di un datbase server centralizzato

Abbiamo visto che funzionalità ha un database server. Ci serve sapere con che meccanismi le realizza.

Perché?
* Capiamo come conviene configurare un database in base a che funzionalità ci interessano di più
* Aiuta a scrivere comandi che possano essere eseguiti meglio
* È utile studiare come funziona
* Alcuni meccanismi vengono estratti e messi a disposizione di altri servizi

Componenti di un server:
1. Ottimizzatore (gestore delle interrogazioni)
   1. Stabilisce le strategie di accesso ai dati
2. Gestore dei metodi di accesso ai dati
   1. Trasforma le richieste dei comandi ad alto livello, in operazioni di lettura e scrittura in memoria secondaria
3. Gestore del buffer
   1. Gestisce il trasferimento delle pagine dalla memoria secondaria alla memoria principale
4. Controllore della concorrenza
   1. Gestisce gli accessi concorrenti
5. Controllore dell'affidabilità
   1. Garantisce il funzionamento in caso di guasti

## Transazioni

Definizione informale: Una unità elementare di lavoro a cui si vogliono associare particolari caratteristiche di correttezza, robustezza ed isolamento.

Un sistema (anche non DB) che mette a disposizione questi meccanismi è detto transazionale.

Si usano due comandi per incapsulare singole operazioni in una transazione:
* Begin
* End

La end è spesso implicita, si capisce dal contesto.
Se sono omesse entrambe, ogni istruzione è una transazione a se stante (modalità autocommit), è quello che accade di solito negli ambienti interattivi.

Quando raggruppiamo istruzioni in una transazione, possiamo vedere l'intera transazione come una unica istruzione.

Esistono due istruzioni speciali:
* Commit
  * Considero quello che ho fatto, definitivo
  * Viene fatta alla fine, quindi non serve la end
* Abort
  * Faccio un rollback a prima di iniziare la transazione
  * Viene fatta alla fine, quindi non serve la end

Nella stessa transazione non posso fare più di una di queste operazioni, non posso fare sia commit che abort, e non posso fare commit e poi aggiungere altri comandi e fare un'altra commit.

Posso scegliere se fare una o l'altra in base ai percorsi di esecuzione dell'applicazione.
Il sistema può forzare un abort se alcune cose vanno storte.

Eseguire il commit garantisce che i cambiamenti vengano memorizzati in modo permanente nella base di dati.

### Proprietà ACID (acide)

Proprietà
* Atomicità
  * Tutta la transazione è una sola operazione
  * O eseguo tutta la transazione, o non eseguo niente
  * Quindi devo essere in grado di disfare la transazione, se succede qualcosa per cui non posso copletarla. Facendo delle undo per annullare le operazioni già fatte
  * Non è possibile che una transazione che ha fatto la commit, non sia registrata permanentemente. A costo di dover rifare (redo) alcune operazioni
    * Il motivo dei redo viene spiegato più avanti, ha a che fare con la gestione del buffer
  * Un abort può avvenire per diversi motivi:
    * La transazione termina con un abort
    * Il sistema non è in grado di portare a termine l'operazione
      * A volte se dopo un certo tempo non riesce a completare un comando (dead lock), si considerà fallita l'operazione
    * Un guasto può abortire tutte le transazioni non completate
    * ...
  * Di norma vanno a buon fine, alcuni sistemi di gestione della concorrenza molto affidabili sono falliti proprio perché abortivano troppo spesso
  * Dopo aver abortito, di solito, l'applicazione fa ripartire la transazione, l'utente vede solo che è più lenta
* Consistenza
  * L'esecuzione non deve violare i vincoli di integrità definiti sulla base di dati
  * Eventualmente si può intervenite od annullare
  * Si può verificare la condizione ad ogni operazione
  * Si può differire il controllo alla commit
* Isolamento
  * L'esecuzione di una transazione deve essere logicamente indipendente da altre transazioni eseguite in contemporanea
  * Deve avere lo stesso effetto che avrebbe avuto se fosse stata eseguita senza altre transazioni concorrenti
  * In particolare, se una transazione fa rollback, non dovrebbero farlo anche le altre
    * Succede quando una transazione legge dati modificati da un'altra incompleta, e questa fa rollback
* Durability (persistenza)
  * È legata alla proprietà di atomicità, vengono entrambe garantite dal controllo dell'affidabilità
  * L'atomicità dice: "o tutto o niente"; la persistenza dice: "se tutto, allora per sempre"

## Gestione del buffer

Il buffer è una vasta porzione di memoria centrale preallocata al DBMS e condivisa tra le transazioni.

Visto che le memoria costano sempre di meno, i buffer diventano sempre più grandi, a volte si può anche inserire l'intera base nel buffer.

Nei casi reali, l'aumento della dimensione del buffer è stato bilanciato da un aumento della dimensione delle basi di dati.

Comunque, +grande=+meglio

Filtra i comandi del gestore dei metodi di accesso per raggiungere il suo obbiettivo.

L'obbiettivo del getore del buffer è mantenere porzioni del DB in memoria centrale per migliorare l'efficienza (il disco è lento), garantendo le proprietà di affidabilità.
Vengono definite delle politiche per garantire queste proprietà, che vengono usate per trasformare le operazioni svolte in memoria centrale (veloci) in operazioni della memoria secondaria.

I suoi compiti sono:
* Caricamento e scaricamento delle pagine
* Accesso alle pagine presenti nel buffer
  * Quando viene richiesto l'accesso ad una pagina, se è già in memoria centrale si accede. Altrimenti carica (ed eventualmente scarica qualcos'altro) e poi permette l'accesso

Deve interagire con lo scheduler per la gestione dei lock durante la concorrenza.

### Organizzazione del buffer

Il buffer è organizzato in pagine che hanno dimensione pari a uno o più blocchi di memoria secnodaria.

Il blocco è l'unità di trasferimento dei dati tra le due memorie.
In genere consideriamo una pagina del buffer grande come un blocco, ed ogni blocco grande diversi kB

### Gestione delle letture e delle scritture

Tutte le operazioni del DB si traduconoin letture e scritture.
Il gestore del buffer gestisce la tempistica delle operazioni per migliorare l'efficienza, può non essere quella richiesta.

In caso di lettura può non essre necessario accedere alla memoria secondaria.

In caso di scrittura, il gestore può ritardare la scrittura, se consintito dalle proprietà di affidabilità del sistema.

Spesso il gestore cambia gli ordini delle operazione senza avvisare i programmatori, per gestire più efficientemente la memoria.

Utilizza le stesse politiche che usa il sistema operativo per la gestione della memoria principale.

Valgono i soliti principi di località e di Pareto
* I dati acceduti di recente hanno maggiore probabilità di essere acceduti di nuovo
  * I dati adiacenti a quello acceduto di recente hanno maggiore probabilità di essere acceduti di nuovo
* L'80% degli effetti è prodotto sul 20% dei dati
  * Il 20% dei dati è acceduto dall'80% delle applicazioni
  * Quindi è più importante memorizzare in centrale questo 20% piuttosto che il  restante 80%

### Direttorio e variabili di stato

Per gestire il buffer vengono msantenute due strutture dati:
* Direttorio
  * Descrive il contenuto corrente del buffer
  * Indica per ogni pagina caricata, il file ed il blocco fisico
* Variabili di stato
  * Un contatore di programmi che usilizzano la pagina
  * Un bit di stato che specifica se è stata modificata

### Primitive per la gestione del buffer

Il buffer manager mette a disposizione delle transazioni, delle primitive di caricamento e scaricamento delle pagine:
* Fix
  * Richiede l'accesso ad una pagina e restituisce un riferimento alla pagina del buffer
* setDirty
  * Indica che la pagina è stata modificata
  * Modifica il bit di stato
* unfix
  * Indica che la pagina non è più in utilizzo
* Force
  * Forza la scrittura in modo sincrono della pagina in memoria secondaria
  * Resetta i bit di stato
  * Viene lanciata da un altro modulo del DBMS, non dalle transazioni

### Primitiva fix

Se non esiston pagine libere, ho due politiche alternative:
* Steal
  * Sottraggo una pagina ad una altra transazione vittima
  * Viene scaricata in memoria per poter caricare la nuova pagina
  * Quando la prima transazione richiederà di nuovo la pagina verrà di nuovo caricata in memoria
* No-Steal
  * Non consento di sottrarre le pagine
  * Viene sospesa la transazione che richiede la pagina finché non si liberano pagine

### Caricamento/scaricamento anticipato

Alcune transizioni dichiarano (o comunque è noto) quali pagine una transazione richiederà in futuro, alcune politiche di gestione della concorrenza prevedono alcune chiamate per questo.

Il buffer può scegliere di caricare in anticipo le pagine che saranno richieste in futuro, o non scaricare pagine libere che verranno chieste in futuro.

Se una pagina è stata liberata, il gestore può scaricarla in anticipo per rendere più efficienti fix successive (che non dovranno scaricare in secondaria la pagina).

### DBMS e file system

Il DBMS si appoggia al filesystem per alcune funzioni, poi crea una sua astrazione dei file, più efficiente pe gli scopi del db.

Primitive usate:
* Creare/Cancellare ed espandere file
* Leggere e scrivere singoli blocchi sui file
  * La gestione dei dati nei blocchi è gestita interamente dal database.
* Apertura e chiusura di un file

Modalità di accesso:
* Diretto
  * Legge un singolo blocco
  * read(fileid, block, buffer)
* Accesso seqeuenziale
  * Accede ad un numero disso di blicchi in modo sequenziale
  * read_seq(fileid, f-block, count, f-buffer)
* Operazioni di scrittura analoghe

## Gestore della concorrenza

Un DBMS deve servire diverse applicazioni contemporaneamente, la qualità di un DBMS viene misurata in transazioni al secondo (tps). Varia da decine a migliaia a seconda dei sistemi.

La serializzazione delle transazioni risolve tutti i problemi di concorrensa. È impesabile serializzare le transazioni, sono troppe, diventerebbe lentissimo.

Per questo serve un gestore della concorrenza (la parte più complicata del sistema) che risolve i problemi di concorrenza. Permettendo a diverse transazioni di avvenire contemporaneamente.

Una esecuzione va bene se produce lo stesso output di una esecuzione seriale.

### Architettura

Le operazioni possono essere di lettura o scrittura dei dati e sono raggruppate in transazioni chiuse da commit od abort.

Il gestore della concorrenza comunica con il gestore dei metodi di accesso ed il gestore delle transazioni per produrre in output le operazini di read e write "sanificate" alla memoria.

Per gestire la concorrenza utilizza una tabella di lock.

### Anomalie

Notazione:
* $r_a(x)$ a legge x
* $w_a(x)$ a scrive x
* $x:=x+1$ aggiorno il valore interno di x

Anomalie:
* Lost update
* Dirty read
* Phantom update
* Inconsistent read
* Phantom insert

#### Lost Update

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
| $x:=x+1$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| $w_1(x)$ |  |
| commit |  |

Eseguo due incrementi, ma il valore registrato aumenta solo di 1.

#### Dirty Read

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
| $x:=x+1$ |  |
| $w_1(x)$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| abort |  |

La seconda transazione scrive un valore incrementato due volte, ma uno dei due incrementi viene abortito dalla transazione 1.

#### Phantom Update

| Transazione 1 | Transazione 2 |
| --- | --- |
| $s:=0$ |  |
| $r_1(x)$ |  |
| $r_1(y)$ |  |
| $s:=s+x$ |  |
| $s:=s+y$ |  |
|  | $r_2(z)$ |
|  | $z:=z+10000$ |
|  | $r_2(y)$ |
|  | $y:=y-10000$ |
|  | $w_2(z)$ |
|  | $w_2(y)$ |
|  | commit |
| $r_1(z)$ |  |
| $s:=s+z$ |  |
| commit |  |

Immaginiamole come operazioni su conti correnti.
La prima transazione prende tre variabili e le somma, ma la terza somma viene fatta dopo che è eseguita la seconda transazione (come se mettessi insieme i soldi di tre conti correnti).
La seconda transazione prende due variabili e decrementa una di quanto incrementa l'altra (come se trasferissi soldi da un conto all'altro).

La terza somma (prima transazione) aggiunge i soldi del terzo conto, ma aggiunge anche i soldi trasferiti dal'altro conto, che erano stati inseriti nella somma già prima del tradferimento.
Il valore della somma è sbagliato.

#### Inconsistent Read

Riguarda transazioni che hanno solo operazioni di lettura, ed eseguono due volte la stessa lettura.

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| $r_1(x)$ |  |
| commit |  |

Il valore di x cambia tra le due letture da parte della prima transazione.

#### Phantom insert

Consideriamo una transazione che valuta un valore aggregato di tutti gli elementi che soddisfano un predicato. Questo valore viene calcolato due volte nella transazione.

Se tra la prima e la seconda valutazione viene inserito (da una seconda transazione) un elemento che soddisfa il predicato, ottengo due risultati diversi.
Vale anche se invece che un inserimento abbiamo un aggiornamento che soddisfa il predicato (per una tupla che prima non soddisfafa).

Sembra uguale alla lettura inconsistente, ma vedremo che viene risolta in modo diverso perché questa volta la modifica avviene su un valore che non avevo modificato.

### Formalizzazione di transazione

Ometteremo le operazioni di inizio e fine, perché sì.
Assumeremo anche che una transazione non vada a scrivere due volte lo stesso dato.

Definiamo una transazione come sequenza di operazioni di lettura e scrittura. Operazioni della stessa transazione sono caratterizzate dallo stesso indice (vedi notazione).

Operazioni di modifica dei dati interni diventano irrilevanti, interessano solo letture o scritture. Assumiamo che se avviene una scrittura, è avvenuta una qualche manipolazione, altrimenti il DBMS ignorerebbe la scrittura.

Esempio: $t_1:r_1(x)r_1(y)w_1(x)w_1(y)$

Notiamo che l'indice 1 ha poco senso se osserviamo una sola transazione.

### Schedule

Una sequneza di operazioni di lettura e scrittura, relative ad un certo insieme di transazioni concorrenti.
L'ordine in cui trovo le operazioni della stessa transazione è lo stesso ordine della transazione. Posso solo decidere come mescolare le transazioni diverse.

Esempio: $S_1:r_0(x)w_1(x)r_1(x)w_0(x)w_2(x)r_1(y)r_0(y)w_1(y)$

Adesso che le azioni vengono da più transazioni, l'indice diventa importante. Se due azioni hanno lo stesso argomento riguardano gli stessi blocchi di dati.

### Scheduler

Produce lo schedule per evitare le anomalie.
Tiene traccia di tutte le operazioni eseguite da tutte le tranazioni della base di dati e via via decide da quale transazione prendere la prossima operazione.

Inizialmente Assumeremo che lo scheduler sappia in anticipo le operazioni che eseguirà, e l'esito. Nella fase finale dello studio ci libereremo della stessa assunzione.

### Schedule seriale

Uno schedule si dice seriale se pe ogni transazione t, tutte le sue azioni compaiono in sequenza senza essere inframezzate da operazioni di altre transazioni.

### Schedule serializzabile

Uno scchedule è corretto/serializzabile, se produce lo stesso effetto di ***uno*** schedule seriale delle stesse transazioni.

Cosa significa "stesso effetto"? Cambia in base ai criteri di serializzabilità.

### Criterio di equivalenza di vista (VSR)

Definizioni:
* Relazione legge
  * Lega coppie di operazioni di lettura e scrittura
  * La lettura $r_i(x)$ legge da un operazione si scrittura $w_i(x)$ se la scrittura preede la lettura ed in mezzo alle due non c'è nessun'altra scrittura su $x$
* Insieme di scritture finali
  * Un operazione si scrittura è detta finale se dopo quella scrittura non ci sono altre scritture sullo stesso dato

Due schedule sono equivalenti rispetto alle viste se hanno le stesse relazioni legge e insieme di scritture finali.

Uno schedule è serializzabile se è equivalente rispetto alle viste, ad uno schedule seriale.

Esempio:
$$
S_3:w_0(x)r_2(x)r_1(x)w_2(x)w_2(z)\\
S_4:w_0(x)r_1(x)r_2(x)w_2(x)w_2(z)\\
S_5:w_0(x)r_2(x)w_2(x)r_1(x)w_2(z)\\
S_6:w_0(x)r_2(x)w_2(x)w_2(z)r_1(x)
$$

* $S_4$ è seriale.
* $S_3$ è come 4, ma con due letture scambiate, non cambiano le scritture finali e non cambiano le letture. Quindi sono equivalenti, quindi è serializzabile
* $S_6$ è seriale 
* $S_5$ non è equivalente a 4, perché cambia la lettura di $r_1$. Però è equivalente a 6, quindi è serializzabile

Per verificarlo bisognerebbe elencare tutti gli schedule seriali e verificarli uno ad uno, ma gli schedule seriali sono tanti (è NP-completo), quindi non si può fare. Esistono tecniche semplici per scsartarne alcuni.

Gli schedule che causano: perdita di aggiornamento, letture inconcistenti, od aggiornamento fantasma; non sono serializzabili rispetto alle viste.

È un buon criterio, il problema è la complessità.

### Criterio di equivalenza rispetto ai conflitti (CSR)

Una azione si dice in conflitto con un altra se:
* Appartengono a transazioni diverse
* Riguardano lo stesso soggetto
* Almeno una è una scrittura

Elenchiamo i conflitti come coppie ordinate, l'ordine è dettato da quale compare prima nello schedule ed è **fondamentale**.

Due schedule sono equivalenti rispetto ai conflitti se contengono le stesse azioni, e le azioni in conflitto compaiono nello stesso ordine (hanno lo stesso insieme dei conflitti).
Uno schedule è serializzabile rispetto ai conflitti se è equivalente rispetto ai conglitti ad uno schedule seriale.

Si può dimostrare che
* Tutti gli scedule CSR sono anche VSR
  * Supponiamo di trasformare uno schedule in un altro spostando le operazioni all'interno del primo schedule
    * Ogni scrittura è in conflitto con tutte le operazioni di lettura e scrittura sullo stesso soggetto in transazioni diverse
      * Se una scrittura si sposta in mezzo a due operazioni legate da una relazione di lettura (cambiando lettura), o modifica i conflitti o non può essere spostata
        * Se veniva da dopo l'operazione di lettura, cambia l'ordine del conflitto con questa
          * Notare che se la scrittura spostata appartiene alla stessa transazione dell'operazione di lettura non si può eseguire lo spostamento
        * Se veniva da prima della scrittura cambia l'ordine del conflitto con questa
          * Notare che se la scrittura spostata appartiene alla stessa transazione dell'altra scrittura non si può eseguire lo spostamento
      * Se non ha conflitti compare solo in letture della propria transazione e non può influenzare le altre
    * Ogni scrittura finale è in conflitto con tutte le scritture sullo stesso soggetto
      * Se una scrittura non è più finale, si scambia di ordine con un altra scrittura
        * Quindi cambia verso il conflitto
      * Mantenere i conflitti mantiene le scritture finali
      * Se non avesse conflitti, sarebbe finale a prescindere dall'ordine
* Non tutti gli schedule VSR sono CSR
  * Esercizio 7, esame del 22/03/2002
    * $S_1:r_0(x)w_1(x)r_1(x)w_0(x)w_2(x)$
      * C'è un ciclo tra $t_0$ e $t_1$, non è CSR
        * $w_0(x)\rightarrow w_1(x)$
        * $w_1(x)\rightarrow r_0(x)$
      * È equivalente a $S_2:r_0(x)w_0(x)w_1(x)r_1(x)w_2(x)$, è VSR
        * Mantiene la scrittura finale $w_2(x)$
        * Mantiene le letture $(w_1(x),r_1(x))$ e $(\_,r_0(x))$
          * Non ci sono altre letture

Si può verificare usando il grafo dei conflitti:
* I nodi sono transazioni
* Se una operazione di una transazione è in conflitto con una in un altra, metto un arco dalla prima transazione alla seconda

Uno schedule è serializzabile rispetto ai conflitti se e solo se il grafo dei conflitti è aciclico.
Non è più NP-completo.

Dimostrazione:
* $\Rightarrow$ Se CSR allora aciclico
  * Supponiamo uno schedule seriale $S_0:t_1,t_2,t_3,...$
  * Nel grafo dei conflitti esistono solo archi da $t_i$ a $t_j$ in cui $i>j$
    * Non può essere ciclico 
* $\Leftarrow$ Se aciclico allora CSR
  * Se è aciclico esiste un ordinamento topologico
  * Uno schedule seriale che segue l'ordinamento topologico è equivalente a quello originale

Anche se è lineare, è troppo lento per sistemi con centinaia o migilaia di transazioni al secondo.

### La Soluzione (locking a due fasi, 2PL)

***La*** $\mathfrak{Soluzione}$.\
[Playing - "O Fortuna Velut Luna"]

Si utilizza un sistema di locking. Protegge le operazioni di lettura e scrittura con operazioni read_lock, write_lock e unlock.

Tipi di lock:
* Si utilizza un lock condiviso per le letture
  * Più transazioni possono leggere contemporaneamente
* Si utilizza un lock esclusivo per le scritture
  * Non si deve fare niente durante le scritture
  * In alcuni sistemi si usa solo questo
* Si può passare da condiviso ad esclusivo, aumentando il livello del lock

L'acquisizione ed il rilascio devono avvenire rispettivamente prima e dopo le operazioni, ma non necessariamente immediatamente prima e dopo. Si può anticipare l'acqusizione e ritardare il rilascio.

Le transazini sono in genere automaticamente ben formate (lock ed unlok sono inseriti in modo trasparente all'applicazione).
La politica è basata su una tabella dei conflitti. Quando viene chiesto un lock, lo scheduler può decidere se lasciare in attesa la transazione o concedere il lock (si dice che acquisisce il lock). Nel momento dell'unlock, la risorsa viene rilasciata, e se possibile, viene acquisita da un'altra transazione.

Per ogni risorsa viene mantenuta una tabella dei conflitti.

| Richiesta | libero      | r_locked    | w_locked    |
| --------- | ----------- | ----------- | ----------- |
| r_lock    | OK/r_locked | OK/r_locked | No/w_locked |
| w_lock    | OK/w_locked | No/r_locked | No/w_locked |
| unlock    | error       | OK/dipende  | OK/libero   |

Le celle della tabella indicano la politica che lo scheduler deve seguire in base allo stato della risorsa (colonna) e il tipo di richiesta (riga). L'unica cosa che non ha senso e genera un errore è l'unlock di una risorsa già libera.
Oltre alla tabella dei conflitti, viene mantenuto un contatore delle transazioni in r_lock.

Questa politica da sola non basta per garantire mutua esclusione. Si separano le operazioni di locking in due fasi:
* Fase crescente
  * Si acquisiscono tutti i lock necessari
* Fase calante:
  * Si rilasciano un po' alla volta tutti i lock

Per forzare questo comportamento si impedisce di acquisire lock dopo averne rilasciato uno.
Notare che formando un grafico con la quantità di lock acquisiti, si ottiene un trapezio, non un rettangolo, perché i lock vengono acquisiti e rilasciati un po' per volta, quando servono.
C'è la possibilità di avere stalli, anche se questa tecnica cerca di evitare la maggior parte dei conflitti.

#### Legame tra 2PL e CSR

2PL è contenuto in CSR.

***Dimostrazione***: Se, per assurdo esistesse uno schedule $S$ tale che $S\in2PL\land s\notin CSR$, seque che il grafo dei conflitti contiene un ciclo $t_1,t_2,...,t_n,t_1$. Se esiste un arco tra $t_1$ e $t_2$, significa che esiste una risorsa su cui le due transazioni operano in modo conflittuale.
Se esite questa operazione conflittuale è necessario che $t_1$ rilasci il lock perché $t_2$ possa accedervi.
Stesso ragionamento per l'arco tra $t_1$ e $t_n$. Per avere questo arco è necessario che l'acquisizione del lock segua l'esecuzione di $t_2$, ma per questo dovrebbe avvnerire dopo il rilascio del primo lock, quindi violerebbe la regola di 2PL.
Se $t_1$ anticipasse il lock che blocca $t_n$ per evitare di rilasciare il lock che blocca $t_2$ prima dell'acquisizione, comunque dovrebbe rilasciarlo prima che sia eseguito $t_n$, evitando il conflitto.

CSR non è contenuto in 2PL, quindi è un sovrainsieme stretto.

***Dimostrazione***: $S_{12}:r_1(x)w_1(x)r_2(x)w_2(x)r_3(y)w_1(y)$. Non contiene cicli, esiste solo un percorso $t_3,t_1,t_2$, quindi appartiene a CSR. Analizziamo i lock:
* 1 aquisisce un r_lock su X
* 1 incrementa il livello a w_lock su X
* 1 deve rilasciare il lock su X per permettere l'esecuzione di 2
* 2 acquisisce il r_lock su X
* 2 incrementa il livello a w_lock su X
* (2 può rilasciare il lock su X)
* 3 acquisisce un r_lock su Y
* (3 può rilasciare il lock su Y)
* !!! 1 non può acquisire il w_lock su Y perché ha già rilasciato X

Proviamo lo scenario alternativo
* 1 aquisisce un r_lock su X
* 1 incrementa il livello a w_lock su X
* 1 deve acquisire un w_lock su Y per poter rilasciare X
* 1 deve rilasciare il lock su X per permettere l'esecuzione di 2
* 2 acquisisce il r_lock su X
* 2 incrementa il livello a w_lock su X
* (2 può rilasciare il lock su X)
* !!! 3 non può acquisire il r_lock su Y, perché è occupato da 1
* 1 deve eseguire prima la scrittura per rilasciare il lock

#### Anomalie

È facile vedere che 2PL risolve le anomalie di perdita di aggiornamento, aggiornamento fantasma e letture inconsistenti.

Per osservare la lettura sporca bisogna rimuovere l'assunzione di commit ed osservare che quando viene abortita la transazione, non viene evitata l'anomalia.
Quindi occorre imporre un nuovo vincolo: che i lock vengano rilasciati tutti assieme *dopo* il commit. In questo caso viene chiamato 2PL stretto, e viene utilizzato comunemente nei sistemi commerciali, ma non sempre in sistemi meno critici, perché è limitante.

L'unica anomalia che non rimuove nemmeno il 2PL stretto è la phantom insert, ma abbiamo detto che deve essere trattata in modo speciale.

#### Phantom Insert

Finora abbiamo definito i lock in base agli oggetti nella base di dati.

Per risolvere l'inserimento fantasma dobbiamo permettere che i lock possano essere definiti in riferimento alle condizioni.
Si chiamano lock di predicato, e se vogliamo evitare l'inserimento fantasma dobbiamo utilizzarli, ma richiedono un approccio ad hoc.

### Timestamp (TS)

È un metodo semplice (nella versione base) meno efficace del precedente, che ha ottenuto un certo interesse in letteratura.

Un timestamp è un identificatore associato ad ogni evento che definisce un ordinamento temporale totale sugli eventi.

Parametri:
* $WTM(x)$ il timestamp della transazione che ha eseguito l'ultima scrittura in x
* $RTM(x)$ il timestamp più grande su x

Lo scheduler riceve richieste $r_t(x)$ e $w_t(x)$ e può decidere se concedere o meno l'operazione. La t p il timestamp della transazione

Politica:
* $r_t(x)$ se $t<WTM(x)$ non concede la lettura
  * Non si può leggere un dato che è strato scritto da una transazione successiva
* $w_t(x)$ se $t<RTM(x)$ non concede la scrittura
  * Non si può scrivere un dato che è già stato concesso ad una transazione successiva

Quando la richiesta viene rifiutata, non implementiamo una sospensione, ma viene forzatamente abortita la transazione.
È molto semplice da implementare e comprendere, ma causa molti aborti. Inoltre, non risolve il problema degli inserimenti fantasma.

Se vogliamo risolvere il problema degli inserimenti fantasma si può aggiungere una qualche tecnica di bufferizzazione delle letture, ma diventa molto complicato, quando l'obbiettivo principale di questo meccanismo è essere semplice.

Per evitare tutti gli aborti, si può aggiungere una operazione di pre-write, che "prenota" la scrittura e ritarda le letture successive a dopo la scrittura.

#### Multiversioni

Un altro metodo è quello delle "multiversioni", che consiste di mantenere diverse copie degli oggetti, mantenendo la versione vecchia dell'oggetto quando viene scritto. Potrà essere letta da transazioni con timestamp minore, il dato vecchio si elimina quando non esistono più transazioni con timestamp minore.

Nuova notazione:
* $WTM_n(x)$ timestamp dell'ultima transazione che ha aggiornato il valore x
* $WTM_k(x)$ timestamp dell'ultima transazione che ha aggiornato il valore x al timestamp k
* $x_n$ ultima versione dell'oggetto x
* $x_k$ versione di x al timestamp k
* $\overline x$ valore letto di x

Nuove politiche:
* $r_t(x)$ viene sempre accettata
  * Se $t\geq WTM_n(x)$ allora $\overline x=x_n$
  * Se $t<WTM_n(x)$ allora $\overline x=x_k$ tale che $WTM_k(x)\leq t\leq WTM_n(x)$
* $w_t(x)$ se $t<RTM_n(x)$ non concede la scrittura
  * Altrimenti $RTM_{n+1}(x)=t$

#### Legame tra TS e 2PL

Recap: VSR è l'insieme più grande, CSR è strettamente contenuto in VSR, 2PL e TS sono entrambi strettamente contenuti in CSR, 2PL stretto è strettamente contenuto in 2PL.\
Aggiunta: TS si interseca con 2PL e co 2PL stretto, ma nessuno contiene TS e TS non contiene nessuno.

Per vedere se uno schedule sta in TS si provano semplicemente i timestamp.
Si dimostra facilmente che se il grafo dei conflitti di CSR contiene cicli, non rispetta l'ordine dei timestamp.

Banalmente esistono schedule che appartengono a TS ma non 2PL (esempio sulle slide).

Banalmente esiste uno schedule seriale con le transazioni in ordine opposto al timestamp che appartiene a 2PL ma non a TS.

Banalmente esistono schedule che stanno in entrambi (esempio sulle slide)

Differenze:
* TS uccide le transazioni che creano conflitti, 2PL le blocca
* In 2PL l'ordine è imposto dai conflitti, in TS dal timestamp di attivazione
* I blocchi possono causare deadlock e lunghi tempi di attesa

## Esercizio esame 22/01/2019

Stabilire se i seguenti schedule appartengono VSR, CSR, 2PL, 2PL stretto, o TS

### a

$$S_1:r_3(x)r_1(x)w_4(z)r_4(y)w_2(x)r_2(x)r_3(y)w_1(x)w_4(y)$$

* VSR?
  * Lunica lettura è $w_2(x)r_2(x)$
  * Le scritture finali sono: $w_4(y),w_1(x),w_4(z)$
  * Proviamo a limitare i controlli
    * 2 non può essere eseguita dopo di 1, (scrittura finale)
    * 2 non può essere eseguita prima di 1, (1 non legge da 2)
  * Non è VSR
* Altri?
  * Non appartiene ad altri scheduler, perché non appartiene a VSR

### b

$$S_2:r_2(z)w_1(t)w_3(z)r_2(x)w_4(t)r_1(y)w_2(z)w_3(y)r_1(x)w_4(z)w_2(x)$$

* CSR?
  * Transazioni
    * $t_1$
    * $t_2$
    * $t_3$
    * $t_4$
  * Archi
    * 1-4
    * 2-3
    * 2-4
    * 3-2
  * C'è un ciclo, quindi non è CSR
* 2PL, 2PL stretto, TS?
  * Non può
* VSR?
  * Scritture finali
    * $w_2(x),w_4(z),w_3(y),w_4(t)$
  * Letture
    * Nessuna
  * Proviamo a limitare i controlli
    * 1 deve precedere 4 (scrittura finale)
    * 2 e 3 devono precedere 4 (altra scrittura finale)
    * 2 deve precedere 3 (2 non legge da 3)
    * 1 deve precedere 2 (1 non legge da 2)
    * Unico candidato $t_1,t_2,t_3,t_4$
  * Si ccontrolla che il candidato non causi altri conflitti
    * Non lo fà
  * È VSR

### c

$$S_3:r_4(y)w_1(x)r_1(y)w_3(t)r_2(t)w_2(x)r_2(y)w_4(y)r_1(z)w_4(x)r_4(t)w_3(z)$$

* 2PL?
  * 4 r_lock y
  * 1 w_lock x
  * 1 r_lock y
  * 3 w_lock t
  * 3 unlock t
  * 2 r_lock t
  * 1 anticipa r_lock z
  * 1 unlock x
  * 2 w_lock x
  * 2 r_lock y
  * 2 unlock y
  * 3 unlock y
  * 4 r_lock -> w_lock y
  * 1 legge z (viola il 2PL stretto)
  * 2 unlock x
  * 4 w_lock x
  * 4 r_lock t
  * 1 unlock z
  * !!! 3 non può acquisire la z, perché ha già rilasciato qualcosa, ma non può anticipare il lock perché deve essere acquisito da 1
  * Non appartiene a 2PL
* 2PL stretto?
  * Non può
* CSR?
  * Transazioni
    * $t_1$
    * $t_2$
    * $t_3$
    * $t_4$
  * Archi
    * 1-3
    * 1-4
    * 2-4
    * 1-2
    * 3-2
    * 3-4
  * Non sono presenti cicli
  * Appartiene a CSR
* VSR?
  * Si, perché in CSR
* TS?
  * 2 legge t dopo che è stato modificato da 3
  * Se permettiamo le multiversioni, la lettura non è un problema
    * Subito dopo 2 scrive t, che era stato già scritto da 3
  * Non appartiene a TS, nemmeno con multiversioni
