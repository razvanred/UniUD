# Tecnologia di un datbase server centralizzato

Abbiamo visto che funzionalità ha un database server. Ci serve sapere con che meccanismi le realizza.

Perché?
* Capiamo come conviene configurare un database in base a che funzionalità ci interessano di più
* Aiuta a scrivere comandi che possano essere eseguiti meglio
* È utile studiare come funziona
* Alcuni meccanismi vengono estratti e messi a disposizione di altri servizi

Componenti di un server:
1. Ottimizzatore (gestore delle interrogazioni)
   1. Stabilisce le strategie di accesso ai dati
2. Gestore dei metodi di accesso ai dati
   1. Trasforma le richieste dei comandi ad alto livello, in operazioni di lettura e scrittura in memoria secondaria
3. Gestore del buffer
   1. Gestisce il trasferimento delle pagine dalla memoria secondaria alla memoria principale
4. Controllore della concorrenza
   1. Gestisce gli accessi concorrenti
5. Controllore dell'affidabilità
   1. Garantisce il funzionamento in caso di guasti

## Transazioni

Definizione informale: Una unità elementare di lavoro a cui si vogliono associare particolari caratteristiche di correttezza, robustezza ed isolamento.

Un sistema (anche non DB) che mette a disposizione questi meccanismi è detto transazionale.

Si usano due comandi per incapsulare singole operazioni in una transazione:
* Begin
* End

La end è spesso implicita, si capisce dal contesto.
Se sono omesse entrambe, ogni istruzione è una transazione a se stante (modalità autocommit), è quello che accade di solito negli ambienti interattivi.

Quando raggruppiamo istruzioni in una transazione, possiamo vedere l'intera transazione come una unica istruzione.

Esistono due istruzioni speciali:
* Commit
  * Considero quello che ho fatto, definitivo
  * Viene fatta alla fine, quindi non serve la end
* Abort
  * Faccio un rollback a prima di iniziare la transazione
  * Viene fatta alla fine, quindi non serve la end

Nella stessa transazione non posso fare più di una di queste operazioni, non posso fare sia commit che abort, e non posso fare commit e poi aggiungere altri comandi e fare un'altra commit.

Posso scegliere se fare una o l'altra in base ai percorsi di esecuzione dell'applicazione.
Il sistema può forzare un abort se alcune cose vanno storte.

Eseguire il commit garantisce che i cambiamenti vengano memorizzati in modo permanente nella base di dati.

### Proprietà ACID (acide)

Proprietà
* Atomicità
  * Tutta la transazione è una sola operazione
  * O eseguo tutta la transazione, o non eseguo niente
  * Quindi devo essere in grado di disfare la transazione, se succede qualcosa per cui non posso copletarla. Facendo delle undo per annullare le operazioni già fatte
  * Non è possibile che una transazione che ha fatto la commit, non sia registrata permanentemente. A costo di dover rifare (redo) alcune operazioni
    * Il motivo dei redo viene spiegato più avanti, ha a che fare con la gestione del buffer
  * Un abort può avvenire per diversi motivi:
    * La transazione termina con un abort
    * Il sistema non è in grado di portare a termine l'operazione
      * A volte se dopo un certo tempo non riesce a completare un comando (dead lock), si considerà fallita l'operazione
    * Un guasto può abortire tutte le transazioni non completate
    * ...
  * Di norma vanno a buon fine, alcuni sistemi di gestione della concorrenza molto affidabili sono falliti proprio perché abortivano troppo spesso
  * Dopo aver abortito, di solito, l'applicazione fa ripartire la transazione, l'utente vede solo che è più lenta
* Consistenza
  * L'esecuzione non deve violare i vincoli di integrità definiti sulla base di dati
  * Eventualmente si può intervenite od annullare
  * Si può verificare la condizione ad ogni operazione
  * Si può differire il controllo alla commit
* Isolamento
  * L'esecuzione di una transazione deve essere logicamente indipendente da altre transazioni eseguite in contemporanea
  * Deve avere lo stesso effetto che avrebbe avuto se fosse stata eseguita senza altre transazioni concorrenti
  * In particolare, se una transazione fa rollback, non dovrebbero farlo anche le altre
    * Succede quando una transazione legge dati modificati da un'altra incompleta, e questa fa rollback
* Durability (persistenza)
  * È legata alla proprietà di atomicità, vengono entrambe garantite dal controllo dell'affidabilità
  * L'atomicità dice: "o tutto o niente"; la persistenza dice: "se tutto, allora per sempre"

## Gestione del buffer

Il buffer è una vasta porzione di memoria centrale preallocata al DBMS e condivisa tra le transazioni.

Visto che le memoria costano sempre di meno, i buffer diventano sempre più grandi, a volte si può anche inserire l'intera base nel buffer.

Nei casi reali, l'aumento della dimensione del buffer è stato bilanciato da un aumento della dimensione delle basi di dati.

Comunque, +grande=+meglio

Filtra i comandi del gestore dei metodi di accesso per raggiungere il suo obbiettivo.

L'obbiettivo del getore del buffer è mantenere porzioni del DB in memoria centrale per migliorare l'efficienza (il disco è lento), garantendo le proprietà di affidabilità.
Vengono definite delle politiche per garantire queste proprietà, che vengono usate per trasformare le operazioni svolte in memoria centrale (veloci) in operazioni della memoria secondaria.

I suoi compiti sono:
* Caricamento e scaricamento delle pagine
* Accesso alle pagine presenti nel buffer
  * Quando viene richiesto l'accesso ad una pagina, se è già in memoria centrale si accede. Altrimenti carica (ed eventualmente scarica qualcos'altro) e poi permette l'accesso

Deve interagire con lo scheduler per la gestione dei lock durante la concorrenza.

### Organizzazione del buffer

Il buffer è organizzato in pagine che hanno dimensione pari a uno o più blocchi di memoria secnodaria.

Il blocco è l'unità di trasferimento dei dati tra le due memorie.
In genere consideriamo una pagina del buffer grande come un blocco, ed ogni blocco grande diversi kB

### Gestione delle letture e delle scritture

Tutte le operazioni del DB si traduconoin letture e scritture.
Il gestore del buffer gestisce la tempistica delle operazioni per migliorare l'efficienza, può non essere quella richiesta.

In caso di lettura può non essre necessario accedere alla memoria secondaria.

In caso di scrittura, il gestore può ritardare la scrittura, se consintito dalle proprietà di affidabilità del sistema.

Spesso il gestore cambia gli ordini delle operazione senza avvisare i programmatori, per gestire più efficientemente la memoria.

Utilizza le stesse politiche che usa il sistema operativo per la gestione della memoria principale.

Valgono i soliti principi di località e di Pareto
* I dati acceduti di recente hanno maggiore probabilità di essere acceduti di nuovo
  * I dati adiacenti a quello acceduto di recente hanno maggiore probabilità di essere acceduti di nuovo
* L'80% degli effetti è prodotto sul 20% dei dati
  * Il 20% dei dati è acceduto dall'80% delle applicazioni
  * Quindi è più importante memorizzare in centrale questo 20% piuttosto che il  restante 80%

### Direttorio e variabili di stato

Per gestire il buffer vengono msantenute due strutture dati:
* Direttorio
  * Descrive il contenuto corrente del buffer
  * Indica per ogni pagina caricata, il file ed il blocco fisico
* Variabili di stato
  * Un contatore di programmi che usilizzano la pagina
  * Un bit di stato che specifica se è stata modificata

### Primitive per la gestione del buffer

Il buffer manager mette a disposizione delle transazioni, delle primitive di caricamento e scaricamento delle pagine:
* Fix
  * Richiede l'accesso ad una pagina e restituisce un riferimento alla pagina del buffer
* setDirty
  * Indica che la pagina è stata modificata
  * Modifica il bit di stato
* unfix
  * Indica che la pagina non è più in utilizzo
* Force
  * Forza la scrittura in modo sincrono della pagina in memoria secondaria
  * Resetta i bit di stato
  * Viene lanciata da un altro modulo del DBMS, non dalle transazioni

### Primitiva fix

Se non esiston pagine libere, ho due politiche alternative:
* Steal
  * Sottraggo una pagina ad una altra transazione vittima
  * Viene scaricata in memoria per poter caricare la nuova pagina
  * Quando la prima transazione richiederà di nuovo la pagina verrà di nuovo caricata in memoria
* No-Steal
  * Non consento di sottrarre le pagine
  * Viene sospesa la transazione che richiede la pagina finché non si liberano pagine

### Caricamento/scaricamento anticipato

Alcune transizioni dichiarano (o comunque è noto) quali pagine una transazione richiederà in futuro, alcune politiche di gestione della concorrenza prevedono alcune chiamate per questo.

Il buffer può scegliere di caricare in anticipo le pagine che saranno richieste in futuro, o non scaricare pagine libere che verranno chieste in futuro.

Se una pagina è stata liberata, il gestore può scaricarla in anticipo per rendere più efficienti fix successive (che non dovranno scaricare in secondaria la pagina).

### DBMS e file system

Il DBMS si appoggia al filesystem per alcune funzioni, poi crea una sua astrazione dei file, più efficiente pe gli scopi del db.

Primitive usate:
* Creare/Cancellare ed espandere file
* Leggere e scrivere singoli blocchi sui file
  * La gestione dei dati nei blocchi è gestita interamente dal database.
* Apertura e chiusura di un file

Modalità di accesso:
* Diretto
  * Legge un singolo blocco
  * read(fileid, block, buffer)
* Accesso seqeuenziale
  * Accede ad un numero disso di blicchi in modo sequenziale
  * read_seq(fileid, f-block, count, f-buffer)
* Operazioni di scrittura analoghe

## Gestore della concorrenza

Un DBMS deve servire diverse applicazioni contemporaneamente, la qualità di un DBMS viene misurata in transazioni al secondo (tps). Varia da decine a migliaia a seconda dei sistemi.

La serializzazione delle transazioni risolve tutti i problemi di concorrensa. È impesabile serializzare le transazioni, sono troppe, diventerebbe lentissimo.

Per questo serve un gestore della concorrenza (la parte più complicata del sistema) che risolve i problemi di concorrenza. Permettendo a diverse transazioni di avvenire contemporaneamente.

Una esecuzione va bene se produce lo stesso output di una esecuzione seriale.

### Architettura

Le operazioni possono essere di lettura o scrittura dei dati e sono raggruppate in transazioni chiuse da commit od abort.

Il gestore della concorrenza comunica con il gestore dei metodi di accesso ed il gestore delle transazioni per produrre in output le operazini di read e write "sanificate" alla memoria.

Per gestire la concorrenza utilizza una tabella di lock.

### Anomalie

Notazione:
* $r_a(x)$ a legge x
* $w_a(x)$ a scrive x
* $x:=x+1$ aggiorno il valore interno di x

Anomalie:
* Lost update
* Dirty read
* Phantom update
* Inconsistent read
* Phantom insert

#### Lost Update

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
| $x:=x+1$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| $w_1(x)$ |  |
| commit |  |

Eseguo due incrementi, ma il valore registrato aumenta solo di 1.

#### Dirty Read

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
| $x:=x+1$ |  |
| $w_1(x)$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| abort |  |

La seconda transazione scrive un valore incrementato due volte, ma uno dei due incrementi viene abortito dalla transazione 1.

#### Phantom Update

| Transazione 1 | Transazione 2 |
| --- | --- |
| $s:=0$ |  |
| $r_1(x)$ |  |
| $r_1(y)$ |  |
| $s:=s+x$ |  |
| $s:=s+y$ |  |
|  | $r_2(z)$ |
|  | $z:=z+10000$ |
|  | $r_2(y)$ |
|  | $y:=y-10000$ |
|  | $w_2(z)$ |
|  | $w_2(y)$ |
|  | commit |
| $r_1(z)$ |  |
| $s:=s+z$ |  |
| commit |  |

Immaginiamole come operazioni su conti correnti.
La prima transazione prende tre variabili e le somma, ma la terza somma viene fatta dopo che è eseguita la seconda transazione (come se mettessi insieme i soldi di tre conti correnti).
La seconda transazione prende due variabili e decrementa una di quanto incrementa l'altra (come se trasferissi soldi da un conto all'altro).

La terza somma (prima transazione) aggiunge i soldi del terzo conto, ma aggiunge anche i soldi trasferiti dal'altro conto, che erano stati inseriti nella somma già prima del tradferimento.
Il valore della somma è sbagliato.

#### Inconsistent Read

Riguarda transazioni che hanno solo operazioni di lettura, ed eseguono due volte la stessa lettura.

| Transazione 1 | Transazione 2 |
| --- | --- |
| $r_1(x)$ |  |
|  | $r_2(x)$ |
|  | $x:=x+1$ |
|  | $w_2(x)$ |
|  | commit |
| $r_1(x)$ |  |
| commit |  |

Il valore di x cambia tra le due letture da parte della prima transazione.

#### Phantom insert

Consideriamo una transazione che valuta un valore aggregato di tutti gli elementi che soddisfano un predicato. Questo valore viene calcolato due volte nella transazione.

Se tra la prima e la seconda valutazione viene inserito (da una seconda transazione) un elemento che soddisfa il predicato, ottengo due risultati diversi.
Vale anche se invece che un inserimento abbiamo un aggiornamento che soddisfa il predicato (per una tupla che prima non soddisfafa).

Sembra uguale alla lettura inconsistente, ma vedremo che viene risolta in modo diverso perché questa volta la modifica avviene su un valore che non avevo modificato.

### Formalizzazione di transazione

Ometteremo le operazioni di inizio e fine, perché sì.
Assumeremo anche che una transazione non vada a scrivere due volte lo stesso dato.

Definiamo una transazione come sequenza di operazioni di lettura e scrittura. Operazioni della stessa transazione sono caratterizzate dallo stesso indice (vedi notazione).

Operazioni di modifica dei dati interni diventano irrilevanti, interessano solo letture o scritture. Assumiamo che se avviene una scrittura, è avvenuta una qualche manipolazione, altrimenti il DBMS ignorerebbe la scrittura.

Esempio: $t_1:r_1(x)r_1(y)w_1(x)w_1(y)$

Notiamo che l'indice 1 ha poco senso se osserviamo una sola transazione.

### Schedule

Una sequneza di operazioni di lettura e scrittura, relative ad un certo insieme di transazioni concorrenti.
L'ordine in cui trovo le operazioni della stessa transazione è lo stesso ordine della transazione. Posso solo decidere come mescolare le transazioni diverse.

Esempio: $S_1:r_0(x)w_1(x)r_1(x)w_0(x)w_2(x)r_1(y)r_0(y)w_1(y)$

Adesso che le azioni vengono da più transazioni, l'indice diventa importante. Se due azioni hanno lo stesso argomento riguardano gli stessi blocchi di dati.

### Scheduler

Produce lo schedule per evitare le anomalie.
Tiene traccia di tutte le operazioni eseguite da tutte le tranazioni della base di dati e via via decide da quale transazione prendere la prossima operazione.

Inizialmente Assumeremo che lo scheduler sappia in anticipo le operazioni che eseguirà, e l'esito. Nella fase finale dello studio ci libereremo della stessa assunzione.

### Schedule seriale

Uno schedule si dice seriale se pe ogni transazione t, tutte le sue azioni compaiono in sequenza senza essere inframezzate da operazioni di altre transazioni.

### Schedule serializzabile

Uno scchedule è corretto/serializzabile, se produce lo stesso effetto di ***uno*** schedule seriale delle stesse transazioni.

Cosa significa "stesso effetto"? Cambia in base ai criteri di serializzabilità.

### Criterio di equivalenza di vista (VSR)

Definizioni:
* Relazione legge
  * Lega coppie di operazioni di lettura e scrittura
  * La lettura $r_i(x)$ legge da un operazione si scrittura $w_i(x)$ se la scrittura preede la lettura ed in mezzo alle due non c'è nessun'altra scrittura su $x$
* Insieme di scritture finali
  * Un operazione si scrittura è detta finale se dopo quella scrittura non ci sono altre scritture sullo stesso dato

Due schedule sono equivalenti rispetto alle viste se hanno le stesse relazioni legge e insieme di scritture finali.

Uno schedule è serializzabile se è equivalente rispetto alle viste, ad uno schedule seriale.

Esempio:
$$
S_3:w_0(x)r_2(x)r_1(x)w_2(x)w_2(z)\\
S_4:w_0(x)r_1(x)r_2(x)w_2(x)w_2(z)\\
S_5:w_0(x)r_2(x)w_2(x)r_1(x)w_2(z)\\
S_6:w_0(x)r_2(x)w_2(x)w_2(z)r_1(x)
$$

* $S_4$ è seriale.
* $S_3$ è come 4, ma con due letture scambiate, non cambiano le scritture finali e non cambiano le letture. Quindi sono equivalenti, quindi è serializzabile
* $S_6$ è seriale 
* $S_5$ non è equivalente a 4, perché cambia la lettura di $r_1$. Però è equivalente a 6, quindi è serializzabile

Per verificarlo bisognerebbe elencare tutti gli schedule seriali e verificarli uno ad uno, ma gli schedule seriali sono tanti (è NP-completo), quindi non si può fare. Esistono tecniche semplici per scsartarne alcuni.

Gli schedule che causano: perdita di aggiornamento, letture inconcistenti, od aggiornamento fantasma; non sono serializzabili rispetto alle viste.

È un buon criterio, il problema è la complessità.

### Criterio di equivalenza rispetto ai conflitti (CSR)

Una azione si dice in conflitto con un altra se:
* Appartengono a transazioni diverse
* Riguardano lo stesso soggetto
* Almeno una è una scrittura

Elenchiamo i conflitti come coppie ordinate, l'ordine è dettato da quale compare prima nello schedule ed è **fondamentale**.

Due schedule sono equivalenti rispetto ai conflitti se contengono le stesse azioni, e le azioni in conflitto compaiono nello stesso ordine (hanno lo stesso insieme dei conflitti).
Uno schedule è serializzabile rispetto ai conflitti se è equivalente rispetto ai conglitti ad uno schedule seriale.

Si può dimostrare che
* Tutti gli scedule CSR sono anche VSR
  * Supponiamo di trasformare uno schedule in un altro spostando le operazioni all'interno del primo schedule
    * Ogni scrittura è in conflitto con tutte le operazioni di lettura e scrittura sullo stesso soggetto in transazioni diverse
      * Se una scrittura si sposta in mezzo a due operazioni legate da una relazione di lettura (cambiando lettura), o modifica i conflitti o non può essere spostata
        * Se veniva da dopo l'operazione di lettura, cambia l'ordine del conflitto con questa
          * Notare che se la scrittura spostata appartiene alla stessa transazione dell'operazione di lettura non si può eseguire lo spostamento
        * Se veniva da prima della scrittura cambia l'ordine del conflitto con questa
          * Notare che se la scrittura spostata appartiene alla stessa transazione dell'altra scrittura non si può eseguire lo spostamento
      * Se non ha conflitti compare solo in letture della propria transazione e non può influenzare le altre
    * Ogni scrittura finale è in conflitto con tutte le scritture sullo stesso soggetto
      * Se una scrittura non è più finale, si scambia di ordine con un altra scrittura
        * Quindi cambia verso il conflitto
      * Mantenere i conflitti mantiene le scritture finali
      * Se non avesse conflitti, sarebbe finale a prescindere dall'ordine
* Non tutti gli schedule VSR sono CSR
  * Esercizio 7, esame del 22/03/2002
    * $S_1:r_0(x)w_1(x)r_1(x)w_0(x)w_2(x)$
      * C'è un ciclo tra $t_0$ e $t_1$, non è CSR
        * $w_0(x)\rightarrow w_1(x)$
        * $w_1(x)\rightarrow r_0(x)$
      * È equivalente a $S_2:r_0(x)w_0(x)w_1(x)r_1(x)w_2(x)$, è VSR
        * Mantiene la scrittura finale $w_2(x)$
        * Mantiene le letture $(w_1(x),r_1(x))$ e $(\_,r_0(x))$
          * Non ci sono altre letture

Si può verificare usando il grafo dei conflitti:
* I nodi sono transazioni
* Se una operazione di una transazione è in conflitto con una in un altra, metto un arco dalla prima transazione alla seconda

Uno schedule è serializzabile rispetto ai conflitti se e solo se il grafo dei conflitti è aciclico.
Non è più NP-completo.

Dimostrazione:
* $\Rightarrow$ Se CSR allora aciclico
  * Supponiamo uno schedule seriale $S_0:t_1,t_2,t_3,...$
  * Nel grafo dei conflitti esistono solo archi da $t_i$ a $t_j$ in cui $i>j$
    * Non può essere ciclico 
* $\Leftarrow$ Se aciclico allora CSR
  * Se è aciclico esiste un ordinamento topologico
  * Uno schedule seriale che segue l'ordinamento topologico è equivalente a quello originale

Anche se è lineare, è troppo lento per sistemi con centinaia o migilaia di transazioni al secondo.

### La Soluzione (locking a due fasi, 2PL)

***La*** $\mathfrak{Soluzione}$.\
[Playing - "O Fortuna Velut Luna"]

Si utilizza un sistema di locking. Protegge le operazioni di lettura e scrittura con operazioni read_lock, write_lock e unlock.

Tipi di lock:
* Si utilizza un lock condiviso per le letture
  * Più transazioni possono leggere contemporaneamente
* Si utilizza un lock esclusivo per le scritture
  * Non si deve fare niente durante le scritture
  * In alcuni sistemi si usa solo questo
* Si può passare da condiviso ad esclusivo, aumentando il livello del lock

L'acquisizione ed il rilascio devono avvenire rispettivamente prima e dopo le operazioni, ma non necessariamente immediatamente prima e dopo. Si può anticipare l'acqusizione e ritardare il rilascio.

Le transazini sono in genere automaticamente ben formate (lock ed unlok sono inseriti in modo trasparente all'applicazione).
La politica è basata su una tabella dei conflitti. Quando viene chiesto un lock, lo scheduler può decidere se lasciare in attesa la transazione o concedere il lock (si dice che acquisisce il lock). Nel momento dell'unlock, la risorsa viene rilasciata, e se possibile, viene acquisita da un'altra transazione.

Per ogni risorsa viene mantenuta una tabella dei conflitti.

| Richiesta | libero      | r_locked    | w_locked    |
| --- | --- | --- | --- |
| r_lock    | OK/r_locked | OK/r_locked | No/w_locked |
| w_lock    | OK/w_locked | No/r_locked | No/w_locked |
| unlock    | error       | OK/dipende  | OK/libero   |

Le celle della tabella indicano la politica che lo scheduler deve seguire in base allo stato della risorsa (colonna) e il tipo di richiesta (riga). L'unica cosa che non ha senso e genera un errore è l'unlock di una risorsa già libera.
Oltre alla tabella dei conflitti, viene mantenuto un contatore delle transazioni in r_lock.

Questa politica da sola non basta per garantire mutua esclusione. Si separano le operazioni di locking in due fasi:
* Fase crescente
  * Si acquisiscono tutti i lock necessari
* Fase calante:
  * Si rilasciano un po' alla volta tutti i lock

Per forzare questo comportamento si impedisce di acquisire lock dopo averne rilasciato uno.
Notare che formando un grafico con la quantità di lock acquisiti, si ottiene un trapezio, non un rettangolo, perché i lock vengono acquisiti e rilasciati un po' per volta, quando servono.
C'è la possibilità di avere stalli, anche se questa tecnica cerca di evitare la maggior parte dei conflitti.

#### Legame tra 2PL e CSR

2PL è contenuto in CSR.

***Dimostrazione***: Se, per assurdo esistesse uno schedule $S$ tale che $S\in2PL\land s\notin CSR$, seque che il grafo dei conflitti contiene un ciclo $t_1,t_2,...,t_n,t_1$. Se esiste un arco tra $t_1$ e $t_2$, significa che esiste una risorsa su cui le due transazioni operano in modo conflittuale.
Se esite questa operazione conflittuale è necessario che $t_1$ rilasci il lock perché $t_2$ possa accedervi.
Stesso ragionamento per l'arco tra $t_1$ e $t_n$. Per avere questo arco è necessario che l'acquisizione del lock segua l'esecuzione di $t_2$, ma per questo dovrebbe avvnerire dopo il rilascio del primo lock, quindi violerebbe la regola di 2PL.
Se $t_1$ anticipasse il lock che blocca $t_n$ per evitare di rilasciare il lock che blocca $t_2$ prima dell'acquisizione, comunque dovrebbe rilasciarlo prima che sia eseguito $t_n$, evitando il conflitto.

CSR non è contenuto in 2PL, quindi è un sovrainsieme stretto.

***Dimostrazione***: $S_{12}:r_1(x)w_1(x)r_2(x)w_2(x)r_3(y)w_1(y)$. Non contiene cicli, esiste solo un percorso $t_3,t_1,t_2$, quindi appartiene a CSR. Analizziamo i lock:
* 1 aquisisce un r_lock su X
* 1 incrementa il livello a w_lock su X
* 1 deve rilasciare il lock su X per permettere l'esecuzione di 2
* 2 acquisisce il r_lock su X
* 2 incrementa il livello a w_lock su X
* (2 può rilasciare il lock su X)
* 3 acquisisce un r_lock su Y
* (3 può rilasciare il lock su Y)
* !!! 1 non può acquisire il w_lock su Y perché ha già rilasciato X

Proviamo lo scenario alternativo
* 1 aquisisce un r_lock su X
* 1 incrementa il livello a w_lock su X
* 1 deve acquisire un w_lock su Y per poter rilasciare X
* 1 deve rilasciare il lock su X per permettere l'esecuzione di 2
* 2 acquisisce il r_lock su X
* 2 incrementa il livello a w_lock su X
* (2 può rilasciare il lock su X)
* !!! 3 non può acquisire il r_lock su Y, perché è occupato da 1
* 1 deve eseguire prima la scrittura per rilasciare il lock

#### Anomalie

È facile vedere che 2PL risolve le anomalie di perdita di aggiornamento, aggiornamento fantasma e letture inconsistenti.

Per osservare la lettura sporca bisogna rimuovere l'assunzione di commit ed osservare che quando viene abortita la transazione, non viene evitata l'anomalia.
Quindi occorre imporre un nuovo vincolo: che i lock vengano rilasciati tutti assieme *dopo* il commit. In questo caso viene chiamato 2PL stretto, e viene utilizzato comunemente nei sistemi commerciali, ma non sempre in sistemi meno critici, perché è limitante.

L'unica anomalia che non rimuove nemmeno il 2PL stretto è la phantom insert, ma abbiamo detto che deve essere trattata in modo speciale.

#### Phantom Insert

Finora abbiamo definito i lock in base agli oggetti nella base di dati.

Per risolvere l'inserimento fantasma dobbiamo permettere che i lock possano essere definiti in riferimento alle condizioni.
Si chiamano lock di predicato, e se vogliamo evitare l'inserimento fantasma dobbiamo utilizzarli, ma richiedono un approccio ad hoc.

### Timestamp (TS)

È un metodo semplice (nella versione base) meno efficace del precedente, che ha ottenuto un certo interesse in letteratura.

Un timestamp è un identificatore associato ad ogni evento che definisce un ordinamento temporale totale sugli eventi.

Parametri:
* $WTM(x)$ il timestamp della transazione che ha eseguito l'ultima scrittura in x
* $RTM(x)$ il timestamp più grande su x

Lo scheduler riceve richieste $r_t(x)$ e $w_t(x)$ e può decidere se concedere o meno l'operazione. La t p il timestamp della transazione

Politica:
* $r_t(x)$ se $t<WTM(x)$ non concede la lettura
  * Non si può leggere un dato che è strato scritto da una transazione successiva
* $w_t(x)$ se $t<RTM(x)$ non concede la scrittura
  * Non si può scrivere un dato che è già stato concesso ad una transazione successiva

Quando la richiesta viene rifiutata, non implementiamo una sospensione, ma viene forzatamente abortita la transazione.
È molto semplice da implementare e comprendere, ma causa molti aborti. Inoltre, non risolve il problema degli inserimenti fantasma.

Se vogliamo risolvere il problema degli inserimenti fantasma si può aggiungere una qualche tecnica di bufferizzazione delle letture, ma diventa molto complicato, quando l'obbiettivo principale di questo meccanismo è essere semplice.

Per evitare tutti gli aborti, si può aggiungere una operazione di pre-write, che "prenota" la scrittura e ritarda le letture successive a dopo la scrittura.

#### Multiversioni

Un altro metodo è quello delle "multiversioni", che consiste di mantenere diverse copie degli oggetti, mantenendo la versione vecchia dell'oggetto quando viene scritto. Potrà essere letta da transazioni con timestamp minore, il dato vecchio si elimina quando non esistono più transazioni con timestamp minore.

Nuova notazione:
* $WTM_n(x)$ timestamp dell'ultima transazione che ha aggiornato il valore x
* $WTM_k(x)$ timestamp dell'ultima transazione che ha aggiornato il valore x al timestamp k
* $x_n$ ultima versione dell'oggetto x
* $x_k$ versione di x al timestamp k
* $\overline x$ valore letto di x

Nuove politiche:
* $r_t(x)$ viene sempre accettata
  * Se $t\geq WTM_n(x)$ allora $\overline x=x_n$
  * Se $t<WTM_n(x)$ allora $\overline x=x_k$ tale che $WTM_k(x)\leq t\leq WTM_n(x)$
* $w_t(x)$ se $t<RTM_n(x)$ non concede la scrittura
  * Altrimenti $RTM_{n+1}(x)=t$

#### Legame tra TS e 2PL

Recap: VSR è l'insieme più grande, CSR è strettamente contenuto in VSR, 2PL e TS sono entrambi strettamente contenuti in CSR, 2PL stretto è strettamente contenuto in 2PL.\
Aggiunta: TS si interseca con 2PL e co 2PL stretto, ma nessuno contiene TS e TS non contiene nessuno.

Per vedere se uno schedule sta in TS si provano semplicemente i timestamp.
Si dimostra facilmente che se il grafo dei conflitti di CSR contiene cicli, non rispetta l'ordine dei timestamp.

Banalmente esistono schedule che appartengono a TS ma non 2PL (esempio sulle slide).

Banalmente esiste uno schedule seriale con le transazioni in ordine opposto al timestamp che appartiene a 2PL ma non a TS.

Banalmente esistono schedule che stanno in entrambi (esempio sulle slide)

Differenze:
* TS uccide le transazioni che creano conflitti, 2PL le blocca
* In 2PL l'ordine è imposto dai conflitti, in TS dal timestamp di attivazione
* I blocchi possono causare deadlock e lunghi tempi di attesa

### Meccanismi per la gestione dei lock

Il lock manager viene invocato dai processi che intendono accedere alla base di dati, essi eseguiranno read_lock, write_lock ed unlock, con i seguenti parametri:
* `read_lock(R,x,errorcode,timeout)`
* `write_lock(R,x,errorcode,timeout)`
* `unlock(T,x)`

T è un identificativo della transazione, x è l'oggetto, errorcode comunica alla transazione l'esito dell'operazione, e timeout indica il tempo che la transazione è disposta ad attendere prima di acquisire il lock. Se la risorsa è disponibile ovviamente non attenderà prima di concedere il lock, altrimenti la transazione viene messa in attesa.
Quando una risorsa viene rilasciata viene o liberata o concessa al prossimo processo in coda.

Quando il timer scade ha la possibilità di istanziare un nuovo timeout o di abortire. È da considerare che se sono in deadlock e reistanzio un timeout, mantengo il deadlock, quindi è da considerare che potrebbe essere controproducente per il sistema.

Ovviamente la probabilità di conflitti è direttamente proporzionale al numero di processi ed in teoria inversamente proporzionale al numero di risorse nel database. In realtà, sappiamo che vale il principio di Pareto, quindi non sarà proprio inversamente proporzionale.

I lock sono mantenuti in uan struttura, la tabella di lock, che associa ad ogni risorsa due bit di stato, ed un contatore per tenere traccia del numero di processi che accedono alle risorse.

### Granularità dei lock

Si può scegliere il livello a cui operano i lock:
* Base di dati completa
* Tupla
* Tabella
* Valore
* Campo del valore
* ...

Può essere scelto dallo sviluppatore della applicazione o dall'amministratore della base di dati.

Scegliere il livello giusto è difficile, se scegliamo male rischiamo di intaccare le prestazioni (troppo restrittivo) o di non catturare abbastanza anomalie (troppo lasco).

#### Lock gerarchico

Il lock gerarchico è stato introdotto come meccanismo per permettere di gestire più facilmente la granularità delle transazioni.

Di base posso bloccare quello che voglio: base, tabelle, frammenti (porzioni di tabelle), tuple.
In questa generalizzazione per bloccare un oggetto in un certo punto della scala gerarchica devo anche bloccare tutti gli oggetti di gerarchia più bassa che lo compongono.
Quindi per bloccare una tabella devo bloccare tutti i frammenti di essa e tutte le tuple di questi frammenti. In realtà non è detto che si arrivi a bloccare le singole tuple, ci si può fermare ad un livello, dipende dai casi.

Per lo sblocco ovvaimente, funziona al rovescio, rilasciando l'oggetto devo rilasciare tutto ciò che lo compone.

È necessario introdurre delle altre operazioni oltre alle tre classiche:
* XL: lock esclusivo (write_lock)
* SL: lock condiviso (read_lock)
* ISL: intenzione di bloccare in modo condiviso
  * Prima di bloccare la tabella segnalo l'intenzione
  * Blocco le tuple
  * Blocco la tabella
* IXL: intenzione di bloccare in modo esclusivo
* SIXL: Lock condiviso ed intenzione di lock esclusivo
  * Per quei casi in cui viene loccata una risorsa in modo condiviso, ma successivamente verrà bloccata in modo esclusivo

Politiche del gestore dell'affidabilità:
| Richiesta\Stato | ISL | IXL | SL  | SIXL | XL  |
| --------------- | --- | --- | --- | ---- | --- |
| ISL             | OK  | OK  | OK  | OK   | No  |
| IXL             | OK  | OK  | No  | No   | No  |
| SL              | OK  | No  | OK  | No   | No  |
| SIXL            | OK  | No  | No  | No   | No  |
| XL              | No  | No  | No  | No   | No  |

### Blocco critico (dead lock)

È il problema tipico dei sistemi concorrenti in cui si introducono condizioni di attesa. Si verifica quando si forma un ciclo di attese tra le transazioni, in cui nessuna transazione del ciclo può proseguire finché non termina un'altra di quelle del ciclo.

Tecniche:
* Timeout
  * Più utilizzata nei sistemi commerciali
  * Rischia di catturare transazioni che non avrebbero portato a deadlock
  * Bisogna scegliere bene il timeout
    * Troppo altro: Attesa lunga quando si verifica il deadlock
    * Troppo basso: Cattura molte transazioni non in deadlock
* Controllo
  * Periodicamente si lancia una routine che controlla se esistono cicli tra transazioni
  * Se si scelgono delle buone attese tra un lancio e l'altro non è nemmeno troppo onerosa
  * Il timeout è più semplice
* Prevenzione
  * È ovviamente la migliore in teoria
  * È molto complicata da realizzare, quindi di solito non viene usata
  * Causa molti abort perché le soluzioni esistenti sono molto restrittivi
    * Catturano molti schedule che non portano a deadlock
  * È possibile scegliere quale processo uccidere in modo ragionevole si separano due classi di politiche:
    * Interrompenti: Si risolve un conflitto uccidento la transazione che possiede la risorsa (è più prudenziale)
      * Esempio: scelgo la transazione che ha svolto meno lavoro ed uccido quella
      * Può essere efficiente perché spreca meno lavoro
      * Rischia starvation, perché tutte le transazioni nuove muoiono di fronte ad una tansazione vecchia che detiene molte risorse
      * Si può evitare la starvation non resettando il timestamp della transazione quando viene uccisa, così anche se non prosegue diventa più vecchia e ha più priorità
    * Non interrompenti: Si uccide la transazione solo nel momento in cui richiede la risorsa (può essere più invasiva)

## Gestione dell'affidabilità

Si occupa delle proprietà di atomicità e persistenza (delle proprietà ACID).
Fa uso di un file di log persistente che registra tutte le operazioni svolte dal dbms.
Ha un costo non trascurabile per il sistema, ma è accettato perché grarantisce due proprietà fondamentali.

Ogni operazione di scrittura viene protetta tramite un azione sul log, in modo che sia posibile disfare (undo) le azioni a seguito di un malfunzionamento o quasto precedenti al commit; oppure rifare queste azioni qualora la riuscita sia in dubbio e le transazioni abbiano effettuato il commit.
È necessario che il log sia sufficientemente robusto.

Il gestore risiede tra i gestori dei metodi di accesso e delle transazioni, ed il gestore del buffer. Il file di lock è salvato nella memoria secondaria.

Funzioni:
* Realizza i comandi `begin`, `commit` e `rollback`
* Realizza primitive di ripristono dopo malfunzionamenti e guasti
* Riceve le richieste di accesso alle pagine
* Predispone checkpoint e (meno frequenti) dump
  * Per il ripristino dai guasti

***Memoria stabile***: Memorie resistenti ai guasti.

Il concetto di memoria stabile è un astrazione, nessuna memoria è completamente esente ai guasti, dobbiamo metterci in una situazione in cui questa probabilità sia prossima allo 0. Il sistema sovrastante assumera che la memoria stabile sia esente ai guasti.

Come viene realizzata la memoria stabile? RAID 0, oppure backup su nastro, oppure entrambi, coppie di dispositivi per mantenere le stesse informazioni, oppure altro.

### File di log

Il file di Log è un file sequenziale gestito dal controllore dell'affidabilità su un suppporto sufficientemente robusto (memoria stabile). Le azioni sono registrate in ordine temporale, le informazioni non saranno mai aggiunte in una posizione a caso, ma sempre nell'ultimo blocco, e quando questo si riempie, su un nuovo blocco. (Nella termonologia classica è un file append-only).

Il log contiene:
* Record di transazione
  * Per ogni transazione
* Record di sistema
  * Per operazioni di checkpoint e dump
  * I primi meno frequenti delle transazioni, ed i secondi rari

Struttura dei record:
* Record di begin, commit e abort
  * Contengono il tipo di record e l'identificativo della transazione
* Record di update
  * Contengono l'identificativo della transazione ($t_i$) e l'identificativo dell'oggetto modificato ($O_j$)
  * Contiene i valori Before state $BS_i$ e afterstate $AS_i$ che descrivono i valori di $O_j$ prima e dopo dell'operazione
  * Assumeremo che contengano copie complete delle pagine modificate, in realtà conteogono solo informazioni sintetiche
* Record di insert e delete
  * Contengono solo gli stati prima o dopo dell'operazione (a seconda che siano di inserimento o cancellazione)

Notazione:
* $B(T)$ Begin
* $C(T)$ Commit
* $A(T)$ Abort
* $U(T,O,BS,AS)$ Update
* $I(T,O,AS)$ Insert
* $D(T,O,BS)$ Delete

Il sistema fornisce due funzioni primitive:
* Undo
  * Viene usata per disfare un'azione su un oggetto, copiando il valore BS nell'oggetto
  * Nel caso di un inserimento, non c'è un BS, bisogna semplicemente cancellare l'oggetto
* Redo
  * Viene usata per rifare un'azione per assicurarsi che sia andata a buon fine (in caso di guasti dopo una transazione finita con successo)
  * Basta copiare il valore AS nell'oggetto interessato
  * Nel caso della cancellazione, non c'è un AS, busogna semplicemente cancellare di nuovo l'oggetto

L'esecuzione di diversi redo ed undo non cambia il risultato, viene fatto quando non siamo sicuri che sia avvenuta l'operazione, ad esempio se è avvenuto un guasto durante le operazioni di ripristino.
Formalmente si dice che le due operazioni sono idempotenti.

### Operazione di checkpoint

Viene svolta periodicamente in coordinamento con il buffer manager, per registrare tutte le transazioni attive (serve per semplificare il ripristino dopo un guasto).

Procedimento:
* Si sospende l'accettazione di altre operazioni da qualsiasi transazione
* Si trasferiscono in memoria secondaria tutte le pagine del buffer
  * Uilizzando delle operazioni force()
* Si scrive in modo sincrono su file di log il record di checkpoint
  * Contiene gli identificatori delle transazioni attive
  * Tutte quelle terminate prima hanno prodotto effetti sulla memoria secondaria
* Si riprendono le accettazioni

Useremo $CK(T_1,T_2,...,T_n)$ per denotare il record di checkpoint.

### Operazione di dump

Produce un copia completa della base di dati, e viene effettuata in mutua esclusione con tutte le altre transazioni (possibilmente quando il sistema non è operativo.
La copia completa vien memorizzata in memoria stabile, nel file di log viene inserito un record che segnala l'avvenuta operazione.

Useremo $DUMP$ per denotare il record di dump.

### Regole di precedenza

#### Regola di write-ahead-log (WAL)

La parte before state dell'operazione di update deve essere scritta prima di effettuare l'operazione, per poter disfare le operazioni fallite a metà aggiornamento.

#### Regola di commit-precedenza

La parte after state deve essere scritta nel log prima di effettuare il commit. Per poter rifare le operazioni in caso di guasto.

#### Regole semplificate

* I record di log devono essere scritti prima delle operazioni corrispondenti
* I record di log devono essere scritti prima ddell'esecuzione dell'operazione di commit

### Scrittura dei record di commit e di abort

L'esito della transazione viene deciso nel momento in cui scrivo il record nel file di log.

Nel caso dei commit: Tutti i guasti che occorrono prima, causano un undo. Tutti i guasti che occorrono dopo, causano un redo

Nel caso degli abort, la decisione, il redo e l'undo, causano lo stesso comportamento, quindi può essere fatta in modo asincrono senza troppi problemi (tanto si annulla la transazione comunque).

### Protocolli di scrittura del log

Le due regole impongono (uno tra) i seguenti protocolli di scrittura:
* Alterno scritture su log e db
  * Inizio la transazione (e scrivo su log)
  * Scrivo l'update sul log
  * Scrivo l'update sul db
  * Scrivo l'update sul log
  * Scrivo l'update sul sb
  * Scrivo la commit sul log
  * Se si verifica un guasto prima devo annullare tutte le scritture
  * Non servono mai operazioni di redo
* Prima scrivo tutto sul log, poi tutto sulla base
  * Inizio la transazione
  * Scrivo il log
  * Scrivo il log
  * Scrivo la commit
  * Scrivo il db
  * Scrivo il db
  * Se si verifica un guasto non serve nessun undo
  * Serve sempre il redo in caso di guasto dopo il commit, perché non so se le operazioni sono state scritte
* Lascia libertà di scrivere prima o dopo il commit
  * Sembra non dare nessun vantaggio
    * Se il guasto è prima serve sempre un undo
    * Se il guasto è dopo serve sempre un redo
  * È quella usata perché non richiede vincoli aggiuntivi non necesari

### Ottimizzazione operazioni sul log

Le operazioni di log sono molte costose.

Tecniche:
* Scrivere i log relativi ad una transazione, nella stessa pagina in cui si scrive il commit
  * Si scrivono tutti insieme
* Scrivere tutti i record corrispondenti alla stessa pagina contemporaneamente
  * Si tengono le operazioni in attesa per raggrupparle
* Scrittura parallela del file di log (per sistemi con elevato TPS)
  * Complicato se lo vogliamo fatto bene

### Procedure di ripresa

Al verificarsi di un guasto, esiste un insieme di transazioni potenzialmente attive, Delle quali si ignora se abbiano ultimato le azioni sulla base di dati (il buffer manager ha perso le informazioni utili)

Possiamo dividerle in due classi:
* Hanno effettuato il commit
  * Avvenuto dopo il checkpoint, quindi non sappiamo se le operazioni sono scritte sulla memoria
  * È necessario rifare le operazioni
* Non hanno effettuato il commit
  * È necessario disfare le azioni

## Esercizio esame 22/01/2019

Stabilire se i seguenti schedule appartengono VSR, CSR, 2PL, 2PL stretto, o TS

### a

$$S_1:r_3(x)r_1(x)w_4(z)r_4(y)w_2(x)r_2(x)r_3(y)w_1(x)w_4(y)$$

* VSR?
  * Lunica lettura è $w_2(x)r_2(x)$
  * Le scritture finali sono: $w_4(y),w_1(x),w_4(z)$
  * Proviamo a limitare i controlli
    * 2 non può essere eseguita dopo di 1, (scrittura finale)
    * 2 non può essere eseguita prima di 1, (1 non legge da 2)
  * Non è VSR
* Altri?
  * Non appartiene ad altri scheduler, perché non appartiene a VSR

### b

$$S_2:r_2(z)w_1(t)w_3(z)r_2(x)w_4(t)r_1(y)w_2(z)w_3(y)r_1(x)w_4(z)w_2(x)$$

* CSR?
  * Transazioni
    * $t_1$
    * $t_2$
    * $t_3$
    * $t_4$
  * Archi
    * 1-4
    * 2-3
    * 2-4
    * 3-2
  * C'è un ciclo, quindi non è CSR
* 2PL, 2PL stretto, TS?
  * Non può
* VSR?
  * Scritture finali
    * $w_2(x),w_4(z),w_3(y),w_4(t)$
  * Letture
    * Nessuna
  * Proviamo a limitare i controlli
    * 1 deve precedere 4 (scrittura finale)
    * 2 e 3 devono precedere 4 (altra scrittura finale)
    * 2 deve precedere 3 (2 non legge da 3)
    * 1 deve precedere 2 (1 non legge da 2)
    * Unico candidato $t_1,t_2,t_3,t_4$
  * Si ccontrolla che il candidato non causi altri conflitti
    * Non lo fà
  * È VSR

### c

$$S_3:r_4(y)w_1(x)r_1(y)w_3(t)r_2(t)w_2(x)r_2(y)w_4(y)r_1(z)w_4(x)r_4(t)w_3(z)$$

* 2PL?
  * 4 r_lock y
  * 1 w_lock x
  * 1 r_lock y
  * 3 w_lock t
  * 3 unlock t
  * 2 r_lock t
  * 1 anticipa r_lock z
  * 1 unlock x
  * 2 w_lock x
  * 2 r_lock y
  * 2 unlock y
  * 3 unlock y
  * 4 r_lock -> w_lock y
  * 1 legge z (viola il 2PL stretto)
  * 2 unlock x
  * 4 w_lock x
  * 4 r_lock t
  * 1 unlock z
  * !!! 3 non può acquisire la z, perché ha già rilasciato qualcosa, ma non può anticipare il lock perché deve essere acquisito da 1
  * Non appartiene a 2PL
* 2PL stretto?
  * Non può
* CSR?
  * Transazioni
    * $t_1$
    * $t_2$
    * $t_3$
    * $t_4$
  * Archi
    * 1-3
    * 1-4
    * 2-4
    * 1-2
    * 3-2
    * 3-4
  * Non sono presenti cicli
  * Appartiene a CSR
* VSR?
  * Si, perché in CSR
* TS?
  * 2 legge t dopo che è stato modificato da 3
  * Se permettiamo le multiversioni, la lettura non è un problema
    * Subito dopo 2 scrive t, che era stato già scritto da 3
  * Non appartiene a TS, nemmeno con multiversioni
