# Constraint Satisfaction Problem

Un CSP è una tripla $\langle V,D,C\rangle$ dove:
* $V$ è il set di variabili
* $D$ è il set dei domini corrispondenti alle variabili
* $C$ è il set dei vincoli
* Un vincolo $c\in C$ sulle variabili $V_{i_1},...,V_{i_m}$ è una relazione sul dominio $D_{i_1}\times...\times D_{i_m}$
* Una soluzione è un assegnamento $\sigma:V\mapsto D_1\cup...\cup D_n$
* TODO

Esempio 4-regine:
* $V=\{X_1,X_2,X_3,X_4\}$
* $D_1=...=D_4=\{1,2,3,4\}$
* Vincolo orizzontale $X_i\neq X_j$
  * $\{(1,2),(1,3),(1,4),(2,1),(2,3),...\}$
* Vincolo diagonale $|X_j-X_i|\neq j-i$
  * $\{(1,1),(1,2),...\}$

Consideriamo SAT:
* Le variabili di SAT sono le variabili in $\Phi$
* Il dominio di tutte le variabili è $\{0,1\}$
* I vincoli sono degli insiemi di tuple che soddisfano un termine.
* C'è un vincolo per ogni termine

## Constraint solver

Il primo SAT solver È DPLL (Davis Putnam Logemann Loveland).
* Si eseguono una serie di passaggi deterministici intelligenti (*unit propagation*)
* Ad un certo punto non sai più cosa fare ed esegui una scelta non deterministica non-intelligente (*non deterministic choice*)
* Dopo la scelta riprovi la unit propagation
* Quando hai assegnato tutte le variabili e i constraint non sono soddisfatti, fai *backtracking* all'ultima scelta non deterministica e provi l'altra strada

È il primo algoritmo ma è molto potente. È sufficiente per i sudoku.\
La propagazione è una forma di ragionamento.

I constraint solver riprendono le idee di DPLL, ma sono più complessi perché i constraint possono essere più vari di quelli di SAT.\
Alternano stadi di:
* Deterministic constraint propagation
  * È una procedura che trasforma un CSP $P$ in un CSP semplificato $P'$ con le stesse soluzioni
  * $P'$ deve essere più semplice di $P$ (se possibile), con meno variabili e domini ridotti
  * Deve essere veloce perché viene applicato ad ogni nodo dell'albero di ricerca
  * I problemi sono NP-hard, quindi non possiamo aspettarci troppo
  * Non c'è un unico concetto di CP, ogni solver ha la sua. In generale si occupano di riscrivere i vincoli e restringere i domini
* Variable selection e non deterministic assignment

Cercando di generalizzare, possiamo dividere i constraint solver in due tipi principali:
* Completi
  * Da un CSP $P$ lo trasformano in un CSP semplice (forma risolta) equivalente a $P$. Un CSP in forma risolta è una descrizione implicita delle soluzioni
  * Per equivalente, in generale, si intende con le stesse soluzioni, ma i solver a volte aggiungono nuove variabili. In quel caso diremmo che sono equisoddisfacibili se, ignorando il valore la variabile nuova, hanno lo stesso insieme di soluzioni
* Incompleti
  * Il nuovo CSP non è necessariamente in forma risolta

Un constraint solver è basato sull'applicazione consecutiva di *proof rules* $\frac\varphi\psi$, dove $\varphi$ e $\psi$ sono CSP. $\psi$ può contenere nuove variabili.\
Una regola si dice *equivalence preserving* se $Sol(\varphi)=Sol(\psi)|_{FV(\varphi)}$.

### Domain reduction rules

Vogliamo ridurre la dimensione dei domini sfruttando le informazioni date dai vincoli. Le regole sono della forma:

$$
\frac{\varphi=\langle C;D_\in\rangle}{\varphi=\langle C';D'_\in\rangle}
$$

Dove:
* $C$ e $C'$ sono i vincoli
* $D_\in$ e $D'_\in$ sono i domini nella forma del tipo $V_i\in D_i,...$
  * La forma esatta dipende dal tipo di dominio

Se uno dei domini viene ristretto all'insieme vuoto, non esistono soluzioni.

Esempio:

$$
\frac{\langle x<y;x~in~5..15,y~in~0..10\rangle}{\langle x<y;x~in~5..9,y~in~6..10\rangle}
$$

I domini sono indicati nella forma dei range. È facile limitare i range espressi così.

* La constraint propagation è l'applicazione ripetuta di regole di questo tipo.
* Una *derivazione* è una sequenza di applicazioni delle regole.
* Una derivazione finita è:
  * *failing* se l'ultimo CSP è `fail`
  * *stable* se 
  * TODO

## Constraint propagation

### Node consistency

Consistent VS node consistent:
* Un CSP è *consistent* se ammette soluzioni
* Un CSP $P$ è *node consistent* se per ogni variabile $V$ in $P$, ogni vincolo unario su $X$ coincide col dominio di $X$.

È facile ottenere node consistence. Basta applicare la regola seguente ($C$ è un vincolo *unario* su $X$):
$$
\frac{\langle C;X~in~D_X\rangle}{\langle C;X~in~D_X\cap  C\rangle}
$$

Nel caso peggiore serve fare una scansione di dominio e vincolo, quindi ha costo $O(|C|~|D_i|)=O(cd)$

### Arc consistency

Un vincolo binario $C$ sulle variabili $X,Y$ si dice *arc consistent* se:
* $\forall_{a\in D_X}\exist_{b\in D_Y}(a,b)\in C$
* $\forall_{b\in D_Y}\exist_{a\in D_X}(a,b)\in C$

Si può ottenere facilmente ar consistent applicando le due regole:
$$
\frac{\langle C;X~in~D_X,Y~in~D_Y\rangle}{\langle C;X~in~D_X,Y~in~D'_Y\rangle}\\[3ex]
\frac{\langle C;X~in~D_X,Y~in~D_Y\rangle}{\langle C;X~in~D'_X,Y~in~D_Y\rangle}
$$

Nel caso peggiore applicare le regole ha costo $O(|C|~|D_i|~|D_j|)=O(cdd)$. Ma una passata può "esporre" nuove inconsistenze, quindi si deve rifare più volte finché non smette di stringere i domini, al più una volta per ogni variabile e per ogni elemento dei domini.
Quindi in totale risultano $O(ncd^3)$.

Applicando ripetutamente Node consistency e Arc consistency possiamo risolvere alcuni semplici problemi molto velocemente. Ad esempio le 4 regine.

### Bounds consistency

Possiamo indebolire il concetto di arc consistency per ottenerlo più efficientemente, spesso si otterrà lo stesso risultato, ma non sempre.

Un vincolo binario $C$ sulle variabili $X$ e $Y$ è *bounds consistent* se:
* $\exist_{b\in\min(D_Y)..\max(D_Y)}((\min(D_X),b)\in C)$
* $\exist_{b\in\min(D_Y)..\max(D_Y)}((\max(D_X),b)\in C)$
* $\exist_{b\in\min(D_X)..\max(D_X)}((b,\min(D_Y))\in C)$
* $\exist_{b\in\min(D_X)..\max(D_X)}((b,\max(D_Y))\in C)$

Se i domini sono intervalli, sono equivalenti, altrimenti no. È più efficiente da calcolare. Non riesce ad eliminare elementi dal centro del dominio, solo dagli estremi.
Come con la arc consistency possiamo forzarla in loop insieme alla node consistency per propagare i vincoli.

### Hyper arc consistency HAC (Generalized arc consistency GAC)

Si può estendere il concetto di arc consistency (e bounds consistency) ai vincoli non binari.

Nel caso della consistenza binaria ogni elemento rimaneva nel dominio se era supportato da un elemento dell'altro dominio. Nella consistenza non binaria, rimane solo se è supportato da un elemento di ogni altro dominio
* $\forall_{i\in1..m}(\exist_{a_1\in D_1})...(\exist_{a_{i-1}\in D_{i-1}})(\exist_{a_{i+1}\in D_{i+1}})...(\exist_{a_m\in D_m})((a_i,...,a_n)\in C)$

In generale abbiamo complessità $O(ncmd^{m+1})$ per ottenere la consistenza limitando i domini. Può diventare molto lento.

Allo stesso modo possiamo estendere la bounds consistency per vincoli non binari, è più efficiente.

Possiamo sempre spezzare i vincoli non binari in una serie di vincoli ternari equivalenti. Possiamo ottenere meno informazioni dalla propagazione di questi vincoli, ma è molto più veloce, passiamo ad una complessità di $O(ncmd^4)$.

### Path consistency

Ci sono alcuni CSP insoddisfacibili che le altre consistenze non rileverebbero fino alla fine. La *path consistency* rileva alcune di queste situazioni.

Un CSP si dice normalizzato se per ogni coppia di variabili c'è esattamente un vincolo binario.

Possiamo normalizzare un CSP:
* Aggiungendo $C(X,Y)=D_x\times D_Y$, per ogni coppia di variabili senza vincolo binario
* Aggiungendo $C(X,Y)=C'(X,Y)\cap C''(X,Y)$ e rimuovendo $C'$ e $C''$, per ogni coppia con due vincoli binari

Il CSP normalizzato è equivalente a quello di partenza.

L'idea è di seguire dei percorsi diversi nel grafo e cercare di scoprire nuove informazioni.

Sia ul prodotto tra vincoli definito come:
$$
C(A,B)C(B,C)=\{(a,c):\exists_{b\in D_B}(a,b)\in C(A,B)\land(b,c)\in C(B,C)\}
$$

Un CSP è *path consistent* se:
* $\forall_{A,B,C}C(A,C)\subseteq C(A,B)C(B,C)$

Possiamo forzare la consistenza in TODO

Possiamo estendere la path consistency per percorsi di lunghezza $k$, in quel caso si chiama *k-consistency*.

### In generale

Come con la local search, per risolvere i problemi alterniamo constraint propagation e scelte non deterministiche. Quindi in un loop forziamo alcune delle consistenze, possiamo andare avanti finché è completamente consistente o semplicemente fare solo alcuni loop secondo delle euristiche.
A questo punto si assegna ad una variabile uno dei valori dal suo dominio (usando alcune euristiche) e si riprende la propagazione. Se la configurazione risulta insoddisfacibile si fa backtracking e si sceglie un nuovo assegnamento.

A volte invece che assegnare un valore, funziona meglio spezzare un dominio in due sottoinsiemi e provare la propagation. Non è detto che si possa fare.

L'albero delle scelte completo (prop-labeling-tree) prende una forma diversa a seconda delle scelte euristiche. Però le foglie sono sempre uguali.

I solver di solito hanno dei parametri per specificare le euristiche da usare nelle scelte.