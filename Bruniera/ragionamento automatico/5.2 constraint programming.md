# Constraint programming

È un paradigma di programmazione dichiarativo nato da AI (computer vision), per modellare problemi combinatori complessi. La modellazione e soluzione dei problemi è chiaramente separata, ci concentriamo sulla modellazione, qualcun'altro si occupa del solver. Il codice è tipicamente leggibile. La ricerca delle soluzioni è naturalmente parallelizzabile. Le euristiche sono fondamentali. Termina sempre

Per risolvere il problema ci concentriamo sulla ricerca di vincoli sulle variabili.

Breve storia:
* Sketchpad, Ivan Sutherland 1963
  * Primo linguaggio di cp, per la ricostruzione tridimensionale
* Notion of CSP, Ugo Montanari 1972
  * Lo vediamo dopo
* Domain filtering, Waltz 1975
* Late 70s early 80s, constraint propagation
* Late 80s primo constraint based language, CLP
  * È stata introdotta una nozione che ha accelerato la ricerca
  * Global constraint
* 90s, global constraints and other languages
* New millennium, tecniche ibride e standardizzazione
* 10s, Minizinc challenge (breakthrough)
  * Sfida per costruire dei solver che capiscano il linguaggio minizinc
  * Tra i 10s ed i 20s ogni anno abbiamo ottenuto solver più veloci

Affermazioni di Mike Trick:
> If you only knew optimization from 10 years ago, you probably don't have the techniques needed to solve real world sport scheduling problems.

Guarda i video sul powerpoint.

#### Esempio, 4-queens

Posiziona 4 regine su una scacchiera 4x4 in modo che non si attacchino a vicenda.

* Variabili
  * Possiamo avere una variabile per ogni colonna. In ogni colonna ci sarà esattamente una regina.
  * $x_1,...,x_4$
* Dominio
  * Le variabili possono assumere valori da 1 a 4.
  * $D(x_i)=\{1,...,4\}$
* Vincoli (con $i,j=1..4$ and $i<j$)
  * $x_i\neq x_j$ attacchi orizzontali
  * $x_j-x_i\neq j-i$ attacchi diagonali

Se abbiamo un'assegnamento di variabili che rispetta tutti i vincoli, è una soluzione

## CSP e spazio di ricerca

Il Constraint Satisfaction Problem (CSP) è definito da:
* Insieme delle variabili $V=\{v_1,...,v_n\}$
* Insieme dei domini $D=\{d_1,...,d_n\}$
* Insieme di vincoli $C$ sulle variabili in $V$
* Si cerca una (o tutte) le soluzioni ammissibili: un assegnamento $\sigma:V\mapsto d_1\cup...\cup d_n$

Una sua variante è il Constraint Optimization Problem:
* Insieme delle variabili $V$
* Insieme dei domini $D$
* Insieme di vincoli $C$ sulle variabili in $V$
* Una funzione $f:d_i\times...\times d_n\mapsto\mathbb A$
* Si cerca una soluzione ammissibile che minimizzi $f$

La soluzione si trova nel set degli assegnamenti possibili $d_i\times...\times d_n$, questo insieme è lo *spazio di ricerca* (search space). Se i domini sono tutti finiti, anche lo spazio di ricerca è finito, quindi è sempre decidibile.

Lo spazio di ricerca è solitamente rappresentato come un *albero di ricerca*.

Il problema 4-queens ha uno spazio di 256 assegnamenti. Possiamo organizzarle su un albero di 4 livelli con quattro ramificazioni.

Non possiamo eseguire una ricerca naive sullo spazio, perché cresce esponenzialmente. Questo approccio si chiama generate-test (assomiglia a guess-verify).\
Un modo un po' più efficace è l'assegnazione parziale, che si ferma appena trova un conflitto con un vincolo, senza proseguire fino alla foglia.

Le tecniche non naive principali sono:
* Local search
* (Integer) linear programming
* Translation to SAT
* Constraint Programming
* Answer Set Programming

### Traduzione COP $\Leftrightarrow$ CSP

#### COP $\Rightarrow$ CSP

Per trasformate un problema CSP in un problema COP (o viceversa) basta una riga

Definisci una funzione $f$ costante

#### CSP $\Rightarrow$ COP

Approssima un limite superiore di $f$.

Assumendo che $f$ mappi in $\N$ segui una ricerca esponenziale sul valore di $f$.

### NP-hardness di CSP

Ricordiamo 3-coloring: Dato un grafo, vogliamo colorare i nodi di tre colori diversi in modo che i nodi adiacenti abbiano colori diversi

Riduciamo 3-coloring a CSP: Ogni nodo è una variabile con dominio i tre colori. Ogni arco corrisponde ad un vincolo $x_i\neq x_j$.

## Metodi di risoluzione di CSP

### SAT

Abbiamo un insieme di variabili, ed una formula proposizionale $\Phi$ in FNC di queste variabili.\
Il problema è verificare l'esistenza di un'interpretazione delle variabili che soddisfi $\Phi$.

Possiamo provare a risolverlo rappresentando $\Phi$ come uan formula aritmetica, o provare a rappresentare le congiunzioni come insiemi di tuple. Ma resta difficile.

Possiamo risolvere CSP trasformandolo in SAT e poi utilizzando un SAT-solver. Ogni anno si tiene una competizione per creare il migliore SAT-solver.
La riduzione potrebbe non essere immediata.

Esempio, riduzione delle n regine:
* Non possiamo usare $\log(n)$ variabili per rappresentare ogni riga delle regine, modellare il problema è possibile ma molto difficile, anche se sembra compatto.
* Per ogni colonna introduciamo n variabili
  * $X_i\Rightarrow Z^i_1,...,Z^i_n$
  * Almeno una di quelle deve essere vera $Z^i_1\lor...\lor Z^i_n$
  * Non possono essere vere due diverse $(\lnot Z^1_1\lor\lnot Z^1_2)\land...$ (nota i pedici)
  * Possono essercene due sulla stessa riga $(\lnot Z^1_1\lor\lnot Z^2_1)\land...$ (nota gli apici)
  * Non possono essercene due sulla stessa diagonale $(\lnot Z^1_1\lor\lnot Z^2_2)\land...$ (nota gli entrambi)
  * Si traduce il testo in formato DIMACS
    * Il file inizia con `p cnf <numero variabili> <numero di congiunzioni>`
    * Ogni riga è una congiunzione, contengono l'indice di ogni variabile nella congiunzione, l'indice è negativo se la variabile è negata. La riga termina con 0
* Poi bisogna tradurre la soluzione nel problema originale, a volte è difficile, per le regine è facile.

### Local Search

Tipicamente si occupa di COP.
Abbiamo un albero con tutte le scelte possibili e configurazioni finali sulle foglie, di cui alcune saranno soluzioni. Ci si sposta con un approccio random tra le foglie *senza* risalire fino alla radice.\
Ci si muove in delle foglie "neighbor", che non sono vicini ma facili da raggiungere.

Si parte da una foglia, si calcola il costo, si sceglie una prossima foglia e si passa a quella solo se costa meno. Per avere la soluzione esatta bisognerebbe andare avanti all'infinito, me invece ci fermeremo ad un timeout. Non possiamo avere la soluzione perfetta.\
A volte bisogna passare ad una foglia con costo maggiore.

Montecarlo, simulated annealing, particle swarm, genetic algorithm. Sono tutti local search con diversi modi di scegliere la prossima foglia.

Si può applicare a CSP, bisogna trovare una funzione di costi che dica quanto si è distanti dalla soluzione.\
Ad esempio per le regine si possono contare (in modo grossolano) il numero di attacchi.

I vincoli sono separati in due categorie:
* Hard constraint
  * Devono essere sempre soddisfatti
* Soft constraint
  * È desiderabile soddisfarli, ma non obbligatorio

Servono:
* Un algoritmo per scegliere la prima soluzione
  * Spesso può essere stupido
  * 4-queens: 1,2,3,4
* Una funzione per trovare i neighbor
* Un modo per scegliere se passare o meno al vicino
  * Hill climbing: solo soluzioni migliori
  * Montecarlo: se non migliora scelgo con probabilità 0.5
  * Simulated annealing: come montecarlo ma la probabilità diminuisce nel tempo
  * Tabu search: come SA ma tengo una lista di alcune soluzioni recenti per evitare di tornare indietro

### (Integer) Linear Programming

C'è anche il quadratic programming, che è più veloce.

Nel LP abbiamo un sistema lineare e vogliamo minimizzare una funzione influenzata dal sistema. LP è polinomiale.

$$
c_1X_1+...+c_nX_n\\[3ex]
\begin{aligned}
a_{1,1}X_1+...+a_{1,n}X_n &&\mathrm{op} \ && b_1\\
\vdots\\
a_{m,1}X_1+...+a_{m,n}X_n &&\mathrm{op} && b_m\\
\end{aligned}
$$

Nel *Integer* LP le soluzioni possono essere solo lineari. Diventa NP-completo.

Si usano diversi metodi per risolverle, un esempio è *Branch and Bound*. Si lancia l'algoritmo per LP che trova una soluzione non intera, a turno si sceglie una variabile e si guardano gli interi di quella variabile più vicini. Si sceglie uno dei punti e si aggiunge quella retta al sistema e si rilancia LP.\
Quando si trova un punto intero o non ho più soluzioni LP, si torna indietro e si sceglie un branch diverso. Si continua solo se la soluzione LP minimizza la funzione meglio di quella già trovata.

Lo vediamo meglio a ricerca operativa.