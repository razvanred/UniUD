# Generatori di lexer/parser

## BNF Converter (BNFC)

Il BNFC è un compilatore che genera un lexer e un parser da una grammatica in BNF etichettata, per un certo linguaggio target tra cui Java, C e Haskell.

Una grammatica bnf etichettata è una sequenza di regole formattate come `etichetta . NonTerminale ::= (Terminale | NonTerminale)`.

BNFC genera:
* Lexer (come programma per un altro strumento, flex/alex)
* Parser (come programma per un altro strumento, bison/happy)
* Un tipo di dato di sintassi astratta
* Un serializzatore per la sintassi astratta

Ha alcuni tipi di non terminale predefiniti:
* `Integer` interi
* `Double` virgola mobile
* `Char` singoli apici
* `String` doppi apici
* `Ident` identificatori

Escluso `Ident`, gli altri sono esposti al linguaggio target con il tipo corrispondente.

Altre feature:
* Semantic dummies
  * Un'etichetta può essere `_` quando la sua produzione ha un solo non terminale (ed eventuali terminali), non verrà generalizzato un tipo per quella produzione.
* Indexed non-terminals
  * Quando un non terminale finisce con un intero, viene usato per la precedenza con gli altri non terminali con lo stesso nome
* Macro
  * Sono abbreviazioni per un gruppo di regole che vengono generate, magari per fare qualcosa su più livelli di precedenza

Esempio:

```bnfc
AddOp. E ::= E "+" E1;
_. E ::= E1;

MulOp. E1 ::= E1 "*" E2;
_. E1 ::= E2;

NegOp. E2 ::= "-" E3;
_. E2 ::= E3;

IntVal. E3 ::= Integer;
Identifier. E3 ::= Ident;
_. E3 ::= "(" E ")";
```

La `coercion NT INT` macro semplifica la produzione di regole per la precedenza nelle espressioni. Con questa possiamo facilmente espandere l'esempio di prima come:

```
Add. E ::= E "+" E1;
Sub. E ::= E "-" E1;

Mul. E1 ::= E1 "*" E2;
Div. E1 ::= E1 "/" E2;
Mod. E1 ::= E1 "%" E2;

Pow. E2 ::= E3 "^" E2;

Neg. E3 ::= "-" E4;

Int. E4 ::= Integer;
Id. E4 ::= Iden;
Float. E4 ::= Double;

coercion E 4;
```

La `terminator NT T` macro define le appropriate regole per il simbolo `NT` per produrre sequenze anche vuote di `NT`, in cui ogni `NT` è terminato da `T`.
Opzionalmente possiamo aggiungere `nonempty` se la sequenza deve essere piena. Se come terminale usiamo `""` otteniamo una sequenza di terminali contigui.

```
terminator Stm ";";

[]. [Stm] ::= ";" ;
(:) [Stm] ::= Stm ";" [Stm];


---

terminator nonempty Stm ";";

(:[]). [Stm] ::= Stm ";" ;
(:). [Stm] ::= Stm ";" [Stm];
```

Nota: Il nome `[Stm]` è un nome qualsiasi, è solo più chiaro. Le etichette `(:),(:[])` funzionano perché il linguaggio target è Haskell. Comunque le regole non sono esattamente così, ma avremo qualcosa di simile.

La macro `separator` è simile a `terminator`, però l'ultimo elemento della lista non ha il separatore, vengono inseriti solo tra due elementi.
Anche questo ha il `nonempty`. Se come terminatore usiamo `""` è identico a `terminator`.

La macro `rules` produce un set di regole con etichette generate automaticamente. Possiamo usarlo quando non ci interessa il nome dell'etichetta.

```
rules Type ::= Type "[" "]"  | "float" | "int";

Type1. Type ::= Type "[" "]";
Type_float. Type ::= "float";
Type_int. Type ::= "int";
```

La macro `comment T` genera le regole per trattare il testo tra `T` e `$` come commento. La macro `comment T T'` genera le regole per trattare il testo tra `T` e `T'` come commento.

BNFC genera di default, un parser per ogni non terminale della grammatica (per usarli come simboli iniziali). Possiamo usare il pragma `entrypoint Stm, Exp, ... ;` per definire quali parser sono effettivamente generati. Non tutti i target (bison) la supportano, in quel caso fa quello che vuole.

Estendiamo ancora il linguaggio di prima, *aggiungendo* queste regole per le espressioni booleane:

```
Or. BoolExpr ::= BoolExpr "||" BoolExpr1;

-- copia dal sito, sono tante
```

Dobbiamo stare attenti perché il parser viene prodotto in modo meccanico ignorante. Se scrivi grammatiche che non sono veramente LALR, o che sono ambigue o non deterministiche, il parser viene prodotto comunque, ma non fa quello che vogliamo.
Se è ambigua, ci sono sempre stringhe che per pura fortuna vengono parsate correttamente, ma ce ne sono anche alcune che non lo saranno.
Quando la grammatica non va bene, happy riporta un conflitto, ma sceglie una soluzione e produce comunque il programma incorretto.

## Alex

Alex è un generatore di lexer, non di parser. Prende in input una descrizione di token e produce il programma haskell che esegue la tokenizzazione.

Struttura del sorgente
* `{ <header del modulo haskell> }`
* `<direttive>`, in particolare `%wrapper "<nome>"` per specificare alcuni codici ausiliari prodotti da alex
* `<definizione macro>`
* `<identificatore> :-`
* `<definizioni di token>` nella forma `<regex> {<codice haskell>}`
* `{<codice del modulo>}` opzionale

### Macro

Le macro sono di due tipi: quelle che definiscono insiemi di caratteri e quelle che definiscono espressioni regolari.

* `$<identificatore> = <set>`, un set può essere:
  * `char` Un singolo carattere unicode
  * `char-char` un range di caratteri
  * `.` tutto tranne lf
  * `set1 # set2` sottrazione tra insiemi
  * `[sets]` unione di set
  * `~set` complemento del set
  * `[^sets]` complemento di unione
  * `$ident` espande con a definizione di un altro set
* `@<identificatore> = <regex>`
  * `set` un carattere dal set
  * `@ident` espande una regex
  * `"..."` matcha la sequenza esatta
  * `r1 r2` r1 seguito da r2
  * `r1|r2` o r1 o r2
  * `r*` 0 o più occorrenze
  * `r+` 1 o più occorrenze
  * `r?` 0 o 1 occorrenze
  * `r{n}` n occorrenze
  * `r{n,}` n o più occorrenze
  * `r{n,m}` da n a m occorrenze

### Definizioni di token

Sono nella forma `<regex> {<azione>}` dove l'azione è un pezzo di codice haskell, che dovrebbe restituire il valore da inserire nella lista di token. Se un token vogliamo scartarlo mettiamo `;` al posto di `{...}`

Dobbiamo assicurarci che le azioni siano tutte dello stesso tipo. Alex non se ne accorge se sbagliamo, però poi non compila ghc.

Per ogni regola, alex cerca quella che matcha il prefisso più lungo, rimuove l'input ed esegue l'azione.
Se due regole matchano una stringa lunga uguale, segue l'ordine della definizione.

### Wrapper

Il wrapper "basic" è il più semplice, si aspetta che l'azione sia una funzione di tipo `String -> t` ed il lexer risultante sarà una funzione `String -> [t]`.