# Introduzione

Ripete le stesse cose introduttive del corso di linguaggi della triennale e la magistrale.

I parser si dividono tra:
* Top down
  * Non deterministici, con backtracking: sono più generali ma meno efficienti
  * Predittivi, senza backtracking: si possono fare solo per alcuni linguaggi 
* Bottom up
  * Partono dalle foglie
  * Deterministici
  * Più complicati dei predittivi, ma più generali
  * Più usati

## Parser top down non deterministici

Parte dalla radice ed espande il simbolo non terminale più a sinistra.
Se l'algoritmo si blocca (non ha più produzioni da espandere, ma ha ancora non terminali) fa backtracking.

```
# per ogni non terminale A
function parse_A () {
    forall production A -> X1 ... Xn {
        try{
            parse_X1()
            ...
            parse_Xn()

            # se è riuscito a parsare tutti si ferma con successo
            return A
        }
    }

    # se nessuno è arrivato alla fine, fallisce
    fail()
}

# parte dal simbolo iniziale S
function parse() {
    return parse_S()
}
```

Potrebbe non terminare per alcune grammatiche.

Una grammatica è *ricorsiva sinistra* se esiste una produzione (anche non immediata) $E \stackrel+\rightarrow E\alpha$ (nota che è sempre $E$ il non terminale), questo algoritmo non termina, continua a riprovare questa produzione.

Si può eliminare la ricorsione sinistra:
* Nel caso immediato $A\rightarrow A\alpha|\beta$
  * $A\rightarrow\beta A'$
  * $A'\rightarrow\alpha A'|\epsilon$
* Nel caso non immediato
  * Eliminiamo tutte le $\epsilon$ produzioni ed i cicli $A\stackrel+\Rightarrow A$
  * Definisco un ordine $\leq$ tra i non terminali
  * Facendo variare $A$ dal minimo al massimo e $B$ dal minimo ad $A$, riscrivo le eventuali produzioni $A\rightarrow B\alpha$, sostituendo $B$ con tutte le sue possibili produzioni

Se riscritte in questo modo, funziona per tutte le grammatiche.

## Parser top down predittivo

Elimina il non-determinismo, non è più così generale.
Invece di scegliere una produzione "qualsiasi" usa un lookahead di $n$ caratteri per decidere quale utilizzare.\
Non tutte le grammatiche ammettono un parser di questo tipo. Chiamiamo $LL(n)$ la classe delle grammatiche che lo ammettono.

$$
LL(1)\subset LL(2)\subset...\subset CF
$$

* Esamina la stringa da sinistra
* Cerca la leftmost derivation partendo dal simbolo iniziale

Si considerano principalmente le grammatiche $LL(1)$.

Supponiamo di avere un parser $LL(n)$ e produzioni del tipo $A\rightarrow \alpha\beta_1|\alpha\beta_2$ dove $|\alpha|=n$ sono problematiche, perché per decidere la produzione da applicare servirebbe un lookahead di $n+1$ caratteri.\
Queste produzioni si possono eliminare riscrivendole come $A\rightarrow\alpha A'$ e $A'\rightarrow\beta_1|\beta_2$.

Per predire la produzione da utilizzare bisogna conoscere con quali terminali iniziano le produzioni derivate da $A$. Quindi è utile sapere con quali *terminali* iniziano le stringhe derivate dai *non terminali* che compaiono nelle produzioni.

Definiamo una funzione $FIRST(\alpha)$ che data una generica stringa di terminali e non terminali, restituisce l'insieme dei terminali con cui inizia la stringa.

$$
FIRST(\alpha)=\begin{cases}
\{a\}&\alpha=a\\
\bigcup\limits_{A\rightarrow\beta}FIRST(\beta)&\alpha=A\\
\{\epsilon\}&\alpha=\epsilon\\
FIRST(X_1)&\alpha=X_1...X_n\land\epsilon\notin FIRST(X_1)\\
FIRST(X_1)\cup FIRST(X_2...X_n)&\alpha=X_1...X_n\land\epsilon\in FIRST(X_1)
\end{cases}
$$

La soluzione minimale si ottiene costruendo $FIRST$ ricorsivamente

Quando $A\rightarrow\alpha$ ed $\epsilon\in FIRST(\alpha)$, è utile sapere quali terminali possono seguire $A$ in una derivazione. Definiamo l'insieme $FOLLOW(A)$ come l'insieme delle $b$ per cui esiste una produzione $S\stackrel*\rightarrow\alpha Ab\beta$.

Quindi cerchiamo i più piccoli insiemi tali che:

$$
\mathrm{eof}\in FOLLOW(S)\\
FOLLOW(A)=\bigcup\limits_{B\rightarrow\alpha A\beta}FIRST(\beta)\cup\bigcup\limits_{B\rightarrow\alpha A\gamma~:~\epsilon\in FIRST{\gamma}}FOLLOW(\gamma) \setminus \{\epsilon\}
$$

Si parte da un $FOLLOW$ iniziale e si ampliano gli insiemi ricorsivamente finché non smettono di crescere.

Una grammatica $G$ è $LL(1)$ sse per ogni coppia di produzioni $A\rightarrow\alpha|\beta$:
* $FIRST(\alpha)\cap FIRST(\beta)=\emptyset$
* $\epsilon\in FIRST(\alpha)\Rightarrow FIRST(\beta)\cap FOLLOW(A)=\emptyset$

In un parser predittivo $LL(1)$ in un istante scelgo la produzione $A\rightarrow\alpha$ tale che il carattere di lookahead compare all'interno di $FIRST(\alpha)$, che per le condizioni precedenti, se esiste è unica (se non esiste rifiuta la stringa).

Per eseguire efficientemente il parsing utilizziamo una parsing table (implementiamo un automa a stack).
Sulle righe mettiamo i non terminali, sulle colonne il simbolo di lookahead.
In ogni cella è indicata la produzione da applicare (scelta usando il $FIRST$ e se contiene anche $\epsilon$ anche il $FOLLOW$).

|   | id | + | * | ( | ) | $ |
| - | - | - | - | - | - | - |
| $E$ | $E\rightarrow TE'$ | | | $E\rightarrow TE'$ | | |
| $E'$ | ... | ... | ... | ... | ... | ... |
| ... | ... | ... | ... | ... | ... | ... |

Il programma ha una stringa di input, uno stack, e la parsing table.
* All'inizio lo stack contiene $\$ E$ (l'EOF ed il simbolo iniziale), ed il lookahead è il primo simbolo dell'input
* Ad ogni step legge il non terminale in cima alla pila ed il lookahead ed applica la produzione indicata nella tabella.
* Applicare la produzione significa sostituire il simbolo nello stack con la sua produzione (che contenga terminali o non), senza spostare l'input
  * La sequenza delle produzioni applicate è l'output del parser
* Quando la cima dello stack è un non terminale, se è uguale al lookahead, rimuovo il simbolo dallo stack, e passo al simbolo successivo nell'input
  * Se non combaciano fallisce il parsing
* Se arrivo a finire lo stack, accetto la stringa
  * Visto che lo stack finisce con $\$$, finisce insieme all'input

Questo parsing è efficiente, ma sono pochi i linguaggi $LL(1)$. E se scegliessi i linguaggi $LL(K)$? Il preprocessing diventerebbe più difficile e la tabella più grande, il resto rimarrebbe simile (non uguale).
La quantità di grammatiche utili però non è molto diverso, non vale la pena di utilizzare $LL(K)$.

## Error recovering

Un compito importante dei compilatori è generare messaggi d'errore, ma anche proseguire nella compilazione, per trovare altri errori.

Un errore può essere:
* Lessicale
  * Rilevati dal lexer
* Sintattico
  * Rilevati dal parser
* Semantico
  * Es: errori di tipo
* Logico

La gestione degli errori è principalmente un sistema di euristiche.

Tecniche:
* Panic mode: Se lo stack e l'input non combaciano (terminali diverse o non terminali senza produzioni) salto caratteri in input finché non si sincronizza di nuovo
  * Possiamo immaginarlo come considerare che ci sia un errore lessicale locale e passare oltre
* Phrase level recovering: Definisco delle procedure specifiche da eseguire per ogni errore rilevato
  * Ad esempio sostituire una virgola con un punto e virgola
  * Provo a risolvere errori comuni
* Error production: Aggiungo regole di parsing per generare programmi con errori
  * Genero i messaggi di errore dall'albero di parsing ottenuto

### Panic mode per $LL(1)$

Se $A$ è in cima allo stack e non posso andare avanti, cerca $FOLLOW(A)$ nell'input, e rimuovi $A$ dallo stack.

Se una grammatica è "gerarchica" (comandi separati da `;`, blocchi contenuti tra parentesi, etc.), si possono cercare i delimitatori e proseguire.

Si può anche non saltare l'input e cercare un simbolo che ha il lookahead nel $FIRST$

### Phrase recovery per $LL(1)$

Si indica la procedura da eseguire nella tabella di parsing. Non serve indicarne una in tutte le celle, si può anche lasciare che fallisca e basta.

Alcune procedure classiche sono:
* Sincronizzazione come in panic mode
* Saltare il non terminale e basta
* Sostituire un non terminale
* ...