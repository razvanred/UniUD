# Middleware

## Caratteristiche delle API di IPC che un MW gestisce

Possiamo suddividere le varie API di IPC in due grandi categorie:
* Sincrone
  * Send bloccante: si aspetta che il destinatario riceva i dati (TCP)
  * Receive bloccante: si aspetta che arrivino dei dati
  * Sono necessarie entrambe per comunicazione sincrona
* Asincrone
  * Send non bloccante: si invia e si passa subito ad altro (UDP)
  * Receive non bloccante: se non ci sono dati da leggere si riporta e si passa oltre
  * Spesso si ha send non bloccante ma receive bloccante, conta comunque come asincrono

Per indicare il destinatario non possiamo usare IP e porta perché viola la trasparenza di locazione.\
Per gli IP basta usare un DNS, per la porta si usa un servizio port mapper, che ascolta sempre sulla stessa porta, e comunica le porte su cui ascoltano diversi servizi.

Affidabilità.

Ordinamento.

## Message Passing Interface (MPI)

È uno dei primi middleware (1994), pensato per scambiare messaggi tra i nodi di un cluster HPC in modo molto ottimizzato.
Progettati per essere semplici, pratici, efficienti, e portabili.

## External Data Representation

Diversi linguaggi su diverse macchine rappresentano i dati in modo diverso.
Serve un modo per rappresentare i dati in modo comune (marshaling/unmarshaling).

Il primo formato era XDR della Sun, ora i più comuni sono XML e json.
JSON è molto usato su web services REST. Mentre XML è richiesto dai servizi SOAP (lo schema va incluso in WSDL).

### Remote Object Reference

Per sistemi come CORBA serve un sistema cross-platform per rappresentare oggetti univocamente in un sistema distribuito.

Servono di sicuro ip e porta. Il tempo e la porta identificano univocamente il processo.
* 32 bit: IP
* 32 bit: porta
* 32 bit: time
* 32 bit: numero dell'oggetto
* Interfaccia dell'oggetto

Non va bene il metodo di CORBA, perché non rispetta la trasparenza di località. Ci sono soluzioni (proxy, informare dei cambiamenti) ma non sono ottimi.

## Comunicazione di gruppo

### Multicast

Lo conosciamo, non è molto supportato.

Utilizzerebbe UDP, che non ha garanzie sull'ordine e sulla ricezione.

### Overlay network

Abbiamo alcune macchine connesse alla rete pubblica. Quando devono comunicare, invece che "parlare" direttamente con il destinatario, ogni macchina parla solo con alcune macchina prestabilite, che inoltreranno il messaggio per farlo arrivare alla destinazione.
Questo aumenta la latenza ovviamente, ma permette di usare algoritmi di routing intelligenti per ottimizzare il traffico, o per implementare altre funzionalità avanzate.

Tecniche:
* Hash table distribuite
* P2P file sharing
* CDN
* molte altre...

Caso di studio, Skype (pre-microsoft):
* Skype nasce come applicazione VoIP p2p nel 2003
* È una rete p2p composta da nodi e super-nodi
* Quando il client si collega, esegue il login su un server principale, che assegna un super-nodo (a questo punto si può chiudere la comunicazione col server principale)
  * Dovrebbero essere scelti in base alla locazione, ma non è immediato stabilirla
  * I super-nodi possono essere "riallocati" se la localizzazione risulta sbagliata
* Tutto il traffico delle chat viene instradato attraverso i super-nodi con un loro algoritmo di routing
* I super-nodi sono dei normali client che vengono promossi a super-nodi in base a certi criteri
  * Se hai un IP pubblico, se hai una buona connessione, se stai collegato molto tempo, etc.
* Il traffico per questi nodi deve essere cifrato end to end, inizialmente non lo era
* Il video invece era diretto perché era pesante gestire il traffico video per i client

## Remote invocation

Come comunicano due processi?

### Request-reply

È il modello più semplice, si adatta perfettamente al modello client server. Ovviamente è sincrono.
Tipicamente il client esegue una chiamata `doOperation` bloccante, mentre il server eseguirà delle `getRequest` bloccanti, eseguirà la richiesta del client, e restituirà il risultato con una `sendReply`.
Ovviamente possono cambiare, ma generalmente sono varianti di queste.

Importante notare che quando il client sta eseguendo, il server è in attesa e viceversa.

Lo usa HTTP, e di conseguenza quasi ogni altra cosa.

Possono essere implementate sopra UDP e TCP
* UDP
  * Più veloce ed efficiente
  * Non serve inizializzare la connessione
  * Non serve controllo di flusso (se i dati sono piccoli)
* TCP
  * Più affidabile
  * Messaggi di dimensione illimitata
  * Non serve reimplementare gli ACK

Bisogna tenere conto di alcune sottigliezze:
* Failure model
  * Se usiamo TCP non ci sono problemi, in UDP si possono perdere richieste o risposte, o possono arrivare in disordine
  * Il processo può morire
  * Client e server potrebbero rimanere bloccati in attesa di un pacchetto, in caso di guasti
* Se non ottengo una risposta?
  * Aspetto e riprovo
* Se si è persa la risposta?
  * Come si accorge il server che la nuova richiesta è un duplicato?
  * Come gestisce i duplicati? Deve tenere le risposte già mandate? Quante?
* Le operazioni non richiedono gestione dei duplicati (tipo)
  * Eseguirle tante volte non cambia il risultato
  * Esempio: leggi x; assegna x=3; ...
  * Non-esempio: incrementa x; (elimina x, circa dipende); ...
  * Le operazioni REST tendono ad essere idempotenti
  * Non è detto che si possano usare solo quelle

I protocolli di scambio request-reply sono:
* R: il client chiede
* RR: il client chiede, il server risponde
* RRA: il client chiede, il server risponde, il client manda ACK

### Chiamata di procedura remota rpc

Vogliamo rendere RR più astratto, le richieste di operazioni diventano simili a chiamate a procedure locali.

Call semantics:
* Maybe
* At least once
* At most once

RPC cerca di assomigliare quanto più possibile a chiamate locali, però bisogna ricordare alcune differenze importanti:
* Maggiore latenza
* Si possono mandare solo dati serializzabili
* Le operazioni possono fallire a causa della rete

Sul lato del client, il modulo main chiama una funzione stub che nasconde il marshaling e le chiamate al modulo di rete.\
Sul lato server, il modulo di rete riceve le richieste, le passa al dispatcher che organizza le richieste, eventualmente le passerà ad una funzione stub che esegue l'unmarshaling e chiama la funzione che esegue la computazione.\
Il risultato della computazione viene restituito alla funzione stub che esegue il marshaling e restituisce il dato al dispatcher che eventualmente invierà la reply attraverso il modulo di rete.\
La funzione stub del cliente riceve la reply, esegue l'unmarshaling e restituisce il risultato al modulo main.

RPC è stato inventato da SUN per implementare NFS. Hanno inventato un loro linguaggio XDR per rappresentare i dati e definire programmi che sarebbero spezzati tra client e server. Compilare questo linguaggio genera automaticamente le funzioni stub ed il dispatcher.

RPC include un servizio broker/port mapper su una porta fissa per informare i client dei servizi offerti e della porta che li offre.

Problemi:
* Traffico in chiaro
* L'autenticazione era basata su UID e GID del client...
* È stato reso più sicuro usando kerberos

### Distributed objects + Remote Method Invocation RMI

È l'estensione ad oggetti dell'RPC. Si lanciano metodi sugli oggetti, ma questi oggetti potrebbero trovarsi in un altra macchina.

Un oggetto espone un'interfaccia remota, che permette di specificare quali metodi sono accessibili remotamente.

Serve un modo per identificare una specifica istanza di un oggetto in una macchina. Per farlo si usano le remote reference, che sono a loro volta un oggetto, e che possono essere passate tra le macchine.

Implementazione e dettagli:
* Istanziazione remota
  * L'oggetto viene istanziato dalla macchina in cui risiede la classe
  * La reference remota viene passata alla macchina che ha richiesto l'istanza
  * La macchina in cui risiede la classe non ha la reference, non può accedere
* Garbage collection
  * Non posso rimuovere gli oggetti a cui non ho reference locali, perché potrebbero avere reference remote
  * Bisogna fare un GC distribuito
  * RC non funziona, se si guasta una macchina non può decrementare il contatore
  * Spesso si usa il leasing, la macchina con la reference deve periodicamente rinnovare la reference
* Eccezioni
  * Una chiamata potrebbe alzare eccezioni inaspettate. Ad esempio istanzio un oggetto e si alza un errore di rete
* Oggetti persistenti
  * Alcuni oggetti possono essere memorizzati in forma serializzata sul disco per essere mantenuti a lungo ed essere recuperati quando vengono invocati di nuovo
* Oggetti migrabili
  * L'oggetto può essere spostato tra le macchine
  * Utile per bilanciare il carico, quando una macchina non riesce più a gestirlo lo scarica ad una libera
  * Serve un modo per informare i referenti che l'oggetto si è spostato
    * Se ho la lista gli scrivo (difficile)
    * Altrimenti tengo un proxy per la prossima volta che viene invocato e informo chi invoca

Le RMI mantengono le stesse semantiche delle RPC:
* Maybe, non ritrasmetto in caso di errore
* At least once, ritrasmetto e viene rieseguita
* At most once, ritrasmetto ed il server fa caching delle risposte

Similmente all'RPC: Quando il client riceve una reference la mantiene in un modulo che fa da runtime, e si occupa della gestione delle reference (ad esempio il leasing e la garbage collection).
Al codice invece viene passato un oggetto fittizio "proxy" che implementa l'interfaccia remota, e quando vengono chiamati i suoi metodi invoca il marshaling e il modulo di gestione delle reference.
Sul server viene mantenuto l'oggetto vero, e un runtime si occupa di tenere traccia dei leasing, la garbage collection, e le istanze remote.

Esempio, garbage collection di java:
* Il server tiene traccia dei proxy
* Quando un proxy viene creato bisogna avvisare il server
* Quando il garbage collector del client rimuove il proxy informa il server
* Quando il server non ha più proxy registrati dealloca l'oggetto
* Usa il leasing per gestire i client guasti
* Possono esserci race condition

Java estende il classico RMI con le callback. Per fare programmazione asincrona ed evitare il polling.

## Comunicazione indiretta/disaccoppiata

### Space and time uncoupling

| | Time coupled | Time uncoupled |
| - | - | - |
| **space coupled** | Devo sapere a chi invio un messaggio, e il destinatario deve esistere in quel momento. (message passing, remote invocation) | Devo sapere a chi mando, ma non serve che esista nel momento dell'invio (e-mail) |
| **space uncoupled** | Non ho bisogno di sapere chi è il destinatario, ma deve esistere in quel momento. (IP multicast) | Non serve conoscere il destinatario ne che esista in quel preciso momento |

### Comunicazione di gruppo

Un esempio è l'IP multicast, è un metodo di comunicazione in spazio disaccoppiato. Il middleware deve gestire l'appartenenza ai gruppi e come eseguire il recapito.
Il programmatore non deve conoscere tutto questo, invia e basta e chi appartiene al gruppo in quel momento riceve il messaggio.

Utile per diramare informazioni.

Possiamo dividerlo tra:
* Gruppi di processi
  * Poco più alto del multicast
  * Si occupa del recapito di messaggi
  * Il middleware tipicamente non fa marshaling, invia vettori di byte
* Gruppi di oggetti
  * Quando viene chiamato un metodo del gruppo viene chiamato su tutti gli oggetti del gruppo
  * Chiaramente gestire i risultati è un problema, tipicamente sono void, o prendo il primo, o implemento altri sistemi di aggregazione

Un gruppo può essere chiuso o aperto:
* Chiuso, comunicano solo i partecipanti
* Aperto, chiunque può inviare informazioni al gruppo

Il middleware deve occuparsi del Group Membership Management. Deve occuparsi di far entrare ed uscire i membri, ma anche di rilevare i guasti.
Deve informare gli altri membri dei cambiamenti.\
Mantenere tutta la lista dei membri equivale ad avere un sistema sincrono. Su gruppi grandi si usa un approccio probabilistico (protocollo gossip). Su alcune reti ad hoc o mobili si usano approcci specifici per la rete.

Multicast affidabile:
* Integrità: tutti devono ricevere lo stesso messaggio (at most once)
* Validità: tutti i messaggi inviati arriveranno prima o poi
* Accordo: tutti i processi ricevono tutti i messaggi

Ordinamento in multicast:
* FIFO
  * Rispetta l'ordine di chi li ha inviati
  * È il più facile
  * È il minimo che possiamo garantire
* Causale
  * Rispetta l'ordine causa-effetto
  * Se il mittente ha gia ricevuto x, deve arrivare a tutti dopo di x
  * Se è causale è anche FIFO
* Totale
  * I messaggi sono ordinati nell'ordine in cui sono stati inviati
  * È il più difficile
  * Protocollo ISIS (nome infelice)

Caso di studio JGroups:
* Permette di creare gruppi multicast di processi java
* Funzionalità principali:
  * Creazione ed eliminazione dei gruppi (LAN o WAN)
  * Entrare ed uscire dai gruppi
  * Rilevazione e notifica di ingressi ed uscite
  * Rilevazione dei membri guasti
  * Invio e ricezione
  * In LAN gira su UDP unicast
* La classe principale è JChannel
  * Si usa per collegarsi ai gruppi, scambiare messaggi e impostare listener
* I membri si scambiano Message con array di byte
* Lo stack di rete è configurabile con dei moduli prefatti o definiti dal programmatore
  * Modulo causale
  * Modulo per frammentazione
  * Modulo UDP (posso usare altri protocolli)
  * Moduli di diagnostica
  * Moduli che simulano problemi di rete (per testing)
  * Etc...
* A livello più alto (sopra il JChannel) è ancora configurabile con dei building blocks
  * Blocchi dispatcher RPC
  * Blocchi per sistemi di notifiche
  * Etc...

### Publish Subscribe (Pub-Sub)

Nel modello pub sub, chiamato anche sistema ad eventi distribuiti, il middleware fornisce un delle api per pubblicare dei messaggi di un "argomento", che arriveranno a tutti quelli che hanno "espresso interesse" a quel argomento.\
È una generalizzazione della comunicazione a gruppi.

Sono usati in:
* Sistemi finanziari
* Sistemi real time
* Sistemi cooperativi
* Ubiquitous computing
* Applicazioni di monitoraggio
* Pubblicità di Google

I modelli pub sub funzionano bene in sistemi eterogenei ed in sistemi asincroni (perché sono disaccoppiati nello spazio).

Forniscono diversi gradi di garanzia sulla consegna:
* Real time
  * È molto reattivo, ma fa meno garanzie
* As soon as possible
* All or nothing (tutti ricevono tutto contemporaneamente)
  * È più difficile

I processi possono inviare al sistema dei comandi per:
* `publish(e1)` Pubblicare un messaggio di un argomento `e1`
* `subscribe(e1)` Iscriversi all'argomento `e1`
* `advertise(e1)` Creare l'argomento `e1`
* (`unsubscribe(e1)` Disiscriversi da `e1`)

Quando il sistema riceve un comando `publish(e1)` invierà un comando `notify(e1)` a tutti i processi che in quel momento sono iscritti all'argomento `e1`.

#### Implementazioni ad alto livello

Ci sono molti modi di implementare (ad alto livello) questo modello. Il modello più basso è quello basato sui canali. I publisher scrivono su un canale specifico, i subscriber ricevono tutti gli eventi del canale.
È molto semplice, non permette di usare filtri, lo usava CORBA.

Un modo più sofisticato è quello basato su topic. Ogni messaggio contiene anche un topic, gli iscritti scelgono a quali topic sono interessati.
I topic possono essere gerarchici, iscriversi ad un topic di livello alto ti fa arrivare le notifiche dei sotto-topic.

Una generalizzazione dei topic sono i modelli basati su contenuto. Il sistema va a guardare il contenuto del messaggio e se contiene delle parole importanti lo assegna a quel topic.\
Gli hashtag sono di questo tipo.

Un approccio basato ad oggetti è il modello type based. Un subscriber si iscrive a delle classi di messaggi e riceve tutti i messaggi che combaciano con quelle classi. Possono essere più o meno granulari.

Object of interest, i subscriber sono informati dei cambiamenti nello stato di un oggetto.

Concept based, sono come i content based, ma guardano alla semantica non la sintassi del messaggio.

Su sistemi speciali tipo il financial trading, si usano implementazioni più sofisticate dove le notifiche vengono inviate secondo delle regole complesse caricate nel sistema.

#### Implementazioni vere

Il modo più semplice di implementare questo sistema è con un server centralizzato che implementi l'intero servizio. Non è il massimo, non scala.

Per scalare meglio, si sostituisce il server centralizzato con una rete broker (in overlay) di server. A cui sono collegati publisher e subscriber.

Ora che abbiamo la rete overlay serve un modo per distribuire i messaggi, il modo banale è il flooding, ma non scala. Un modo un po' migliore è quello di avere una rete ad albero in modo da gestirla in modo gerarchico.\
Si possono avere anche reti più generali con algoritmi di routing più complessi.

Questo sistema era un approccio "ibrido" dove i client sono separati dai server, ma i server sono p2p.
È più raro, ma ci sono anche implementazioni dove l'intero sistema è p2p e non si distinguono i client dai server.

#### Architetture

Strati:
* Matching
* Event routing
  * Flooding, Filtering, Rendezvous, Informed gossip
* Rete overlay
  * TODO
* Rete
  * Multicast, Broadcast, etc...

### Code di messaggi

L'idea è di inserire un intermediario tra delle macchine "produttori" e "consumatori". I messaggi inseriti in queste code intermediarie sono persistenti finché non sono consumati.\
Sono disaccoppiati sia nello spazio che nel tempo.

I produttori eseguono una `send` su una coda ed il messaggio resta lì. I consumatori possono prendere il messaggio dalla coda con una `receive` bloccante.
Quando il consumatore legge il messaggio viene consumato, solo un consumatore riceverà uno specifico messaggio.

Alcuni sistemi supportano un'operazione `poll` ne bloccante ne consumante, per leggere (se ci sono) alcuni messaggi dalla coda senza consumarli.

Non è detto che tutti i produttori e consumatori abbiano accesso a tutte le code.

Sono facili da implementare sopra un DBMS quindi spesso sono preimplementate dai sistemi database. I DBMS sono molto scalabili.

Bisogna stabilire delle politiche di accodamento, di solito FIFO ma potrebbe essere basato su priorità od altro.
I consumatori potrebbero non volere il primo messaggio in coda, ma selezionarne uno in base a dei metadati.

Caso di studio, IBM WebSphere MQ:
* Centralizzato
  * Il client ha un oggetto proxy che espone l'interfaccia di una coda
  * Il proxy comunica con un oggetto stub sul server centralizzato che inserisce i messaggi in delle vere code
  * Altri clienti e servizi con un proxy per la stessa coda possono produrre e consumare i dati.
* Topologia Hub-and-spoke
  * Nelle aziende ci sono molti applicativi diversi (uno per il magazzino, uno per il gestionale, etc...), bisogna farli comunicare
  * Le varie parti dell'azienda (spoke) comunicano tramite un sistema di code (hub)
  * Ogni parte quando ha bisogno di qualcosa da un'altra pate lo scrive su una delle code ed un servizio della parte interpellata lo leggerà e soddisferà la ricerca
  * L'azienda concorderà (dovrebbe) un formato e ogni parte dell'azienda deve adattarlo al proprio applicativo


Esiste uno standard aperto per implementare i le code di messaggi: AMQP (advanced message queueing protocol). È un protocollo, non un set di API, ma ci sono molte implementazioni anche buone.
È interoperabile ed agnostico.

### Distributed shared memory (DSM)

Non si usa mai nella realtà.

Uno dei vari sistemi di IPC dei sistemi operativi è la memoria condivisa. Una porzione dello spazio di indirizzi virtuali di due processi è mappato sulla stessa porzione di memoria fisica.
È un metodo di comunicazione molto veloce che evita di dover copiare buffer in giro.\
Si vuole adattare questo modello ai sistemi distribuiti. (Questo cozza con la definizione che abbiamo usato noi di sistemi distribuiti, comunque non è l'unica).

Non è un modello client server. È ovviamente un'astrazione su un sistema di scambi di messaggi.

Alcune delle "regole" che siamo abituati a dare per scontate non sono garantite, in particolare leggi sugli ordering.

Viene usata nei sistemi NUMA (macchine multi-processore).

Sono un esempio di time-uncoupling perché la comunicazione deve essere gestita in modo asincrono.

### Tuple Space

I processi comunicano inserendo tuple in uno spazio comune. Disaccoppiato nello spazio e nel tempo.

Lo spezio è esposto come un multiinsieme, i client hanno le primitive:
* `write` aggiunge una tupla, non bloccante
* `take` seleziona una delle tuple indicando il valore di alcuni campi ed i tipi di altri. la prima tupla che matcha è consumata e viene restituita al processo, se non matcha niente si blocca
* `read` come take ma non consuma

Implementarlo bene in un vero sistema distribuito è difficile.

Una delle tante implementazioni commerciali è JavaSpaces. Fa parte di un framework per IoT (jini). Implementa uno spazio *persistente* dove posso mettere e richiedere oggetti. Aggiunge la funzione takeIfExist (non bloccante), e notify (per implementare una callback).
Aggiunge anche un lease time per far scomparire l'oggetto dopo un certo tempo anche se non è stato preso da nessuno.