# Sistemi lineari di equazioni

Si possono rappresentare sistemi lineari come prodotto di matrici:

$$
\displaylines{\begin{cases}
\begin{aligned}
&a_{1,1}x_1+...+a_{1,n}x_n&&=b_1\\
&\vdots&&= \vdots\\
&a_{m,1}x_1+...+a_{m,n}x_n&&=b_m
\end{aligned}
\end{cases}
\\
\\
\\
x_1
\begin{pmatrix}
a_{1,1}\\
\vdots\\
a_{m,1}
\end{pmatrix}
+...+x_n
\begin{pmatrix}
a_{1,n}\\
\vdots\\
a_{m,n}
\end{pmatrix}=
\begin{pmatrix}
a_{1,1}&...&a_{1,n}\\
\vdots&\ddots&\vdots\\
a_{m,1}&...&a_{m,n}
\end{pmatrix}
~
\begin{pmatrix}
x_1\\
\vdots\\
x_n
\end{pmatrix}=
\begin{pmatrix}
b_1\\
\vdots\\
b_m
\end{pmatrix}}
$$

Se $x$ esiste, $b$ è una combinazione delle colonne di $A$. Quindi, l'equazione ha soluzioni se e solo se $b$ appartiene allo span di $A$.

Se le colonne di $A$ sono linearmente indipendenti, il sistema ha una sola soluzione, altrimenti o infinite o nessuna.

Verranno considerate solo matrici quadrate.

## Condizionamento

### Condizionamento su $b$

Introduciamo una perturbazione del termine noto $\delta b=\tilde b-b$, ed il rispettivo errore $\epsilon_b=\frac{||\delta b||}{||b||}$.\
Sia $\tilde x=x+\delta x$ la soluzione in aritmetica esatta del problema perturbato:

$$
\begin{aligned}
& A\cdot(x+\delta x)=b+\delta b &\\
& \Rightarrow A^{-1}\cdot(A\cdot(x+\delta x))=A^{-1}\cdot(b+\delta b)\Rightarrow x+\delta x=A^{-1}\cdot(b+\delta b) & [b=A\cdot x,~ x=A^{-1}\cdot b]\\
& \Rightarrow\delta x=A^{-1}\cdot\delta b &
\end{aligned}
$$

Sapendo che $\mathrm{cond}(A)~ \epsilon_b\geq\epsilon_x$, si vuole ottenere $\mathrm{cond}(A)$:

$$
\begin{aligned}
& \epsilon_x=\frac{||\delta x||}{||x||}=\frac{||A^{-1}\delta b||}{||x||} & [\text{definizione di }\epsilon_x]\\
& \leq\frac{||A^{-1}||~ ||\delta b||}{||x||} & [\text{regola 4 delle norme}]\\
& \leq\frac{||A^{-1}||~ ||\delta b||~ ||b||}{||x||~ ||b||} & [\text{moltiplicare e dividere per }||b||]\\
& \leq||A^{-1}||~ \frac{||b||}{||x||}~ \epsilon_b & \left[\frac{||\delta b||}{||b||}=\epsilon_b\right]\\
& =||A^{-1}||~ \frac{||Ax||}{||x||}~ \epsilon_b & [b=Ax]\\
& \leq||A^{-1}||~ \frac{||A||~ ||x||}{||x||}~ \epsilon_b & [\text{regola 4 delle norme}]\\
& =||A^{-1}||~ ||A||~ \epsilon_b
\end{aligned}
$$

$\mathrm{cond}(A)=||A^{-1}||~ ||A||$ è chiamato numero di condizionamento ed è $\geq1$. Quando il numero di condizionamento è molto maggiore di 1 è mal condizionato, quando è piccolo è ben condizionato.

### Condizionamento su $b$ ed $A$

Introduciamo la perturbazione $\delta A$ della matrice $A$ ed il rispettivo errore $\epsilon_A=\frac{||\delta A||}{||A||}$, si assume che $A+\delta A$ non sia singolare.\
Si può dimostrare che:

$$
\epsilon_x\leq\frac{||A||~ ||A^{-1}||}{1-||A||~ ||A^{-1}||~ \epsilon_A}(\epsilon_b+\epsilon_A)=\frac{\mathrm{cond}(A)}{1-\mathrm{cond}(A)\epsilon_A}(\epsilon_b+\epsilon_A)
$$

### Osservazioni

Il condizionamento da una misura dell'accuratezza del risultato. Calcolare il condizionamento può essere più costoso che calcolare la soluzione, perché usa l'inversa.

## Trasformazioni

Risolvere un sistema generico è molto costoso, quindi si cerca un modo di trasformare un sistema in uno equivalente ma più facile da risolvere.\
In particolare si moltiplicano a sinistra sia $A$ che $b$ per una stessa *matrice invertibile* $M$.

$$
M\cdot A\cdot x=M\cdot b\iff x=(M\cdot A)^{-1}\cdot M\cdot b=A^{-1}\cdot M^{-1}\cdot M\cdot b=A^{-1}\cdot b
$$

Si usano:

* *matrici di permutazione*: $P$ ottenute scambiando righe dell'identità, rappresentano scambi di righe
* *matrici di scaling*: $D$ ottenute da matrici diagonali, rappresentano scaling di righe

### Casi facili

* $A$ diagonale:\
  Se $A$ è diagonale, tutte le $n$ equazioni del sistema sono nella forma $a_{i,i}x_i=b_i$, quindi è più veloce risolverle individualmente con $x_i=\frac{b_i}{a_{i,i}}$.
* $A$ triangolare:\
  Se $A$ è triangolare, ogni equazione coinvolge solo una variabile in più della precedente, e la prima sarà nella forma $ax=b$. È più veloce risolverle in ordine.
* $A$ è ortogonale:\
  Una matrice $A$ si dice ortogonale se la sua trasposta è la sua inversa $A\cdot A^T=I$.\
  È più veloce perché non serve calcolare l'inversa e basta fare il prodotto $A^T\cdot b$.

## Errore e residuo

Il vettore residuo $r$ della soluzione $\tilde x$ di un sistema è una misura dell'errore della soluzione, ed è definito da:

$$
r=b-A\cdot\tilde x
$$

Se la matrice $A$ è non singolare allora:

$$
||x-\tilde x||\iff||r||=0
$$

>>>>>>>>>> Dato gato tito, tuto tipo quato

Sapendo che:

$$
\begin{aligned}
& b=A\cdot x\Rightarrow||b||=||A\cdot x||\leq||A||~ ||x||\\
& \Rightarrow\frac1{||x||}\leq\frac{||A||}{||b||}
\end{aligned}
$$

Si può stimare l'errore relativo usando le norme:

$$
\begin{aligned}
& r=b-A\tilde x=A\cdot x-A\cdot \tilde x=A\cdot(x-\tilde x) & [b=A\cdot x]\\
& \Rightarrow||x-\tilde x||=||A^{-1}r||\leq||A^{-1}||~ ||r||\\
& \Rightarrow\frac{||x-\tilde x||}{||x||}\leq||A^{-1}||\frac{||r||}{||x||} & [\text{dividere entrambi per }||x||]\\
& \Rightarrow\frac{||x-\tilde x||}{||x||}\leq||A^{-1}||~ ||A||\frac{||r||}{||b||} & \left[\frac1{||x||}\leq\frac{||A||}{||b||}\right]\\
\\
& \Rightarrow\frac{||x-\tilde x||}{||x||}\leq\mathrm{cond}(A)\frac{||r||}{||b||} & [\mathrm{cond}(A)=||A^{-1}||~ ||A||]
\end{aligned}
$$

Un piccolo residuo relativo $\frac{||r||}{||b||}$ assicura un piccolo errore relativo, quando la matrice è ben condizionata. Lo stesso vale per l'errore relativo rispetto a $||\tilde x||$, dove $\tilde b=||A||~ ||\tilde x||$:

$$
\frac{||x-\tilde x||}{||\tilde x||}\leq\mathrm{cond}(A)\frac{||r||}{||A||~ ||\tilde x||}
$$

Si può osservare una relazione tra il residuo $r$ e la stabilità all'indietro $E$:

$$
\begin{aligned}
& (A+E)\cdot\tilde x=A\cdot\tilde x+E\cdot\tilde x=b\\
& r=b-A\cdot\tilde x=E\cdot\tilde x\\
& ||r||\leq||E||~ ||\tilde x||\Rightarrow\frac{||r||}{||\tilde x||}\leq||E||\\
& \Rightarrow\frac{||r||}{||A||~ ||\tilde x||}\leq\frac{||E||}{||A||} & [\text{dividere entrambi per }||A||]\\
\end{aligned}
$$

Se il residuo è grande, l'algoritmo è instabile all'indietro. Un algoritmo stabile fornisce un piccolo errore solo se la matrice è ben condizionata.

## Raffinamento iterativo

Dalle soluzioni approssimate $\tilde x$ di un sistema, si può costruire un sistema $A\cdot e=r$ che ha come soluzione il vettore $e=x-\tilde x$ :

$$
r=A\cdot(x-\tilde x)=A\cdot e\\
$$

Dalla soluzione approssimata $\tilde e$ si ottiene una raffinazione di $\tilde x$:

$$
\displaylines{
x=e+\tilde x\\
\tilde{\tilde x}=\tilde e+\tilde x}
$$
