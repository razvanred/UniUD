# Analisi dell'errore: Il calcolatore

## Numeri reali

I numeri reali sono infiniti ed in generale sono necessarie infinite cifre $d_i$ per la loro rappresentazione in base $B\geq 2, B\in \N$.

$\R = \{0\} \cup \{\pm (d_1B^{-1}+d_2B^{-2}+...) * B^p | d_1\in N,0\leq d_i \leq B-1, d_i$ non definitivamente $=B-1, p\in \Z\}$

### Numeri normalizzati

il sistema di numeri di macchina è il sottointieme $F:=F(B,t,p_{\min},p_{\max})$ di $\R$ definito da:

$F = \{0\} \cup \{\pm (d_1B^{-1}+d_2B^{-2}+...+d_tB^{-t}) * B^p | 0\leq di\leq B-1, i=1,...,t,d_1\neq 0,-p_{\min}\leq p\leq p_{\max}\}$

ed è carratterizzato da 4 interi:
* $B$: base
* $t$: numero di cifre di mantissa
* $p_{\min}, p_{\max} > 0$: limitazioni inferiori e superiori dell'esponente

proprietà:
* l'insieme è finito e la sua cardinalità è: $1+2(B-1)B^{t-1}(p_{\max}+p_{\min}+1)$
* il più piccolo numero positivo normalizzato è: $realmin = B^{-p_{\min}-1}$
* il più piccolo numero positivo normalizzato è: $realmax = B^{p_{\max}}(1-B^{-t})$
* non sono uniformemente distribuiti
* sono equispaziati solo tra due potenze successive di $B$

### Numeri denormalizzati

l'insieme di macchina $F$ può essere eseteso includento anche i numeri denormalizzati, che sono i reali con cifra significativa principale $d_1=0$ e con esponente $p=-p_{\min}$

tali numeri sono distribuiti tra $\pm realmin$ e lo $0$, e sono equispaziati con spaziatura pari a $B^{-p_{\min}-t}$

### Approssimazione dei numeri reali

Solitamente i calcolatori laborano in una base $B\neq 10$, pertanto anche il numero che è rappresentabile con un numero finito di cifre decimali, può richiedere un numero infinito di cifre per la rappresentazione in base diversa

```
0.3 B10 = 0.0100110011001... B2
```

Dobbiamo definire un'applicazione $fl:\R\rightarrow F$ che:
* segnala un overflow se $|x| > realmax$ 
* segnala un underflow se $|x| < realmin$. (in alcuni sistemi ) $fl(x)$ viene posto a 0
* $fl(x) = x$ se $x\in F$
* altrimenti scelgo una delle seguenti strategie:
  * troncamento: la mantissa viene troncata alla t-esima cifra
  * arrotondamento: $fl(x)$ è il numero macchina più vicino a $x$. Se è equidistante da due numeri macchina si sceglie una delle seguenti strategie
    * round away from zero: $fl(x)$ è il numero più grande dei due
    * round to even: $fl(x)$ è il numero con la cifra $d_t$ pari

### Precisione di macchina

L'accuratezza di un sistema di numeri macchian ha una definita precisione di macchina $u$

Ogni numero reale nel range di $F$ darà approssimato da $fl(x)$ con un errore relativo maggiorato dalla precisione di macchina $u$

$\epsilon x = \frac{|fl(x)-x|}{|x|} \leq u$

* $u := B^{1-t}$ nel caso di troncamento
* $u := \frac{B^{1-t}}{2}$ nel caso di arrotondamento

### Standart IEEE-DP (1985)

$F(2,53,1021,1024)$

* $realmin = 2^{-1022} \simeq 2.2251E-308$
* $realmax = 2^{1024}(1−2^{−53}) \simeq 1.7977E+308$
* $u = 2^{-53} ~=1.11E-16$ (arrotondamento alla cifra pari)

L'esponente può assumere valori speciali:
* $p=-1022, d_2...d_{53} = 0$ rappresentazione dello 0
* $p=-1022, d_2...d_{53} \neq 0$ numeri denormalizzati
* $p=1025, d_2...d_{53} = 0$ infinito
* $p=1025, d_2...d_{53} \neq 0$ NaN

### Aritmetica di macchina

Non è detto che la somma (o altre operazioni elementari) di due numeri di macchina abbia come risultato esatto un numero di macchina

* Lo shift della mantissa necessario per la somma può causare la perdita anche di tutte le cifre di mantissa
* Il prodotto di due mantisse contiene fino a $2t$ cifre è il risultato esatto può non essere rappresentabile o causare overflow
* Il quoziente di due mantisse può contenere più di $t$ cifre (anche infinite) e non essere rappresentabile

#### modello di calcolo

Per analizzare gli errori di arrotondamento servono delle assunzioni sull'accuratezza delle operazioni elementari. Utilizziamo in esame questo modello

* Tutte le operazioni elementari sono calcolate in modo da avere $err_{op} = \frac{|x_1fl(op)x_2)-(x_1(op)x_2)|}{|x_1(op)x_2|} \leq u$, $op=\pm, /, *$
* Si considera valida anche per $op=\sqrt{}$
* Il modello asserisce che il valore calcolato è "buono" quanto il valore ottenuto arrotondando il valore esatto. $x_1fl(op)x_2 = fl(x_1(op)x_2)$

#### limiti dell'aritmetica di macchina

L'aritmetica di macchian non soddisfa tutte le proprietà dell'aritmetica esatta. 

* Si conservano le proprietà commutative di somma e prodotto
* Non si conservano:
  * le proprietà associative di somma e prodotto
  * la proprietà distributiva della somma rispetto al prodotto
  * la legge di cancellazione

Pertanto, in aritmetica di macchina, **algoritmi matematicamente equivalenti possono non esserlo numericamente**

### Errore nel calcolo di una funzione $f:\R\rightarrow\R$

Prendiamo un esame il problema del calcolo del valore $y=f(x)$. Dove $x\in\R=$ dato in input e $y\in\R=$ dato in output

**Osservazione**: Tutte le definizioni che seguono di ettore possono essere estese al caso generale di $y=F(x)$ con $F:\R^n\rightarrow\R^m, n\geq 1, m\geq 1$ usando le norme.

Sia $g$ la funzione che rappresenta l'algoritmo sceldo per approssimare la funzione $f$ in aritmetica esatta e sia $\tilde g$ la funzione effettivamente calcolata in aritmetica di macchina

${x\rightarrow y=f(x)}\\{\updownarrow \quad\quad \updownarrow}\\{\tilde x\rightarrow\tilde g(\tilde x)}$

In prima approssimazione risulta:

$err_{totale}=\frac{f(x)-\tilde g(\tilde x)}{f(x)}=err_{inerente}+err_{analitico}+err_{algoritmico}$

$err_{inerente}=\frac{f(x)-f(\tilde x)}{f(x)}\\err_{analitico}=\frac{f(\tilde x)-g(\tilde x)}{f(\tilde x)}\\err_{algoritmico}=\frac{g(\tilde x)-\tilde g(\tilde x)}{\tilde g(\tilde x)}$

L'accuratezza viene misurata dall'errore totale e dipende da tutte le componenti.

#### Errore inerente e condizionamento

Esistono problemi tali che qualunque algoritmo venga utilizzato, l'errore generato risulta elevato e talvolta privo di significato. èp una particolarità intrinseca del problema

L'errore inerente è legato al problema assegnato e studia l'effetto degli errori. 

Il problema si dice **ben condizionato** se non amplifica gli errori nei dati. Un errore relativo nell'input provoca un errore relativo dello stesso ordine di grandezza nell'output

Il problema si dice **mal condizionato** se non se non amplifica gli errori nei dati

Il condizionamento di misura della funzione $f$:

$cond_f(x):=\frac{|errore_{risposta}|}{|errore_{dato}|}=\frac{|f(x)-f(\tilde x)||x|}{|f(x)||x-\tilde x|}$

Il problema $f$ è mal condizionato se $cond_f(x)\gg1$. se la funzione $f$ è differenziabile due volte in un intorno $x$, otteniamo in prima approssimazione:

$cond_f(x)=\frac{|f'(x)||x|}{|f(x)|}$

Osserviamo che il condizionamento dipende anche dal dato $x$ non solo da $f$

```
Se il problema è mal condizionato cerchiamo una riformulazione matematicamente equivalente ma con indice di condizionamento migliore
```

#### Condizionamento di una funzione $F:\R^n\rightarrow\R$

Usando la formula di Taylor si trova:

$\frac{F(\tilde x)-F(x)}{F(x)}=\sum\limits^n_{i=1}(\frac{x_i}{F(x)}\frac{\partial F(x)}{\partial x_i})\frac{(\tilde x_i-x_i)}{x_i}$

Dove $x=(x_1,...-x_n),\tilde x=(\tilde x_1,...,\tilde x_n)\in R^n$.

$|err_{inerente}|\leq\sum\limits^n_{i=1}|c_i(x)|\epsilon_{x_i}$

Dove $\epsilon_{x_i}$ è l'errore relatico al dato i-esimo e $c_i(x):=\frac{x_i}{F(x)}\frac{\partial F(x)}{\partial x_i}$ è il coefficiente di amplificazione ad esso relativo. I coefficienti di amplificazione forniscono una misura del condizionamento

* La somma di n numeri è ben condizionata quando i numeri sono di segno concorde. Diventa mal condizionata se ci sono molti numeri quasi opposti (es: $+3.14-3.15$) (fenomeno della cancellazione)
* Il prodotto di n numeri è sempre ben condizionato

#### Errore algoritmico

l'errore algoritmico è generato dal fatto che le operazioni sono effettuate in aritmetica di macchin: misura l'errore tra il risultato fornito dall'algoritmo che opera in aritmetica esatta e l'algoritmo che opera in aritmetica di macchina.

L'algoritmo in aritmetica di macchina $\tilde g,i=1...N$ si ottiene sostituendo ogni operazione in aritmetica esatta $g_i:F^{n_i}\rightarrow F$ con la relativa operazione $\tilde g_i$ in aritmetica di macchina

$g=g_N\circ g_{N-1}\circ...\circ g_1\Rightarrow\tilde g=\tilde g_N\circ\tilde g_{N-1}\circ...\circ\tilde g_1$ 

Un algoritmo si dice **stabile in avanti** se l'errore è un piccolo multiplo della precisione $u$

La stabilità in avanti *non* garantisce l'accuratezza del risultato finale. Che dipende dall'errore totale.

Un risultato non accurato può risultare sia dall'applicazione di un algoritmo instabile ad un problema ben condizionato che dall'applicazione di un algoritmo stabile ad un problema mal condizionato

Nei casi semplici l'errore algoritmico si può analizzare con i **grafi computazionali**:
* Si parte dalla definizione ricorsiva dell'algoritmo
* Si disegna un grafo che rappresenta il calcolo, alcuni nodi sono i dati in input, altri sono le operazioni tra quei dati
* Affianco ad ogni nodo di dati si scrive l'errore accumulato fino a quel punto del calcolo
* Accumulando gli errori del grafo si ottiene la formula ricorsiva che descrive l'accumulo dell'errore
* Si semplifica la formula ottenuta per averne una non ricorsiva

Altrimenti si può usare l'**analisi dell'errore all'indietro**:
* Si considera il risultato di $\tilde g(\tilde x)$ come l'esecuzione di $g$ su un dato perturbato $\tilde g(\tilde x)=g(x+\epsilon)$
* l'algoritmo sarà **stabile all'indietro** se $\forall\tilde x (\frac{|\epsilon|}{|\tilde x|})$ è un piccolo multiplo di $u$
* $\frac{|\epsilon|}{|\tilde x|}\simeq u\alpha\Rightarrow|err_{algoritmico}|\simeq cond_g(\tilde x)\frac{|\epsilon|}{|\tilde x|}$

### Somma di n numeri

#### Somma ricorsiva:

* $S_i$:
  * $S_n=x_n+S_{n-1}$
  * $S_1=x_1$

La precisione dipende dall'ordinamento. In prima approssimazione $err_{algoritmico}=\frac1S_n\sum\limits^n_{i=2}S_i\delta_{i-1}$ dove $\delta_i$ è l'errore dell'$i$-esima operazione di somma

#### Algoritmo PSUM

Eseguo la somma ricorsiva ordinando gli elemendi in modo che l'errore accumulato ad ogni passaggio sia più piccolo possibile. In generale si scelgono dei compromessi, come l'ordinamendo di modulo crescente. L'ordine decrescente è più accurato in caso di "forte cancellazione"

#### Algoritmo di inserzione

I dati $x_i$ vengono ordinato secondo il modulo crescente ed ogni somma parziale calcolara per $i=2$ viene reinserita nela lista dei dati mantenendo l'ordine crescente.

#### Algoritmo della somma binaria

Per $n=2^k$ , al primo passo si sommano gli addendi a coppie e si ripete il procedimento sui risultati delle somme. Il risultato si raggiunge in $log_2(n)$ passi. È interessante per somme con molti elementi

#### Algoritmo di somma sompensata

Ad ogni somma la parte meno significativa dell'addendo più piccolo viene persa nella somma. L'algoritmo cerca di compensare questo errore sommando questo errore all'addendo successivo e ripetendo il procedimento per ogni passaggio

### Cancellazione degli errori

Si considetino i seguenti algoritmi:

alg 1:
```matlab
if x=0 then
  f=1
else
  f=exp((x)-1)/x
end
```

alg 2:
```matlab
y=exp(x)
if y=1 then
  g=1
else
  g=(y-1)/log(y)
end
```

l'algoritmo 1 risente della cancellazione se $|x|\ll1$. L'algoritmo 2 caluta in maniera approssimativa sia exp(x) che log(y), anche se i valori sono poco accurati il rapporto è preciso perché si eliminano gli errori nellla divisione