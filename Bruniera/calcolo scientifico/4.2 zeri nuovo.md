# Zeri di una funzione

Vogliamo cercare gli zeri di equazioni non lineari:

Data una funzione $f:\R\rightarrow\R$ trovate $\alpha$ tale che $f(\alpha)=0$. $\alpha$ è detta radice (o zero) della funzione.

Non sempre c'è uno zero, e non sempre è unico, a volte sono infiniti ($cos(x)$).

Una radice si dice multipla quando, con una certa molteplicità $\mu$, oltre ad essere radice della funzione è radice delle sue derivate fino a $\mu-1$:

$$
\mathrm{per~}\mu>1 \mathrm{~si~ha~}\\ 
f'(x)=f''(x)=...=f^{(\mu-1)}(x)=0 \mathrm{~e~} f^{(\mu)}(x)\neq0
$$

## Localizzazione di una radice

Stabilito che la funzione ha una radice, dobbiamo trovare un intervallo sufficientemente piccolo che la racchiuda.

**Teorema**: Sia $f$ una funzione continua in $[a,b]$ e tale che $f(a)f(b)<0$ (ovvero che nell'intervallo la funzione cambi segno), allora $f$ ha almeno uno zero nell'intervallo. Quest'intervallo è detto **intervallo di localizzazione** (bracket). Come si può ridurre?

## Algoritmo della bisezione

Dato un intervallo che contiene uno zero (i cui estremi hanno segno opposto) si controlla il segno della funzione nel punto medio, quindi si sceglie come prossimo intervallo la parte dove l'estremo ha segno opposto del punto medio. Si prosegue fino a che l'intervallo non è più piccolo di una soglia prefissata.

Converge sempre per funzioni continue.

Il numero delle iterazioni necessarie è $k=\left\lceil\log_2\left(\frac{|b-a|}{\mathrm{tol}}\right)\right\rceil$. Non dipende dalla funzione ma dall'intervallo. È piuttosto lento perché ad ogni iterazione si avvicina di un bit al valore del risultato partendo dal range. Con $|b-a|=1$ serve circa un iterazione per ogni cifra binaria di precisione del risultato (~4 per ogni cifra decimale), ad esempio con $\mathrm{tol}=10^{-7}$ si ha $k=24$.

### Errore

Vogliamo vedere l'errore dell'approssimazione di $\alpha$ ottenuta scegliendo $\tilde\alpha=m=(a+b)/2$ dopo k iterazioni.

$$
|\alpha-\tilde\alpha|\leq\frac{|b-a|}2\leq\frac{\mathrm{tol}}2
$$

Sostituiamo:

```matlab
while (|b-a|>tol)
```
con:

```matlab
while (|b-a|/min{|a|,|b|} > tol)
```

per fermarci quando siamo soddisfatti dell'errore relativo invece che l'errore assoluto (l'altro può diventare più lento, a volte).
La tolleranza non è più "assoluta" ma "relativa".

Si ottiene il seguente errore relativo:

$$
\frac{|\alpha-\tilde\alpha|}{|\alpha|}\leq\frac{|b-a|}{2\min{|a|,|b|}}\leq\frac{\mathrm{tol}}2
$$
 
Può non funzionare per $\min{|a|,|b|}$ molto vicino a zero.

## Metodo dell'iterazione funzionale

Trasformiamo il problema di trovare gli zeri di una funzione $f(x)$ nel trovare i punti fissi di una funzione $g(x)$.
Quindi invece dell'equazione $f(x)=0$ risolviamo $g(x)=x$. Per un'opportuna $g$ i problemi sono equivalenti.

Al problema associamo lo schema iterativo:
$$
x_0~\mathrm{dato}\\
x_{k+1} = g(x_k)
$$

In generale alla stessa $f$ sono associati più problemi di punto fisso equivalenti, ma con proprietà iterative ben diverse (non convergono, o lo fanno lentamente).

* Esempio $f(x)=x^2-x-2$
  * $g(x)=x^2-2$ con $x_0=2.01$
    * L'iterazione non converge, si dice che il punto fisso è *repulsivo*
    * Non va bene
  * $g(x)=\sqrt{x+2}$ con $x_0=1$
    * L'iterazione converge, si dice che il punto fisso è *attrattivo*
    * In 10 passaggi raggiunge un buon errore relativo
    * Il rapporto fra gli errori in passi successivi è $\frac{|\varepsilon_{k+1}|}{|\varepsilon_k|}$ tende a $\frac14$. Ciò ci fornisce una misura della velocità di convergenza
    * È monotona (cresce/decresce sempre, o resta uguale), le stime restano sempre dallo stesso lato di $\alpha$
  * $g(x)=1+\frac2x$ con $x_0=1$
    * L'iterazione converge
    * Stavolta il rapporto tra gli errori è $\frac12$, è paragonabile a quello della bisezione
    * Non è monotona
  * $g(x)=\frac{x^2+2}{2x-1}$ con $x_0=1$
    * Converge, è monotona
    * È molto veloce. Con 6 iterazioni supera la precisione di macchina
    * L'errore non migliora linearmente come gli altri, ma è quadratico. Per questo è veloce

### Teorema del valore medio

Dati due punti $g(x_k)$ e $g(x_{k+1})$ di una funzione $g$, esiste un punto $\xi_k$ dove la tangente ha la stessa pendenza del segmento tra i due punti.

$$
\frac{g(x_{k+1})-g(x_k)}{x_{k+1}-x_k}=g'(\xi_k)\\
$$

### Teorema della convergenza locale

Sia $g$ derivabile in un intervallo, e sia $\alpha$ un suo punto fisso nell'intervallo.\
$x_k$ converge se esiste un intorno circolare di $\alpha$ ($I_\alpha$) in cui $\forall_{x\in I_\alpha}|g'(x)<1|$.\
Va scelto un $x_0$ all'interno di $I_\alpha$.

**Dimostrazione**: Per il *teorema del valore medio* vale l'equivalenza:

$$
e_{k+1}=x_{k+1}-\alpha=g(x_k)-g(\alpha)=\frac{g(x_k)-g(\alpha)}{(x_k-\alpha)}(x_k-\alpha)=g'(\xi_k)(x_k-\alpha)=g'(\xi_k)e_k
$$

Inoltre, se:
$$
|g'(\xi_k)|<1\Leftrightarrow\left|\frac{g(x_k)-g(\alpha)}{x_k-\alpha}\right|<1\Leftrightarrow\left|\frac{x_{k+1}-\alpha}{x_k-\alpha}\right|<1\Leftrightarrow|x_{k+1}-\alpha|<|x_k-\alpha|\Leftrightarrow e_{k+1}<e_k
$$

Quindi, se nell'intorno la derivata è sempre minore di 1, anche $g'(\xi_k)$ sarà minore di 1 per tutti i $k$.
Quindi ad ogni passaggio l'errore assoluto diminuirà.
Quindi $x_k$ converge perché si avvicina ad $\alpha$.

Sia $\lambda=\max_{x\in I_\alpha}g'(x)$ e $\lambda<1$, si ha $|e_{k+1}|\leq\lambda e_k$.

Infine, si può dimostrare "facilmente" che non possono esserci altri punti fissi all'interno di $I_\alpha$

### Osservazioni

Siccome $\alpha$ non è noto, la condizione che l'intorno $I_\alpha$ sia circolare è piuttosto restrittiva:

* Se la condizione del teorema è verificata in un intervallo $[a,b]$ contenente $\alpha$, le ipotesi valgono al massimo in un intervallo circolare $I_\alpha$ contenuto in $[a,b]$.\
Per assicurare la convergenza, bisogna scegliere come $x_0$ l'estremo più vicino ad $\alpha$ (non si sa quale). Si può sceglierne uno e controllare che non esca dall'intervallo
* Se $g'(x)>0$ in $[a,b]$, la successione è monotona e $x_0$ può essere scelto indifferentemente.\
Inoltre in questo caso è sufficiente che la condizione sia verificata solo in nella metà dell'intervallo in cui scegliamo $x_0$
* Se $g'(x)<0$ in $[a,b]$  la successione è alternata e non si può stabilire quale dei due estremi sia il più vicino.\
Si può scegliere uno degli estremi come $x_0$ e poi:
  * Se $x_1\in[a,b]$ si può continuare con la successione, se esce lo fa subito
  * Se $x_1\notin[a,b]$, si deve ripartire scegliendo l'altro estremo, stavolta funzionerà

### Altre osservazioni

Il metodo è convergente anche con ipotesi più deboli. Visto che $\xi_k$ cade *tra* $x_k$ e $\alpha$, si possono escludere sia gli estremi che $\alpha$ dalla condizione del teorema.

Se la derivata $g'(\alpha)\approx1$ converge molto lentamente. Intuitivamente farà dei salti molto piccoli ad ogni iterazione, perché la funzione si avvicina all'identità.