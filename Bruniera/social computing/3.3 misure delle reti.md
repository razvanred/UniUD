# Misure delle reti

Sono dati estratti dalle reti. Essenzialmentem prendiamo una rete, la mettiamo in una scatola e sputa fuori un numero.

Ci servono per quantificare alcune informazioni della rete ad esempio:
* Chi è più influente
  * Ad esempio il numero di follower
  * Può essere meno banale, ad esempio chi sono i follower
* Riconoscere pattern nelle interazioni
  * Chi è simile a chi (omofilia)

Fino al 2018 c'era il servizio Klout che forniva misure personalizzate sui social media. Il punteggio di influenza dava a Obama 99 punti e a Justin Bieber 92 anche se il primo ah 2m follower e il secondo 10m, per dimostrare che il numero non basta.
Chiuso perché si poteva manipolare i punteggi sapendo come si calcolavano.

## A che domande rispondono le misure

* Chi sono gli attori più importanti.
  * Centralità: chi è il nodo al centro, chi devo cancellare per scollegare la rete
* Quali pattern di interazione sono comuni?
  * Reciprocità e transitività
  * Bilanciamento e status (più avanti)
* Quali individui sono simili e come li trovo?
  * Chi ha gli stessi amici è simile
* Misure quantitative

## Centralità

### Centralità di grado

Più è alto il grado più è centrale.

Ovviamente per grafi indiretti è semplicemente il numero di connessioni $d_i$.

Per i grafi indiretti abbiamo più tipi di centralità di grado:
* $d^{in}_i$ Prestigio (si misura dall'indegree)
* $d^{out}_i$ Aggregazione (si misura dall'outdegree)
* $d^{in}_i+d^{out}_i$ Altro che posso definire

Di solito si utilizza l'indegree, perché è più importante, ma non è una regola. Dipende dai casi.

Per confrontare la centralità tra grafi differenti in più modi:
* Lasciando i gradi così (è stupido)
* Normalizzarli per il grado massimo possibile
  * $C^{norm}_d(v_i)=\frac{C_d(v_i)}{n-1}$
* Normalizzarli per il grado massimo reale
  * $C^{max}_d(v_i)=\frac{C_d(v_i)}{\max\{d_i|i\in n\}}$
* Normalizzarli per la somma  dei gradi
  * $C^{sum}_d(v_i)=\frac{C_d(v_i)}{\sum\limits_{i\in n}d_i}$

### Centralità di betweennes (centralità di centralità ( ‾ʖ̫‾))

È un altro modo di misurare la centralità proposta da Linton Freeman. Indica quanto un nodo è "in mezzo ai piedi". Quindi quanto è importante per connettere gli altri.

$$C_b(v_i)=\sum\limits_{s\neq t\neq v_i}\frac{\sigma_{st}(v_i)}{\sigma_{st}}$$

Dove $\sigma_{st}(v_i)$ Indica il numero di percorsi più brevi da $s$ a $t$ passando per $v_i$ e $\sigma_{st}$ è il numero totale dei percorsi più brevi.

Quindi calcolo questo rapporto per tutte le coppie di $s$ e $t$ diverse da $v_i$ e le sommo per ottenere la misura di centralità

Per confrontare la betweenness tra due grafi diversi bisogna normalizzarla.

### Centralità di closeness (centralità di vicinanza)

Altro modo proposto da Linton Freeman che non aveva altro da fare se non trovare modi per misurare la centralità con Floyd-Warshall.
Il nodo più centrale è quello che raggiunge tutti gli altri nodi più velocemente. Ovviamente funziona solo se il grafo è connesso

Calcolo tutti i percorsi più brevi. Calcolo il reciproco della media delle distanze. La più alta è la più centrale (senza il reciproco sarebbe la più bassa, e non ci piace).

È già normalizzato

### Confronti interessanti

Se li ordino secondo le tre misure ottengo ordinamenti simili (di solito hanno correlazione positiva).
Quando non lo sono (correlazione negativa o bassa) abbiamo informazioni utili:
* Se abbiamo vicinianza bassa e grado alto il nodo è parte di una comunità distante dal resto della rete (una setta)
* Se abbiamo alto grado e bassa betweenness le sue connessioni sono ridondanti, la rete lo bypassa
* Se abbiamo alta vicinanza e basso grado abbiamo un nodo chiave della rete, connette parti molto diverse (sconnesse) della rete
* Se abbiamo alta vicinanza e bassa betweennes il grafo ha molti percorsi. Il nodo è vicino a molte persone, ma anch'esse sono vicine a mole persone
* Se abbiamo alta betweenness e basso grado, i pochi collegamenti del nodo sono cruciali
* Se abbiamo alta betweenness e bassa vicinanza (è molto raro), il nodo monopolizza i collegamenti di poche persone verso mole persone, è un intermediario verso tanti nodi

### PageRank

Pensato per la rete del web, si può facilmente sostituire con una rete sociale.

È nato intorno al 1998, inventato da Brin e Page, i fondatori di google. Si dice che il PageRank abbia fatto la fortuna di Google ma non è vero, c'erano una paio di altri ingredienti.

È sempre una misura di centralità. Il PageRank di una pagina $u$ è alto se $u$ è linkato fa molte pagine con PageRank alto.
Non dipende dalle ricerche, ogni pagina ha il suo punteggio.

$$r(v)\propto\sum\limits_{u\in I(v)}\frac{r(u)}{|O(u)|}$$

Il page rank di un nodo è proporzionale alla somma del rank diviso per la cardinalità outgoing di tutti i vicini incoming del nodo.

Ogni pagina $u$ distribuisce il suo rank a tutte le pagine che linka. Più il suo rank è alto e meno pagine linka, più il ranl di queste ultime aumenta.

Deve essere normalizzato, sono solo numeri che crescono.

Si calcola con matrici e vettori. Raccogliamo i page rank di tutte le pagine in un vettore r che costruiremo iterativamente.

Partiamo da un r0 iniziale con dei valori iniziali e lo trasformiamo in r1, poi r2 etc. Dobbiamo moltiplicarlo per una matrice speciale costruita in modo da mantenere la proporzionalità di sopra. Ripetiamo finche la differenza tra ri ed ri+1 non è più piccola di una soglia piccola.

Problemi:
* Quali sono i valori iniziali?
* Converge?
  * NO, si può avere un rank sink: un ciclo che aumenta il suo rank ad ogni iterazione

Useremo un'altra formalizzazione basata su percorsi casuali.

### PageRank: percorsi casuali

Immaginiamo di girare randomicamente tra le pagine web scegliendone una iniziale e aprendo un link randomico, tutti con la stessa probabbilità.

Quanto è probabile che un utente arrivi ad una certa pagina così?
Si calcola il limite per $t\rightarrow\infin$ della probabilità che dopo un percorso di $t$ pagine si finisca su questa pagina. Il risultato è il rank

#### Catene di Markov

Per calcolare quel limite si utilizzano le catene di Markov.
Si ha uno stato per ogni nodo ed $n$ nodi, ed in ogni istante la catena si trova in un certo stato (il percorso termina in un certo nodo), inizialmente trovarsi in un certo stato è equiprobabile agli altri stati.
Si ha una matrice di transizione di probabilità $n\times n$, ad ogni cella indica la probabilità di spostarsi dal nodo corrispondente alle righe a quello corrispondente alle colonne, dipende dal numero di link e dal loro "peso" (alcuni link verranno cliccati più volte di altri).

**N.B.**: La matrice di probabilità è la matrice di adiacenza di un grafo pesato.

In ogni istante avremo un vettore di probabilità con le probabilità di essere in ogni stato, la somma delle componenti deve essere 1 perchè gli stati sono una partizione.
Moltiplicando il vettore di probabilità per la matrice si ottiene il vettore di probabilità all'$i$-esimo istante.

Si calcola il valore del vettore per $i$ iterazioni con $i\rightarrow\infin$ partendo da un vettore iniziale. C'è una convergenza, spesso velocemente, quindi non conta quale si sceglie come vettore di partenza e per calcolare il limite basta calcolare qualche iterazione e fermarcisi quando non cambia più.
Quindi stiamo cercando un autovettore, cioè un vettore $p|pX=p$, e possiamo utilizzare algoritmi degli autovettori per trovarlo. 
Se l'autovettore esiste si dice catena di Markov ergodica, non sempre esiste.

#### Catene di Markov ergodiche

Se una catena è ergodica il vettore di probabilità probabilità ha il limite stabile

* La catena è fortemente connessa
* Ad ogni passo è  possibile essere in ogni stato con una probabilitàa maggiore di 0
* Una catena può essere connessa ma non ergodica (es: un grafo di due nodi con 100% di probabilità di passare da uno all'altro in ogni passaggio)

Pagine a caso sono ergodiche? No, il web non è connesso, se ne sono accorti subito. La soluzione è permettere il teletrasporto: saltare ad una pagina casuale non linkata.
La probabilità di raggiungere una pagina è la probabilità di seguire un link sommata alla probabilità di teletrasportarsi a quella pagina.
La probabilità di teletrasportarsi ad una pagina è una costante molto bassa, equidistribuita tra tutte le pagine del grafo, inizialmente si usava $0.1$, ma non sappiamo quanto sia ora, quindi la probabilità da ogni pagina di cliccare un link è $1-0.1=0.9$ che viene distribuita in base al numero di link in quella pagina.

La formula completa è: $r_{i+1}=(1-d)*r_i*P+d*r_1*M$. Dove $P$ è la matrice di transizione e $M$ è la matrice di teletrasporto composta solo da $1/N$ in cui $N$ è il numero di pagine.

Questo connette il grafo e permette di calcolare il PageRank di tutte le pagine.

Non si calcola proprio così, e nemmeno inizialmente, perché ci sono troppe pagine, la dimensione della matrice sarebbe non meno di $10^9\times10^9$. Si può calcolare ogni settimana partendo da quello della settimana precedente.
Molti dei punti della matrice sono 0 quindi si posson non memorizzare.

### HITS: l'algoritmo di Kleinberg

Si definiscono due insiemi correlati di pagine:
* pagine hub "H"
  * Contengono molti link buoni. Es: motori di ricerca
  * Prende il nome dagli aereoporti
* Pagine authority "A"
  * Pagine di persone ed entità ben note
  * Pagine che sono linkate da tanti buoni hub

Parto da un insieme root $rs$ e lo unisco alle sue pagine linkate $O(rs)$ e le pagine che lo linkano $I(rs)$, per produrre un insieme base $bs=x\cup O(rs)\cup I(rs)$, calcolo la hubness (H) e authorityness (A) su queste.

$$H(x)=\sum\limits_{y\in O(x)} A(y)$$
$$A(x)=\sum\limits_{y\in I(x)} H(y)$$

#### Come calcolarlo

Costruiamo due vettori colonna, uno di H (h) e uno di A (a).

L'iesima H del vettore h è data dalla moltiplicazione della iesima riga della matrice di adiacenza M, per il vettore a. Per calcolare tutto il vettore h posso moltiplicare la matrice di adiacenza per il vettore a.
Funziona anche viceversa con la trasposta della matrice

Quindi $h=Ma$ e $a=M^Th$, quindi $a=M^TMa$ e $h=MM^Th$, quindi i vettori h ed a sono gli autovettori delle matrici $MM^T$ e $M^TM$, se trovo uno con la matrice M trovo anche l'altro

### Perché si usa PageRank e non HITS?

PageRank non è spammabile, non riesco a trarre rank da altre pagine importanti.
Però non è specifico per le query, funziona male su grafi piccoli, ed è complesso

HITS è spefico per query, funziona su grafi piccoli, separa le pagine tra hub e autorità.
Però è facilmente spammabile (basta avere una pagina che linka molte buone pagine ed una pagina spam, la prima è un buon hub e di conseguenza la seconda una buona autorità), è complesso, a volte non converge.


### Prestigio e Centralità

Il concetto di prestigio o status esiste nel mondo degli studi sociali già dagli anni '50.

Il prestigio e la centralità riprendono gli stessi concetti. Quando si stavano studianto le centralità si sono resi conto che stavano riprendendo concettti del passato da un punto di vista diveso.

## Social Network Analysis

Misura le relazioni tra le persone. Ad esempio grafi di collaborazione.

Usa delle terminologie strane, le adatteremo alle terminologie dei grafi:
* Ponti tra due nodi: archi che collegano due nodi che senza sarebbero più distanti. Sono legami deboli
* Triangoli: un sottografo completo di 3 nodi
* Legame forte: arco che appartiene a molti triangoli

Secondo l'articolo di Granovetter "the strenght of weak ties"
* Rimuovere legami forti non cambia molto le distanze
* Rimuovendo legami deboli si tende a sconnettere il grafo
* I legami deboli sono scorciatoie
* Se cerchi qualcosa, chiedi ai legami deboli. Se chiedi a quelli forti l'informazione rischia di restare intrappolata in una clique