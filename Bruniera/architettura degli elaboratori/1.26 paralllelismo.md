# parallelismo 

secondo il modello di Von Neumann ci deve essere una unica operazione in esecuzione ed una sola comonente attiva in un dato istante

si cercano modelli diversi che prevedano il parallellismo

## approcci:
* reti neurali
* data flow machine, connection machine (modelli teorici)
* architetture bio-ispirate
* **i calcolatori vettoriali**: sono usati nel calcolo scientifico
* **supercomputer**: sono costose archtetture non standard che richiedono personale e tecniche di programmazione specializzate
* **cpu multicore** sono utilizzate negli attuali computer. bisogna cercare di utilizzarli più efficientemente possibile

## sviluppo delle architetture parallele

architetture parallele nel mercato degli anni '80

* cpu con pipeline, cpu superscalati: eseguono programmi preesistenti
* cpu multicore, sistemi multiprocessori, cluster: richede tecniche di programmazione diverse

## motivazioni

migliorare le prestazioni e aumentare la fault tollerance

## catalogazione del parallelismo

**granlarità**: complessità delle operazioni eseguite in parallelo e dei circuiti che le eseguono
* **fine**: semplici istruzioni; istruction level parallelism (ilp). es: pipeline
* **grossa (coarse)**: procesure , process level parallelism (plp).  es: multithreading, multiprocessori, multicomputer

## livello di accoppiamento

* forte: unità connesse, condivisione dei dati, es: processori superscalari, multiprocessori
* debole: unità più indipendenti, scambio di messaggi, es. multicomputer

## parallelismo su singolo chip

* **pipeline**: esecuzione della microistruzione su più stadi
* **processori supescalari**: esegue più microistruzioni in contemporanea, aumentano le prestazioni circa di un ordine di grandezza

i precedenti non rendono necessaria la riscrittura di un programma, però l'aumento dell prestazioni è limitato.
per questo si usano altre tecniche di parallelismo:
* **very long instruction word** (vliw)
* on-chip **multi-threading**
* single-chip **multiprocessor**
  * multiprocessori omogenei
  * multiprocessori eterogenei

---
### vliw

prevede istruzioni macchina adatte alcalcolo parallelo, e istruzioni sono lunghe e sono composte da più istruzioni di base, si cerca di sfruttare quanto più possibile tutte le capacità del processore usando diverse funzioni contemporaneamente

#### TriMedia

è un processore prodotto da philips per le applicazioni ultimediali, ogni istruzione era composta da 5-8 istruzioni base: potevano essere aritmetiche, load-store, multimediali eccetera

#### Itanium IA-64

processore prodotto da intel per sostituire il intel IA-32 (pentium, core).

più istruzioni possono essere accodate ed eseguite contmeporaneamente senza controllarne l'indipendenza

* prevede istruzioni condizionare per minimizzare i salti
* utilizza centinaia di registri per minimizzare gli accessi in memoria e la dipesenza tra itruzioni
* utilizza load speculativi per minimizzare gli accessi in memoria

---
### multi-threading

permette di struttare meglio le capacità di calcolo dei processori superscalari. un processore esegue più thread contemporaneamente

può essere utilizzato anche in processori con sngola pipeline ma è più utile in processori superscalari.

il processore commuta da un thread ad un altro:
* mt a grana fine: commutazione su ogni istruzione. anticipa i possibili blochi ma impone un numero elevato di commutazioni
* mt a grana grossa: si eseguono più istruzioni per ogni thread, riduce le commutazioni senza prevenire i blocchi
* mt simultaneo: a grana grossa, ma nel caso di stallo comuta sul thread successivo, massimizza l'impegno delle unità funzionali cpu

#### multi-threading: ripartizione delle risorse

* isorse condivise: memoria cache
* risorse partizoinare (tempo): pipeline
* risorse partizionate (spazio): registri

partizionare le risorse in modi equo tra i thread non necessariamente ottimizza le prestazioni degli ultimi

#### multi-threading: condivisione delle risorse

* condivisionie ripartita: ogni thread possiede un insieme privato di risorse, si rischia il sottoutilizizzo
* completa: i thread condividono tutte le risorse, si rischia l a starvation

---
### multiprocessori omogenei

sono un evoluzione del mulithreading. c'è un processore per ogni thread e si possono eseguire contemporaneamente le istruzioni di tutti i thread

la cache è condivisa attraverso una rete token ring che garantisce semplicità e consistenza dei dati con un moderato spreco di tempo.
nella rete passa un unico dato che viene passato da un componente ad un altro

---
### coprocessori

parallelismo iottenuto delegando alcuni compiti a processori ausiliari.
* dma: complesso controllore per la gestione dell'i/o
* scheda video: elaborazioniedelle immagini in tempo reale
* coprocessori multimediali: codifica e decodifica e postelaborazione
* cripto-processori: si fanno carico delle operazioni di criptazione

---
### multiprocessori eterogenei

TODO

---
---

## parallelismo su più chip

### multiprocessore

1. più processori su più circuiti.

possono essere a memoria condivisa, si dividono le operazioni da eseguire su uno stesso insieme di dati. rende più facile la condivisione dei dati attraverso LOAD e STORE, deve però mantenere la consistenza della memoria. non serve ripartirre i dati tra le cpu, lavorano tutte sigli stessi dati

2. sistemi a memoria distribuita.

ogni processore ha la sua memoria privata e comunicano tra di loro tramite scambio di messaggi

---
### multicomputer
 
sono sistemi molto grandi a scambio di messaggi

---
---
## rappresentazione della memoria condivisa

1. memoria principale condivisa
2. memoria virtuale paginata condivisa. una pagina può trovarsi:
   1. nella memoria locale della cpu
   2. nella memoria di massa
   3. nella memoria di unaltra cpu
3. memoria dell'applicazione condivisa
   1. il sistema operativo non se ne occupa
   2. se ne occupa il programma utente attraverso un'astrazione fornita dal runtime
   3. esempi: Linda, ORCA, etc.

---
---
## scalabilità

**scalabilità**: una stessa idea architetturale può essere realizzata con un numero variabile di processori. posso aggiungerli o rimuoverli a necessità

### prestazioni

* le unità di calcolo devono sincronizzarsi (overhead)
* memoria e altre risorse condivise creano potenziali conflitti

quindi:
* è impossibile che n cpu svolgano un lavoro n vole più velocemente.
  *  legge di Amdahl: rapporto di incremento= $n/(1+(n-1)(1-f))$ con 0<=f<=1 frazione di tempo parallelizzabile
*  per alcuni algoritmi un aumento delle unità di calcolo comporta un peggioramento delle prestazioni

---
---
## elementi di un multicomputer/mliprocessore

* unità di calcolo: cpu/ processor standard
* unità di memoria: memorie locali delle cpu, memoria principale divisa in più banchi per gestire richieste parallele
* rete di interconessione
  * collegano processori e moduli di memoria per i muliprocessori
  * collegano i computer per i mulrticomputer

---
### memoria

* diverse unità in parallelo
* complessità dovura alla replicazione dei dati
  * memoria locale per ogni core
  * memoria di livello più alto per ogni processore
  * memoria principale comune ai processori
* tempi di accesso dipendenti dalla distanza dai processori
* possibili letture e scritture fuori ordine

#### semantica della memoria

compromesso tra fficienza e consistenza:
* stretta: rappresentazione ordinata
* sequenziale: rappresentazione ordinata della sequenza di scritture
* di processore:
* rappresentazione ordinata della sequenza di scritture di ogni cpu
* debole: rappresentazione ordinata solo dopo sincronizzazioni regolari
* dopo il rilascio: rappresentazione ordinata solo dopo che un evento di sincronizzazione è invocato dalla cpu

---
### reti di interconnessione

equivalenza logica coi protocolli per i bus, ma più complessa.

composte da:
* link
* switch
* interfacce

#### switch

tipi di instradamento:
* commutazione a circuito
* commutazione a pacchetto

**routing**: determinazione del percorso

---
---
## tassonomia delle architetture parallele

* sisd single instruction single data (Von Neumann)
* simd single instruction multiple data (computer vettoriali)
* mimd multiple instruction multiple data (multiprocessoti e multicomputer)
* misd multiple instruction single data (nessun esempio)

### SIMD, array processor

più processori controllati da una unità che eseguono la stessa istruizone su dati diversi

array di dati e array di processori

o processori attuali ereditano l'esperienza simd, eseguono istruzioni su insiemi di dati di lunghezza variabile

in isa x86:
* mmx
* sse
* avx

usano registri molto lunghi per eseguire operazioni vettoriali

### SIMD, gpu

alcune gpu ereditano l'architettura dei computer vettoriali

nvidia fermi:
* la stessa operazione è eseguita da idendici core (cuda) clusterizzati in streaming multiprocessor
* ogni processore SIMD esegue due thread
* la struttura della memoria è complessa
  * ogni core ha una memoria privata
  * ogni sm ha una memoria locale
  * gli sm condividono una memoria cache

#### gpgpu

gpu general purpose, sono processori vettoriali usati per eseguire applicazioni non necessariamente grafiche, richiedono linguaggi specifici come CUDA o OpenGL

---
---
## multiprocessori UMA

UMA: Uniform Memory Access

### SMP: singolo bus
è la più semplice implementazione di un sistema multiprocessore, le cpu comunicano con un unico bus, hanno una cache e una memoria privata e condividono una memoria principale

si usano cache di grandi dimenzioni per limitare l'utilizzo del bus che limita, tra l'altro, il numero di CPU. la cache deve essere mantenuta coerente

#### SMP: cache snooping

la cache spia il traffico sul bus per garantire la coerenza

protocollo write-through:
* read hit: lettura della cache, nessuna azione
* read miss: lettura della memoria condivisa
* write miss: scrittura in memoria condivisa, nessuna azine
* write hit: scrittura in cache, il protocollo invalida la stella linea delle cahce delle altre cpu

poco efficiente, necessita di molte scritture in memoria condivisa

protocollo write-back:
ogni liea viene marcata in 4 modi invece che 2
* shared: linea condivisa, memoria aggiornata
* exclusive: linea non condivisa, memoria aggiorata
* modified: linea non condivisa, memoria non aggiornata
* invalid: linea non valida

#### esempio: MESI

quando una cpu carica una linea è exclusive, se unaltra cpu la legge è shared su entrambe. quando una cpu la modifica la segna modified e l'altra è segnata invalid. se un'altra cpu vuole la linea la prende dalla cpu che la ha segnata come modified e viene segnata come shared su entrambe

---
### UMA: Crossbar Switch

processori e memorie sono connesse mediante crossbar: rete non bloccante. il numero degli switch per l'accesso alla memoria è nell'ordine di grandezza O(n^2) 

cpu e memorie sono collegate ai due lati di una matrie di switch. chiudendo uno switch un processore ha accesso ad una delle memorie. il numero degli switch è pari al prodotto del numero di cpu per il numero di memorie.

nel caso migliore, ogni cpu deve accedere ad una memoria diversa, le cpu possono accedere completamente in parallelo

in alcuni casi ogni processore ha accesso preferenziale alla memoria cona la sua stessa etichetta.

---
### UMA: reti a commutazione

utilizza una rete bloccante. una serie di "nodi" di commutazione organizzati in stadi che collegano cpu e memorie, l'accesso non può avvenire in parallelo se non in casi particolarmente fortunati in cui i due accessi non richiedano agli stessi nodi la commutazione

l'indirizzo del mittende viene generato dalla rete durante il trasferimento. sono necessarei 3 stadi di 4 nodi per commutare i messaggi di 8 cpu e 8 memorie. il numero di witch è nell'ordine di grandezza O(n log(n))

il numero di switch è di molto minore rispetto alla soluzione crossbar (12 < 64) non è possibile 

---
---
## NUMA (non approfondito oltre)

Non UMA

l'accesso alla memoria non è uniforme.

ogni cpu ha una bus locale, che lo collega ad una memoria privata, ed un accesso al bus di sistema per accedere alle memorie degli altri processori.

la richiesta di una cpu al bus locale o di sistema è controllata da una MMU