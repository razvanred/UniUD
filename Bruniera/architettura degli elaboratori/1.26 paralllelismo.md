# parallelismo 

secondo il modello di Von Neumann ci deve essere una unica operazione in esecuzione ed una sola comonente attiva in un dato istante

si cercano modelli diversi che prevedano il parallellismo

## approcci:
* reti neurali
* data flow machine, connection machine (modelli teorici)
* architetture bio-ispirate
* **i calcolatori vettoriali**: sono usati nel calcolo scientifico
* **supercomputer**: sono costose archtetture non standard che richiedono personale e tecniche di programmazione specializzate
* **cpu multicore** sono utilizzate negli attuali computer. bisogna cercare di utilizzarli più efficientemente possibile

## sviluppo delle architetture parallele

architetture parallele nel mercato degli anni '80

* cpu con pipeline, cpu superscalati: eseguono programmi preesistenti
* cpu multicore, sistemi multiprocessori, cluster: richede tecniche di programmazione diverse

## motivazioni

migliorare le prestazioni e aumentare la fault tollerance

## catalogazione del parallelismo

**granlarità**: complessità delle operazioni eseguite in parallelo e dei circuiti che le eseguono
* **fine**: semplici istruzioni; istruction level parallelism (ilp). es: pipeline
* **grossa (coarse)**: procesure , process level parallelism (plp).  es: multithreading, multiprocessori, multicomputer

## livello di accoppiamento

* forte: unità connesse, condivisione dei dati, es: processori superscalari, multiprocessori
* debole: unità più indipendenti, scambio di messaggi, es. multicomputer

## parallelismo su singolo chip

* **pipeline**: esecuzione della microistruzione su più stadi
* **processori supescalari**: esegue più microistruzioni in contemporanea, aumentano le prestazioni circa di un ordine di grandezza

i precedenti non rendono necessaria la riscrittura di un programma, però l'aumento dell prestazioni è limitato.
per questo si usano altre tecniche di parallelismo:
* **very long instruction word** (vliw)
* on-chip **multi-threading**
* single-chip **multiprocessor**
  * multiprocessori omogenei
  * multiprocessori eterogenei

---
### vliw

prevede istruzioni macchina adatte alcalcolo parallelo, e istruzioni sono lunghe e sono composte da più istruzioni di base, si cerca di sfruttare quanto più possibile tutte le capacità del processore usando diverse funzioni contemporaneamente

#### TriMedia

è un processore prodotto da philips per le applicazioni ultimediali, ogni istruzione era composta da 5-8 istruzioni base: potevano essere aritmetiche, load-store, multimediali eccetera

#### Itanium IA-64

processore prodotto da intel per sostituire il intel IA-32 (pentium, core).

più istruzioni possono essere accodate ed eseguite contmeporaneamente senza controllarne l'indipendenza

* prevede istruzioni condizionare per minimizzare i salti
* utilizza centinaia di registri per minimizzare gli accessi in memoria e la dipesenza tra itruzioni
* utilizza load speculativi per minimizzare gli accessi in memoria

---
### multi-threading

permette di struttare meglio le capacità di calcolo dei processori superscalari. un processore esegue più thread contemporaneamente

può essere utilizzato anche in processori con sngola pipeline ma è più utile in processori superscalari.

il processore commuta da un thread ad un altro:
* mt a grana fine: commutazione su ogni istruzione. anticipa i possibili blochi ma impone un numero elevato di commutazioni
* mt a grana grossa: si eseguono più istruzioni per ogni thread, riduce le commutazioni senza prevenire i blocchi
* mt simultaneo: a grana grossa, ma nel caso di stallo comuta sul thread successivo, massimizza l'impegno delle unità funzionali cpu

#### multi-threading: ripartizione delle risorse

* isorse condivise: memoria cache
* risorse partizoinare (tempo): pipeline
* risorse partizionate (spazio): registri

partizionare le risorse in modi equo tra i thread non necessariamente ottimizza le prestazioni degli ultimi

#### multi-threading: condivisione delle risorse

* condivisionie ripartita: ogni thread possiede un insieme privato di risorse, si rischia il sottoutilizizzo
* completa: i thread condividono tutte le risorse, si rischia l a starvation

---
### multiprocessori omogenei

sono un evoluzione del mulithreading. c'è un processore per ogni thread e si possono eseguire contemporaneamente le istruzioni di tutti i thread

la cache è condivisa attraverso una rete token ring che garantisce semplicità e consistenza dei dati con un moderato spreco di tempo.
nella rete passa un unico dato che viene passato da un componente ad un altro

---
### coprocessori

parallelismo iottenuto delegando alcuni compiti a processori ausiliari.
* dma: complesso controllore per la gestione dell'i/o
* scheda video: elaborazioniedelle immagini in tempo reale
* coprocessori multimediali: codifica e decodifica e postelaborazione
* cripto-processori: si fanno carico delle operazioni di criptazione

---
### multiprocessori eterogenei

TODO

---
---

## parallelismo su più chip

### multiprocessore

1. più processori su più circuiti.

possono essere a memoria condivisa, si dividono le operazioni da eseguire su uno stesso insieme di dati. rende più facile la condivisione dei dati attraverso LOAD e STORE, deve però mantenere la consistenza della memoria. non serve ripartirre i dati tra le cpu, lavorano tutte sigli stessi dati

2. sistemi a memoria distribuita.

ogni processore ha la sua memoria privata e comunicano tra di loro tramite scambio di messaggi

---
### multicomputer
 
sono sistemi molto grandi a scambio di messaggi