# Esecuzione asincrona

Vogliamo che l'host non resti bloccato finche la GPU lavora, però l'host deve trasferire i dati alla GPU per farla lavorare.

Se i dati possono essere separati in parti indipendenti, posso avviare più trasferimenti e mentre stanno eseguendo, lanciare i kernel.
Ora, alcuni kernel non potranno lavorare finche non finisce il trasferimento, ma quando finiscono i dati da cui dipendono, possono lavorare senza aspettare che finiscano gli altri trasferimenti.

Per farlo dobbiamo inviare dati e kernel su più stream diversi, perché le cose dello stesso stream sarebbero "serializzate".

## Concorrenza e parallelismo

Concorrenza vuoldire far progredire più task insieme, magari alternando esecuzioni dell'uno e dell'altro. Questo si fa quando magari ci sono delle dipendenze tra i dati prodotti dai task o da degli stream che arrivano un po' alla volta.

Parallelismo vuoldire eseguire più task nello stesso momento.

Quando due processi concorrenti accedono alla stessa risorsa si verifica una race condition.

Per risolvere le race condition usiamo le primitive di sincronizzazione che si implementano con le procedure atomiche.

Il professore mostra l'algoritmo di Peterson. Quello degli spinlock che c'è sul Tanenbaum.

L'algoritmo di Peterson funziona solo se gli accessi alle tre variabili di sincronizzazione sono atomiche.

## Operazioni atomiche in CUDA

Il thread legge una locazione, calcola un nuovo valore, e aggiorna la locazione. E durante questa operazione nessuno può utilizzare quella locazione ed il thread non può essere interrotto.

Le operazioni atomiche hanno uno scope:
* System-wide: atomica su *tutto* il sistema, inclusi i thread della CPU e delle altre GPU
* Device-wide: atomica per tutta la GPU
* Block-wide: atomica per tutto il blocco
* ...

Esempi di operazioni atomiche:
* `int atomicaAdd(int* address, int val)`
  * Esegue atomicamente `*address += val` e restituisce il vecchio valore
* `unsigned int atomicInc(unsigned int* address, unsigned int val)`
  * `*address += (*address >= val ? 0 : 1)`
* `int atomicCAS(int* address, int compare, int val)`
  * `*address = (*address == compare ? *address : val)`
* ...

## Memory fence

Gli atomici non fanno memory ordering. Quelli si fanno con le memory fence.

Esempi di fence:
* `__threadfence_block()`
  * Tutte le scritture eseguite prima di questa operazione devono essere osservabili dagli altri thread prima di iniziare quelle eseguite dopo.
  * Tutte le letture eseguite prima di questa operazione devono essere ordinate prima di quelle eseguite dopo
* `__threadfence()`: Come il precedente, ma a livello di GPU
* `_threadfence_system()`: Come il precedente, ma a livello di sistema

## Gruppi di cooperazione

Offrono direttive per definire partizionare e sincronizzare gruppi di thread.

Il CG programming model specifica:
* I tipi di dato per rappresentare i gruppi e proprietà
* I gruppi intrinsecamente definiti dai blocchi
* I gruppi intrinsecamente definiti da altri gruppi
* Barriere
* Primitive di comunicazione

I gruppi possono fare operazioni collettive, che eseguono qualcosa (operazioni di sincronizzazione o comunicazione) su tutti i thread insieme. Il caso più semplice è `barrier` che 