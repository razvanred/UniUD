# Esecuzione asincrona

Vogliamo che l'host non resti bloccato finche la GPU lavora, però l'host deve trasferire i dati alla GPU per farla lavorare.

Se i dati possono essere separati in parti indipendenti, posso avviare più trasferimenti e mentre stanno eseguendo, lanciare i kernel.
Ora, alcuni kernel non potranno lavorare finche non finisce il trasferimento, ma quando finiscono i dati da cui dipendono, possono lavorare senza aspettare che finiscano gli altri trasferimenti.

Per farlo dobbiamo inviare dati e kernel su più stream diversi, perché le cose dello stesso stream sarebbero "serializzate".

