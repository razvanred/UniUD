# GPU

Terminologia:
* GPU: il termine è stato inventato da nvidia nel 1999.
* GPU computing/GPGPU: (general purpose gpu) usare la GPU per cose che non sono grafica
* Heterogeneous computing: l'utilizzo trasparente di diversi device di architetture diverse per la computazione

Perché usare le GPU? Sono più economiche ed efficienti di altre architetture parallele. Sono trainate dall'industria dei videogiochi, quindi prodotte in massa.

La grafica computerizzata può essere definita (circa) come delle tecniche per produrre e manipolare immagini partendo da dati e modelli.
Generare l'immagine si chiama rendering, in generale prendere una scena 3d e proiettarla in 2d. Uno schermo full hd ha circa 2 milioni di pixel, quindi per generare immagini velocemente serve molto parallelismo.

Le GPU implementano la *graphic pipeline*:
* Geometry:
  * Trasformazioni: scaling, rotazioni, traslazioni, etc
  * Clipping: cancellare le parti non visibili (per non renderizzarle)
  * Lighting e shading
* Rasterization: proiettare la scena sulla griglia di pixel

Storia:
* 1980: I primi chip grafici implementavano fisicamente la pipeline ed erano tutti diversi
  * Potevano avere DMA e "display list" (code di operazioni)
* 1985: Chip grafici simili a CPU, programmabili col loro ISA
  * Potevano avere DSP
* 1990: Primi controller VGA con frame buffer
  * Programmabili ed economiche
  * Accelerazione hardware 2d
* 1995: Impulso all'accelerazione 2d
  * Nuovi chip per accelerazione hardware
  * OpenGL e DirectX
  * Implementazione della pipeline grafica nella GPU
* 1999: GPU
* 2000: Introduzione delle shading units
  * Sono piccoli processori che eseguono dei piccoli programmini prestabiliti chiamati shader
  * La GPU controlla grandi quantità di shading units in stile SIMD
  * Alcuni shader sono:
    * Vertex shader: operazioni sui vertici
    * Geometry shader: costruire oggetti dai vertici
    * Pixel shader: filtri sui pixel
* 2005: Shading unit programmabili
  * Ogni shading unit può eseguire qualsiasi shader e sono definite dal programmatore
  * Programmare le GPU è più facile
  * Nascono i primi progetti di GPGPU, per sfruttare OpenGL per risolvere problemi scientifici sui vettori usando i vertex shader
  * Bisogna stabilire delle tecniche per bilanciare il carico di lavoro sulle shading units
* 2007: Nvidia introduce l'unified shader model
  * Tutti gli shader usano lo stesso ISA
  * Le compute unit (ex shading unit) sono generiche
  * Nvidia propone CUDA (compute unified device architecture)
  * AMD propone Brook+
  * Permettono di programmare le GPU senza utilizzare API grafiche come OpenGL e DirectX
* 2008: Khronos introduce OpenCL
  * Il primo standard per la programmazione parallela cross platform
  * È un framework di heterogeneous computing, è meno efficiente di usare direttamente CUDA

## CPU vs GPU

Ripasso MIMD:
* Adottano o message passing, o thread level parallelism, a noi interessa il secondo
* Ci sono program counter multipli
* Orientati alle architetture tightly-coupled o shared-memory
* Sfruttiamo N processori eseguendo almeno N thread
* I lavori possono essere coarse grained o fine grained
* Spesso ci troviamo con tanti thread tightly coupled che eseguono lo stesso task

I multipcocessori MIMD hanno pochi core, con ALU molto potenti e controlli complessi per esecuzione speculativa e altre tecniche. Ogni core ha la sua cache, in più ci sono altre cache condivise.

In una GPU (che è una via di mezzo tra MIMD e SIMD) ci sono grandi quantità di core semplici e ALU piccole ma efficienti e a basse frequenze.
La parte di controllo è molto semplice, non fa esecuzione speculativa.
Più core sono raggruppati ed associati allo stesso circuito di controllo e cache, quei core faranno la stessa cosa sempre. 

Nei lavori sequenziali, una CPU sarà sempre molto più veloce di una GPU. Viceversa, nei lavori inerentemente paralleli ad alto throughput, la GPU sarà molto più veloce di una CPU, a patto che siano tanti task uguali (SIMD).

Il meta è usare sia GPU che CPU quando si fa un lavoro, facendo una sorta di thread level parallelism, in cui facciamo fare fare le cose sequenziali alla CPU e parallele alla GPU.

## SIMT

L'architettura delle GPU è detta SIMT, single instruction multiple threads, che assomiglia a SIMD ma non uguale.

Ci sono migliaia di core, o CU (compute units). Questi core non sono individuali, vengono raggruppati.\
La GPU contiene un certo numero di cluster GPC (gpu processing clusters) uguali. I GPC contengono alcuni TPC (texture processing cluster) composti da SM (streaming multiprocessors) che a loro volta contengono le CU.

I CU non sono tutti uguali. Ad esempio una GPU potrebbe avere un certo numero di CU per FP32 e di meno per FP64.

Un SM contiene alcuni CU di vario tipo (FP32, INT, tensor core, etc), ogni CU ha accesso ad una porzione dei registri del SM e di cache del SM (che può fare da memoria condivisa). Il SM contiene alcuni scheduler, a ciascuno sono associati alcune CU, questi scheduler non controllano individualmente i CU, ma in blocco.

## CUDA

Terminologia:
* Platform model: Astrae un certo numero di device (GPU) gestite da un host (CPU)
* Execution model: Definisce il set di istruzioni che possono essere eseguite dalla GPU, e per controllare/inizializzare la GPU
* Kernel: Le sequenze di istruzioni che i core eseguono
* Memory model: Definisce i tipi di memoria è la visibilità
* Programming mode: Definisce la logica della computazione

CUDA descrive platform e programming model per programmare le GPU Nvidia.

Fornisce tre astrazioni fondamentali:
* Gerarchia tra blocchi di thread
* Memorie condivise
* Barriere per la sincronizzazione

Queste astrazioni sono accessibili al programmatore tramite estensioni di un linguaggio di programmazione general purpose.

Quando eseguo una applicazione CUDA, ho alcuni thread, e ciascuno esegue un'istanza di un kernel, i kernel sono tutti uguali.
I thread sono raggruppati in blocks, che sono organizzati in una matrice (da 1,2, o 3 dimensioni) chiamata *grid* ed identificati dalle coordinate, e a loro volta i thread sono organizzati in una matrice all'interno del blocco.
*Tutti i blocchi devono avere le stesse dimensioni*.

Lo scheduler assegna ogni blocco ad uno SM, fino ad occupare tutti gli SM, che eseguono i blocchi esegue fino al termine. Quando hanno finito assegna nuovi blocchi, le schede vecchie aspettavano che avessero finito tutti.
Se i blocchi sono piccolo potrebbe non sfruttare tutta la potenza dei SM.

All'interno dello SM, i thread di un blocco sono raggruppati in warp, e gli scheduler contenuti nel SM li assegnano ai vari core (in batch sempre).

La CPU stabilisce la configurazione della grid ed inizializza le istanze dei kernel. Poi le comunica alla GPU che li esegue.
La CPU deve anche trasferire i dati da/a la memoria della GPU e quella centrale.