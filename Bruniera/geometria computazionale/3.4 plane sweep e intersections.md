# Plane sweep per identificare punti di intersezione tra segmenti

## Plane sweep

Un approccio in cui tentiamo di identificare delle proprietà geometriche immaginango di spazzare il piano con una retta. Spostiamo una retta da sinistra a destra (o viceversa) chiedendoci cosa vede la retta.

Per sua natura è strettamente legataa problemi sul piano. La introdurremo come tecnica per identificare le intersezioni tra segmenti.

Elementi del plane sweep:
* Sweep line:
  * Una retta verticale (convenzionalmente)
  * Spazza il piano da sinistra a destra (convenzionalmente) parallelamente a se stessa
  * Teniamo traccia di quello che la retta "vede" del problema e come cambia
  * A sinistra della retta il lavoro è completato
  * A destra stiamo ancora la vorando
* Events:
  * Sono le posizioni di questa retta in cui occorrono dei "cambiamenti sostanziali"
  * Per "cambiamenti sostanziali" cambiamenti rilevanti per il problema
  * Cambiamenti riguardanti la topologia del piano
  * Quello che la retta vede è quello che si trova tra la retta stessa ed uno degli eventi significativi precedenti

## Problema dei punti di intersezione (line segment insersection)

* Siano un set $S$ di $n$ segmenti su un piano
* Trovare tutti i punti di ntersezione tra i segmenti in $S$
  * Per ora supponiamo che non ci siano punti di intersezione di 3 segmenti ne estremi in comune tra segmenti
* È banale risolverlo in $\theta(n^2)$ nel caso peggiore
  * Si ordinano i segmenti in base al vertice più a destra
  * Si confronta ogni segmento con tutti i precedenti
  * Ci sono casi in cui questa è l'unica soluzione:
    * Metà dei segmenti interseca l'altra metà dei segmenti
      * Abbiamo $(\frac n2)^2$ punti e dobbiamo visitarli tutti
    * Se queste situazioni fossero comuni, avrebbe senso usare sempre l'algoritmo banale, ma non è così
* Ci interessano algoritmi che siano "proporzionati" alla dimensione dell'output

### Prima idea

* Due segmenti possono intersecarsi solo se le loro intersezioni sull'asse $x$ si sovrappongono
* La retta di spazzamento vede i segmenti che interseca (le cui proiezioni si sovrappongono)
* Se ci interessa solo sapere quali segmenti interseca (ed è così) gli eventi corrispondono a quando incontra gli estremi
  * Quando incontra l'estremo a sinistra vede un segmento in più (ENTER)
  * Quando incontra l'estremo a destra vede un segmento in meno (EXIT)
* Abbiamo una descrizione di un algoritmo rudimentale
  * Agli eventi ENTER controlliamo l'intersezione tra il nuovo segmento e quelli incrociati
  * In entrambi i casi aggiorno la lista aggiungendo o rimuovento i segmenti
* Ordinare gli estremi inizialmente costa $O(n\log n)$
* Comunque, il caso peggiore è sempre $O(n^2)$
  * Sappiamo che a volte è inevitabile
  * Qua succede anche se non è inevitabile (ad esempio quando abbiamo tutte linee parallele inclinate, ragionateci sopra)
  * Molto male

### Seconda idea

* Al passaggio $k$, sia $L_k$ l'insieme di punti in cui la linea incroca i segmenti
* Perché due segmenti si intersechino serve che ad un certo passaggio (prima dell'intersezione) siano adiacenti nell'insieme
* Shanoms & Hoey propongono un algoritmo per scoprire se esistono segmenti che si intersecano in $S$
  * Non trova i punti di intersezione
  * L'ordinamento dei segmenti in $S$ costa $O(n\log n)$
  * Creiamo un albero di ricerca bilanciato vuoto $S_k$ (per abbassare la complessità)
    * Gli eventi ENTER aggiungono il segmento $s\in S$ ad $S_k$
    * Gli eventi EXIT rimuovono il segmento 
    * Costo delle singole operazioni $O(\log n)$
  * Come troviamo le adiacenze?
    * Quando inseriamo il segmento $s$ troviamo i due segmenti ($u,v$) tra cui viene inserito
      * Controllo se interseca i due
    * Quando rimuoviamo il segmento $s$ diventano adiacenti i due segmenti ($u,v$) tra cui si interponeva
      * Controllo se $u$ e $v$ si intersecano
      * Non sono necessariamente gli stessi di prima (che sarebbero già stati testati)
  * Costo complessivo $O(n\log n)$
    * Ordinamento +
    * Al più $n$ eventi
      * Ciascun evento causa una quantità limitata da costante di operazioni su albero $O(\log n)$
* Questa soluzione è ottimale nel caso peggiore, quindi diventa un lower bound per il test di intersezione
  * Il problema di element uniqueness può essere ridotto a questo test di intersezione
    * Vedi Dobkin & Lipton 1975, 1979
    * Sia una sequenza $X$ di numeri di cui vogliamo testare l'unicità
    * Per ogni numero $X_i$ inseriamo un segmento $(x_i-i,-i)(x_i+i,+i)$ in cui $i$ è l'indice
      * L'indice rende i segmenti tutti diversi tra di loro
    * Se due $x_i$ e $x_j$ sono uguali, i segmenti hanno una sovrapposizione
  * Il test di intersezione si può ridurre al problema dei punti di intersezione

## Bentley & Ottmann (1979)

L'algoritmo di B&O cerca di estendere l'algoritmo di S&H cercando di catturare tutti gli eventi di intersezione.

Assunzioni iniziali:
* Non ci sono segmenti verticali
* Non ci sono segmenti sovrapposti
* Non ci sono punti di intersezione di tre segmenti
* Non ci sono estremi condivisi tra i segmenti
* Non ci sono intersezioni sugli estremi

Eventi:
* ENTER
  * Avviene raggiunto l'estremo sinistro di un segmento $s$
  * Il segmento cade tra i segmenti $u$ e $v$ (due nuove adiacenze con $s$)
  * Si testano entrambi per intersezioni con $s$
* EXIT
  * Avviene raggiunto l'estremo destro di un segmento $s$
  * Crea una nuova adiacenza $u-v$
  * Si testa l'intersezione tra $u$ e $v$
* SWAP
  * Avviene quando si intersecano due segmenti $s$ e $t$
    * Quando si intersecano l'ordine dei punti di uscita si scambia
  * Cadono tra $u$ e $v$
  * Prima c'erano le adiacenze $u-t$ ed $s-v$
  * Dopo lo scambio si creano due nuove adiacenze $u-s$ e $t-v$
  * Si controllano entrambe

Alcune considerazioni:
* Invariante: tutti gli elementi a sinistra della sweep line sono stati già computati
* Le stesse intersezioni possono essere scoperte più di una volta
* Serve considerare solo le intersezioni a destra della linea, quelle a sinistra sono già state computate
  * Altrimenti servirebbe tornare indietro, che rende tutto più complicato
  * L'invariante dice che sono già stati computati
* Bisogna trattare i casi in cui scopro la stessa intersezione due volte
  * Questo permette di gestire anche altri casi limite

Raffinamenti della struttura dati che mantiene gli eventi:
* Coda degli eventi:
  * Gli eventi di SWAP sono intercalati da eventi ENTER/EXIT
    * Ma i punti corrispondenti non sono noti a priori
  * Ordiniamo dinamicamente gli eventi con una coda con priorità
  * Una possibile struttura è una binary heap
  * Il costo complessivo è $O(|E|\log|E|)$ in cui $E$ è il numero di eventi
    * Gli eventi sono non meno di $2n$, e possono arrivare a $2n+n^2$
* Segmenti intersecati dalla sweep line
  * La struttura di base è un BST in cui i segmenti sono ordinati in base alla coordinata $y$
  * Mediamente si trovano un segmento e le sue adiacenze in tempo $O(\log n)$
  * Per garantire questo tempo si utilizza un albero bilanciato come AVL o RBT

Correttezza dell'approccio:
* La struttura connessa alla sweep line (l'albero) è rappresentativa della geometria di una striscia verticale tra due eventi consecutivi
* Visto che i punti di intersezione sono eventi, le intersezioni sono rilevate almeno a questi eventi
  * C'è stato un evento appena prima dell'intersezione che ha fatto scoprire l'intersezione
* Si può risolvere il problema delle rette verticali utilizzando l'ordinamento lessico grafico come per il CH

Complessità:
* L'inserimento di tutti gli eventi ENTER ed EXIT $O(n\log n)$
* Gli eventi sono $O(n+k)$ dove $k$ sono le intersezioni
  * Gli eventi SWAP ripetuti possono essere uniti agli eventi EXIT che li causano, quindi sono $O(n)$
* Il costo di processare un generico evento è $O(\log n)$
  * Una ricerca e possibilmente uno o due inserimenti
* Costo totale $O((n+k)\log n)$
  * I costi di memorizzazione possono essere più fastidiosi perché potrebbero anche essere di costo quadratico (gli SWAP possono essere $O(n^2)$)
  * Nella struttura manteniamo solo gli eventi corrispondenti a segmenti adiacenti, tanto li troveremo di nuovo più avanti
    * Nella struttura saranno presenti solamente $O(n)$ SWAP perché solo tanti segmenti possono essereadiacenti lungo la linea
  * Non si può rimuovere in modo efficente un elemento da uan coda con priorità
    * Conviene sostituire la struttura con un albero bilanciato, che ha sempre costo $O(\log n)$ per operazioni di ricerca inserimento e rimozione

Casi degeneri:
* Segmenti verticali:
  * Usiamo l'ordine lessicografico come al solito
* Punti ocndivisi da più di due segmenti (non sovrapposizioni)
  * Si possono verificare tre possibili situazioni:
    * Punti che si incontran oall'estremo sinistro
    * Punti che si incontrano all'estremo destro
    * Punti di intersezione di più segmenti
  * Dato che abbiamo già complicato la struttura dell'albero, conviene pensare direttamente ad un evento ibrido
    * Gli eventi che si incontrano allo stesso punto sono adiacenti
    * I punti adiacenti che si incontrano sullo stess opunto possono essere fusi in un evento ibrido
    * Gli eventi possono essere aggiornati dinamicamente durante l'elaborazione
      * Quando si trova un evento che era già presente nella struttura, si aggiorna invece che inserirlo
  * Processando i punti ibridi
    * Gli elementi in $R(p)\cup C(p)$ sono adiacenti nella struttura
    * Se $|L(R)\cup R(p)\cup C(p)|>1$, riporto il punto di intersezione $p$
    * Rimuovo gli elementi $R(p)\cup C(p)$ dalla struttura della linea
    * L'ordine dei segmenti $C(p)$ è invertito
    * Inserisco gli elementi $L(p)\cup C(p)$ nella struttura
    * Se $|L(p)\cup C(p)|=0$ si deve controllare l'intersezione dei segmenti appena sopra e sotto di $R(p)$
  * Abbiamo risolto tutti i problemi tranne la sovrapposizione su una stessa retta
