# Scanner e Parser

In questa parte applicheremo tutta la teoria dei liguaggi e le grammatiche.

## Descrizione di un linguaggio di programmazione

* Sintassi
  * Quali sequenze di caratteri costituiscono programmi
  * Come sono strutturati
* Semantica
  * Significato
  * Comportamento di un programma
  * Cosa causa la sua esecuzione
* Pragmatica
  * Regole sull'utilizzo pratico
  * Standard e convenzioni
  * Più vicina ad ingegneria del software
* Implementazione
  * Come eseguire il codice sorgente
  * Che codice macchina ganarare dal codice sorgente

### Descrizione della sintassi di un linguaggio

La descrizione di una sintassi può esere fatta utilizzando le gramamtiche formali libere dal contesto. Utilizzeremo quelle proposte da Noam Chomsky negli anni 50 (un linguista, non un informatico).

È interessante che la prima idea di grammatica formale era stata proposta nel quaero secolo avanti Cristo da Panini (un indiano) per descrivere il Sanscrito.

Questi formalismi permettodo di generare tutte le frasi sintatticamente corrette in una lingua naturale, o nel nostro caso tutti i programmi sintatticamente corretti.

Mette anche in evidenza la struttura della frase o di un programma.

Una grammatica libera dal contesto è costituita da:
* Un insieme di simboli terminali
  * Possono essere parole di una lingua,
  * simboli di base di un linguaggio di programmazione,
  * lettere di un alfabeto
* Un insieme di simboli non terminali: categorie sintattiche
  * Possono essere: Nomi, Verbi, Articoli, etc
  * Possono essere: Identificatori, Costanti, Operazioni, etc
* Un insieme di regole generative
  * Descrivono come posso espandere i simboli non terminali come simboli terminali od altri non terminali
  * Ad esempio:
    * Proposizione -> soggetto predicato
    * Proposizione -> soggetto predicato-verbale complemento-oggetto
    * soggetto -> Giovanni
    * Programma -> dichiarazione-variabili corpo-del-programma
* Un simbolo iniziale
  * Il primo simbolo che si trova nella frase
  * Se è un terminale il linguaggio ha una sola frase possibile che è il simbolo iniziale stesso
  * Altrimenti si può espandere secondo le regole per produrre tutte le altre frasi

#### Esempio: Grammatica delle stringhe palindrome dell'alfabeto {a,b}

* Terminali: a,b
* Non terminali: P
* Regole:
  * P ->
  * P -> a
  * P -> b
  * P -> aPa
  * P -> bPb
* Simbolo iniziale

#### Esempio: Espressioni aritmetiche...

... a partire dalle variabili a,b,c

* Terminali: a,b,c,+,-,*,(,)
* Non terminali: E,T,F,Var (espressione, termine, fattore)
* Regole:
  * E -> T
  * E -> E + T
  * E -> E - T
  * T -> F
  * T -> T + F
  * F -> (E)
  * F -> Var
  * Var -> a
  * Var -> b
  * Var -> c
* Simbolo iniziale: E

#### Formilazione alternativa BNF (Backus-Naur Form)

Sviluppata per algol60

Era pensata per essere facilmente scritta utilizzando i caratteri che troviamo sulla tastiera:
* I non terminali sono indicati con le parentesi angolati `<e>`
* Le frecce sono sostituite da `::=`
* Le regole con lo stesso simbolo a sinistra sono raggruppate come `<E>::=<T>|<E> + <T>|<E> - <T>`

## Derivazione ed alberi di derivazione (Parser)

La derivazione è il processo di passare dal simbolo iniziale alla parola finale eseguendo una regola alla volta. Si dovrebbe rappresentare elencando tutte le regole applicate in ordine ed i passaggi di derivazione intermedi.

Un modo più sintetico di rappresentarlo è con un albero in cui un arco (direzionato) indica l'espansione di un simbolo
* I singoli simboli (terminali e non) sono i nodi
* Gli archi escono dai simboli non terminali, un arco per ogni simbolo in cui viene espanso il simbolo (da una sola regola)
* Dall'altro capo dell'arco, a seconda della regola, possono esserci simboli terminali o non terminali
* I simboli terminali sono foglie
* La stringa ordinata delle foglie forma la frase

Gli alberi di derivazione sono alberi ordinati, quindi:
* Grafi orientati
* Aciclici e connessi
* Ogni nodo ha al più un arco entrante
* Gli archi uscenti sono ordinati
  * L'ordine degli archi uscenti dipendono dalla regola di derivazione applicata

Quello che fa il compilatore è ricavare l'albero di derivazione della frase.
Ad ogni albero di derivazione viene assegnato un significato. Se una stessa frase può essere derivata da due alberi diversi è ambigua e non sappiamo che significato ha.

Esempio:
* Una grammatica alternativa delle espressioni aritmetiche è
  * `<E>::=<E>*<E>|<E>+<E>|<E>-<E>|(<E>)|a|b|c|`
* Questa grammatica è ambigua perché esistono più alberi che producono la stringa
  * a+b*c
  * Non sappiamo cosa significa

Ci sono due soluzioni al problema della ambiguità:
* Si rende la grammatica più complessa in modo che non sia più ambigua
  * È quello che abbiamo fatto con la grammatica dell'esempio
  * La prima versione presentata è più complicata ma non è ambigua
* Si aggiungono delle regole per interpretare le frasi ambigue
  * Si danno degli ordini di precedenza alle regole che possono essere applicate
    * Ad esempio, nel caso delle espressioni aritmetiche, la moltiplicazione ha la precedenza su somma e sottrazione
  * Quando alcuni operatori hanno la stessa precesenza si indica se si associa a sinistra od a destra
    * Ad esempio, nel caso delle espressioni aritmetiche, somme e sottrazioni si associano a sinistra
  * Non è un formalismo previsto dalla grammatica, è una convenzione

Un esempio di grammatica ambigua è quella dei comandi if-then-else:
* `<stat>::=IF <bool> THEN <stat> ELSE <stat>|IF <bool> THEN <stat>|...`
* È ambigua nel caso di `IF <bool1> THEN IF <bool2> THEN <stat1> ELSE <stat2>`
  * Può essere interpretata come:
    * `IF <bool1> THEN (IF <bool2> THEN <stat1>) ELSE <stat2>`
    * `IF <bool1> THEN (IF <bool2> THEN <stat1> ELSE <stat2>)`
    * La convenzione è di usare la prima

L'albero di derivazione viene poi semplificato in un albero sintattico astratto, in cui sono rimossi i passaggi che servono a risolvere le ambiguità (come passaggi in cui si aggiungono parentesi). Questo albero astratto viene poi trasformato in un albero sintattico che è ancora più semplice e rimuove tutti i passaggi, mantenendo solo la struttura che mantiene le informazioni.

### Classi di grammatiche

Questa classificazione è stata proposta da Chomsky stesso e sono divise in:
* A struttura di frase
* Dipendenti dal contesto
* Libere dal contesto
* Lineari sinistre, lineari destre
* Regolari

Si differiscono per il grado di libertà delle regole e la difficoltà di computazione.
Quelle più utili per noi sono quelle libere dal contesto e quelle regolari, che vengono usate in parti diverse del compilatori.

Il parser utilizza le grammatiche libere dal contesto, in particolare una loro sottoclasse che rende possibile accettare la frase in tempo lineare.

Ci sono alcuni controlli che queste grammatiche non riescono a fare:
* Controllo di tipo delle variabili
* Controllo che un simbolo sia dichiarato prima di essere utilizzato
* Controllo che le funzioni siano chiamate con gli stessi argomenti (numero e tipo) con cui sono state dichiarate
* Controllo che non vengano midificate le variabili di controllo di un for
* ...

## Analisi semantica statica

L'analisi semantica si occupa di controllare quelle cose (elencate sopra) che una grammatica libera dal contesto non riesce a controllare.

La semantica di un programma descrive il suo significato ed il suo comportamento in esecuzione (non solo il controllo degli errori).

La semantica è quasi sempre definita informalmente in linguaggio naturale.

Possibile approccio formale alla semantica:
* Semantica operazionale strutturata:
  * Descriviamo il comportamento del programma mediante un insieme di regole (simili a quelle delle grammatiche) che descrivono cosa succede nella computazione
* Semantica denotazionale:
  * Associamo un oggetto matematico (una funzione) al comportamento del programma

## Analisi lessicale

La sintassi del linguaggio, come per i linguaggi naturali, non è definita sul singoo carattere, ma su dei lessemi, parole, catalogate in diverse categorie.

La prima operazione che viene eseguita sul programma, prima della analisi sintattica, è l'analisi lessicale, ch prende una stringa di caratteri e la separa in una sequenza di token.

I token sono del tipo `(Categoria: valore)` e sono quello che poi sarà l'input dell'analizzatore sintattico

Questa fase abbastanza semplice viene realizzata utilizzando le grammatiche regolari (espressioni regolari).

### Ripasso linguaggi regolari

Operazioni sui linguaggi:
* Unione $L\cup M$
* Concatenazione $LM=\{st|s\in L\land t\in M\}$
* Chiusura di Kleene $L^*=\{s_1s_2...s_n|\forall_is_i\in L\}$

A partire da queste operazioni realizziamo un algebra (algebra di Kleene), che definisce l'insieme delleespressioni regolari. Queste permettono di rappresentare sinteticamente le grammatiche regolari.

Le espressioni sono costituite a partire da:
* Un insieme di costanti
  * I simboli di un alfabeto $\mathcal{A}$
  * La stringa vuota $\varepsilon$
* L'insieme delle operazioni sui linguaggi
  * Concatenazione: $LM$ o $L\cdot M$
  * Unione: $L|M$
  * Chiusura di Kleene: $L^*$

Sintassi delle espressioni regolari:
* Parentesi tonde $()$ sono usate per indicare l'ordine di applicazione delle operazioni
* Le concatenazioni ed unioni sono associative
  * Concatenazioni: $L(MN)=(LM)N=LMN$
  * Unioni: $(L|M)|N=L|(M|N)=L|M|N$
* Le chiusure di Kleene hanno la precedenza sulle concatenazioni e le unioni hanno la precedenza su tutto
  * $LM^*|N=\{N,L,LM,LMM,LMMM,...\}$
* Sono presenti alcune estensioni per comodità. Non aumentano l'espressività, sono solo più comode
  * Chiusura positiva: $L^+=LL^*$
  * Zero od una istanza: $L?=\varepsilon|L$
  * N concatenazioni di parole in $L$: $L\{n\}=LL...L$
  * Uno tra: $[abcde]=a|b|c|d|e$
  * Range: $[a-e]=a|b|c|d|e$
  * Opposto: $[\hat\space a-e]=$tutti i caratteri tranne quelli tra $a$ e $e$
  * Ne esistono anche molte altre che sono usate da editor di testo ed altro
* Definizioni tramite equazioni
  * Permettono una scrittura più chiara, le usiamo per indicare facilmente le costanti numeriche
  * `digit:=`$[0-9]$
  * `simple:=`$\{$`digit`$\}^+$
  * `fract:=`$\{$`simple`$\}.\{$`simple`$\}|.\{$`simple`$\}$
  * `exp:=`$\{$`fract`$\}e(\varepsilon|+|-)\{$`simple`$\}$
  * `num:=`$\{$`simple`$\}|\{$`fract`$\}|\{$`exp`$\}$

#### Teorema di equivalenza

I linguaggi regolari possono essere descritti in modi diversi equivalenti:
* Espressioni regolari
* Grammatiche regolari
* Automi a stati finiti non deterministici NFA
* Automi a stati finiti deterministici DFA

È difficile avere un programma che verifica un espressione regolare, è più semplice trasformare l'espressione regolare in un NFA, trasformare questo in un DFA, che poi può essere simulato in modo molto semplice da un programma.

#### Teorema di minimalità

Esiste un DFA minimo (nel senso col minor numero di stati possibile)

NOTA: Vedi gli appunti di fondamenti per i DFA e NFA

### Scanner, Lexer

Abbiamo visto che ogni lessema viene riconosciuto da un DFA, ma il programma che riconosce i lessemi non può essere un semplice DFA, perché risolve un problema leggermente più complesso:
* Riconoscere la stringa più lunga che viene riconosciuta da un DFA
* A volte andare un po' oltre la stringa riconosciuta per accettarla

Bisogna gestire alcune situazioni problematiche:
* Come deicdo la fine di un lessema?
  * La soluzione standard è che il lessema sia la più lunga stringa riconosciuta da un DFA
  * Può essere necessario leggere oltre la fine del lessema per riconoscere che non appartiene ad altri più lunghi (lookahead)
* Alcuni lessemi vengono riconosciuti da più DFA

Come è realizzato uno scanner?
* Costruisco gli automi di ogni lessema
* Simulo tutti gli automi contemporaneamente
* Quando nessuno può andare avanti, l'ultimo che si ferma riconosce il lessema
* Questa costruzione può essere automatizzata
  * Ci sono dei generatori di scanner (il professore propone "flex") a cui forniamo:
    * Tutte le espressioni regolari
    * Delle azioni da compiere corrispondenti (codice c da eseguire)
  * Produce in output un programma che:
    * Legge una stringa
    * Riconosce i lessemi
    * Applica le azioni ai lessemi per generare i token
      * Se più espressioni riconoscono la stessa lunghezza, la precedenza è definita dall'ordine
  * Le azioni possono accedere ad alcune variabili:
    * `yytex` contiene il testo riconosciuto
    * `yyleng` contiene la lunghezza del testo riconosciuto
    * `yyval` usata per passare parametri al parser
  * Permette di definire (in una sezione del file di configurazione)
    * Espressioni regolari
      * Nel formato `nome espressione` per usarle più comodamente
    * Variabili
      * Per leggere ed alterare valori condivisi tra le azioni
  * Non descrivo troppo aprofonditamente la sintassi di flex, si può trovare su internet scritta meglio

## Analisi sintattica

Dopo il passaggio dell'analisi lessicale si passa all'analisi sintattica, che è basata sulle grammatiche libere dal contesto e non quelle regolari, introducendo altra complessità computazionale.

### Automi a pila

Automi a pila. Le grammatiche libere possono (dal contesto) essere riconosciuti da automi a pila non deterministici.
Sono delle macchine a stati finiti con accesso (limitato) ad una memoria. Limitato nel senso che deve per forza essere uno stack.

Automi a pila:
* Insieme finito di stati
* Uno stack in cui inserire elementi finiti
* Passo di computazione
  * In base a:
    * Stato
    * Testa della pila
    * Simbolo in input
  * Deciso
    * Nuovo stato
    * Una sequenza di simboli da inserire nella pila
    * Se consumare l'input

Sa parola viene accettata se alla fine della scansione si raggiunge uno stato di accettazione.

Anche questi automi possono essere deterministici o non deterministici (ho più decisioni possibili). Ma in questo caso non sono equivalenti, l'automa ND può fare più cose.

In generale le grammatiche libere richiedono automi non deterministici.

Come simuliamo il ND?
* Con il backtracking abbiamo complessità esponenziale
  * Come simulando una ND-TM
* Esistono due algoritmi che riscono a riconoscere qualunque linguaggio libero in tempo $O(n^3)$
  * In casi pratici è troppo complesso comunque
* Un automa deterministico si simula linearmente, se riusciamo ad usare uno di questi lo scegliamo sempre
  * Usiamo solamente linguaggi riconoscibili da automi deterministici (è comunque una classe abbastanza ricca)
  * I linguaggi C/C++ fanno eccezione, sono riconosciuti da automi ND
    * La stringa `x * y ;` può essere interpretata in modi diversi a seconda di come è stata dichiarata `x`
    * Il parser di C/C++ deve essere più complicato per gestire altre notazioni come questa
    * Questo parser non può essere generato atumaticamente

Esistono due tipi di automi a pila: LL e LR.

#### Automi LL(n)

Costruisce l'albero di derivazione in modo top-down:
* Parte dal simbolo iniziale
* Guarda al più n (lo stesso n che sta in `LL(n)`) simboli non consumati (lookahead)
* Determina la prossima regola di espansione da applicare
* Si chiama LL(n) perché scorre da sinistra, espande sempre il non terminale pià a sinistra, e ha un lookahead di n

Esempio:
* S -> aAB
* A -> C|D
* B -> b
* C -> c|$\varepsilon$
* D -> d

| Output   | Pila    | Input |
| -------- | ------- | ----- |
| Start    | S\$     | adb\$ |
| S -> aAB | (a)AB\$ | adb\$ |
|          | AB\$    | db\$  |
| A -> D   | DB\$    | db\$  |
| D -> d   | (d)B\$  | db\$  |
|          | (B)\$   | b\$   |
| B -> b   | (b)\$   | b\$   |
|          | \$      | \$    |

Successo!


| Output             | Pila     | Input |
| ------------------ | -------- | ----- |
| Start              | S\$      | abb\$ |
| S -> aAB           | (a)AB\$  | abb\$ |
|                    | AB\$     | bb\$  |
| A -> C             | CB\$     | bb\$  |
| C -> $\varepsilon$ | \(C\)B\$ | bb\$  |
| B -> b             | (bB)\$   | b\$   |
|                    | \$       | b\$   |

Fallimento!

La teoria più nello specifico viene vista al corso di compilatori.

È facile capire se un linguaggio è LL(1), sono quelli che quando si espandono creano sempre solo un terminale, ed è facile scrivere un automa LL(1). Quindi in genere è una cosa possibile trasformare la grammatica in modo che sia di questo tipo.

#### Automi LR(n)

Utilizzano un approccio bottom-up. Sono più complicati ma sono anche più potenti.

```
Vedi esempio sulle slide
Non vale la pena di scriverlo quà
```

Esistono diversi algoritmi per costruire questi automi, che variano per:
* Complessità
* Numero di stati dell'automa generato
  * In genere non sono troppo grandi
  * Per un vero linguaggio di programmazione si parla di qualche centinaio di stati
* Ampiezza di linguaggi riconoscibili

Elencati in ordine crescente di complessità e linguaggi conosciuti:
* SLR(n)
* LARL(n)
  * Questo è lo sweetspot tra linguaggi conosciuti e complessità, si usa questo
* LR(n)

### Yacc (Yet Another Compiler-Compiler)

È uno dei generatori di parser più diffusi, riceve in input una descrizione del parser:
* Descrizione di una grammatica libera
* Insieme di regole da applicare

Restituisce il programma C che implementa il parser:
* L'input del programma sono i token dello scanner lex
* Simula un automa LARL
* Calcola ricorsivamente il valore associato ad ogni simbolo
  * Utilizzando l'albero di derivazione, più eventualmente altri valori

Esistono programmi equivalenti scritti in altri linguaggi.

Note:
* Yacc non assicura che la grammatica sia LALR
  * Grammatiche non LALR sono accettate da yacc ma:
    * Viene generato un automa con più scelte possibili (Non-deterministico)
    * Il codice generato sceglie una sola delle scelte possibili
    * Il codice generato potrebbe non accettare alcune frasi che sarebbero accettate dall'altra scelta
    * Non è detto che venga fatta la scelta migliore
* Permette grammatiche ambigue
  * Si può indicare la priorità per decidere come deve comportarsi Yacc per risolvere le ambiguità
