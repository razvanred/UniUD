# Scanner e Parser

In questa parte applicheremo tutta la teoria dei liguaggi e le grammatiche.

## Descrizione di un linguaggio di programmazione

* Sintassi
  * Quali sequenze di caratteri costituiscono programmi
  * Come sono strutturati
* Semantica
  * Significato
  * Comportamento di un programma
  * Cosa causa la sua esecuzione
* Pragmatica
  * Regole sull'utilizzo pratico
  * Standard e convenzioni
  * Più vicina ad ingegneria del software
* Implementazione
  * Come eseguire il codice sorgente
  * Che codice macchina ganarare dal codice sorgente

### Descrizione della sintassi di un linguaggio

La descrizione di una sintassi può esere fatta utilizzando le gramamtiche formali libere dal contesto. Utilizzeremo quelle proposte da Noam Chomsky negli anni 50 (un linguista, non un informatico).

È interessante che la prima idea di grammatica formale era stata proposta nel quaero secolo avanti Cristo da Panini (un indiano) per descrivere il Sanscrito.

Questi formalismi permettodo di generare tutte le frasi sintatticamente corrette in una lingua naturale, o nel nostro caso tutti i programmi sintatticamente corretti.

Mette anche in evidenza la struttura della frase o di un programma.

Una grammatica libera dal contesto è costituita da:
* Un insieme di simboli terminali
  * Possono essere parole di una lingua,
  * simboli di base di un linguaggio di programmazione,
  * lettere di un alfabeto
* Un insieme di simboli non terminali: categorie sintattiche
  * Possono essere: Nomi, Verbi, Articoli, etc
  * Possono essere: Identificatori, Costanti, Operazioni, etc
* Un insieme di regole generative
  * Descrivono come posso espandere i simboli non terminali come simboli terminali od altri non terminali
  * Ad esempio:
    * Proposizione -> soggetto predicato
    * Proposizione -> soggetto predicato-verbale complemento-oggetto
    * soggetto -> Giovanni
    * Programma -> dichiarazione-variabili corpo-del-programma
* Un simbolo iniziale
  * Il primo simbolo che si trova nella frase
  * Se è un terminale il linguaggio ha una sola frase possibile che è il simbolo iniziale stesso
  * Altrimenti si può espandere secondo le regole per produrre tutte le altre frasi

#### Esempio: Grammatica delle stringhe palindrome dell'alfabeto {a,b}

* Terminali: a,b
* Non terminali: P
* Regole:
  * P ->
  * P -> a
  * P -> b
  * P -> aPa
  * P -> bPb
* Simbolo iniziale

#### Esempio: Espressioni aritmetiche...

... a partire dalle variabili a,b,c

* Terminali: a,b,c,+,-,*,(,)
* Non terminali: E,T,F,Var (espressione, termine, fattore)
* Regole:
  * E -> T
  * E -> E + T
  * E -> E - T
  * T -> F
  * T -> T + F
  * F -> (E)
  * F -> Var
  * Var -> a
  * Var -> b
  * Var -> c
* Simbolo iniziale: E

#### Formilazione alternativa BNF (Backus-Naur Form)

Sviluppata per algol60

Era pensata per essere facilmente scritta utilizzando i caratteri che troviamo sulla tastiera:
* I non terminali sono indicati con le parentesi angolati `<e>`
* Le frecce sono sostituite da `::=`
* Le regole con lo stesso simbolo a sinistra sono raggruppate come `<E>::=<T>|<E> + <T>|<E> - <T>`

## Derivazione ed alberi di derivazione (Parser)

La derivazione è il processo di passare dal simbolo iniziale alla parola finale eseguendo una regola alla volta. Si dovrebbe rappresentare elencando tutte le regole applicate in ordine ed i passaggi di derivazione intermedi.

Un modo più sintetico di rappresentarlo è con un albero in cui un arco (direzionato) indica l'espansione di un simbolo
* I singoli simboli (terminali e non) sono i nodi
* Gli archi escono dai simboli non terminali, un arco per ogni simbolo in cui viene espanso il simbolo (da una sola regola)
* Dall'altro capo dell'arco, a seconda della regola, possono esserci simboli terminali o non terminali
* I simboli terminali sono foglie
* La stringa ordinata delle foglie forma la frase

Gli alberi di derivazione sono alberi ordinati, quindi:
* Grafi orientati
* Aciclici e connessi
* Ogni nodo ha al più un arco entrante
* Gli archi uscenti sono ordinati
  * L'ordine degli archi uscenti dipendono dalla regola di derivazione applicata

Quello che fa il compilatore è ricavare l'albero di derivazione della frase.
Ad ogni albero di derivazione viene assegnato un significato. Se una stessa frase può essere derivata da due alberi diversi è ambigua e non sappiamo che significato ha.

Esempio:
* Una grammatica alternativa delle espressioni aritmetiche è
  * `<E>::=<E>*<E>|<E>+<E>|<E>-<E>|(<E>)|a|b|c|`
* Questa grammatica è ambigua perché esistono più alberi che producono la stringa
  * a+b*c
  * Non sappiamo cosa significa

Ci sono due soluzioni al problema della ambiguità:
* Si rende la grammatica più complessa in modo che non sia più ambigua
  * È quello che abbiamo fatto con la grammatica dell'esempio
  * La prima versione presentata è più complicata ma non è ambigua
* Si aggiungono delle regole per interpretare le frasi ambigue
  * Si danno degli ordini di precedenza alle regole che possono essere applicate
    * Ad esempio, nel caso delle espressioni aritmetiche, la moltiplicazione ha la precedenza su somma e sottrazione
  * Quando alcuni operatori hanno la stessa precesenza si indica se si associa a sinistra od a destra
    * Ad esempio, nel caso delle espressioni aritmetiche, somme e sottrazioni si associano a sinistra
  * Non è un formalismo previsto dalla grammatica, è una convenzione

Un esempio di grammatica ambigua è quella dei comandi if-then-else:
* `<stat>::=IF <bool> THEN <stat> ELSE <stat>|IF <bool> THEN <stat>|...`
* È ambigua nel caso di `IF <bool1> THEN IF <bool2> THEN <stat1> ELSE <stat2>`
  * Può essere interpretata come:
    * `IF <bool1> THEN (IF <bool2> THEN <stat1>) ELSE <stat2>`
    * `IF <bool1> THEN (IF <bool2> THEN <stat1> ELSE <stat2>)`
    * La convenzione è di usare la prima

L'albero di derivazione viene poi semplificato in un albero sintattico astratto, in cui sono rimossi i passaggi che servono a risolvere le ambiguità (come passaggi in cui si aggiungono parentesi). Questo albero astratto viene poi trasformato in un albero sintattico che è ancora più semplice e rimuove tutti i passaggi, mantenendo solo la struttura che mantiene le informazioni.

### Classi di grammatiche

Questa classificazione è stata proposta da Chomsky stesso e sono divise in:
* A struttura di frase
* Dipendenti dal contesto
* Libere dal contesto
* Lineari sinistre, lineari destre
* Regolari

Si differiscono per il grado di libertà delle regole e la difficoltà di computazione.
Quelle più utili per noi sono quelle libere dal contesto e quelle regolari, che vengono usate in parti diverse del compilatori.

Il parser utilizza le grammatiche libere dal contesto, in particolare una loro sottoclasse che rende possibile accettare la frase in tempo lineare.

Ci sono alcuni controlli che queste grammatiche non riescono a fare:
* Controllo di tipo delle variabili
* Controllo che un simbolo sia dichiarato prima di essere utilizzato
* Controllo che le funzioni siano chiamate con gli stessi argomenti (numero e tipo) con cui sono state dichiarate
* Controllo che non vengano midificate le variabili di controllo di un for
* ...

## Analisi semantica statica

L'analisi semantica si occupa di controllare quelle cose (elencate sopra) che una grammatica libera dal contesto non riesce a controllare.

La semantica di un programma descrive il suo significato ed il suo comportamento in esecuzione (non solo il controllo degli errori).

La semantica è quasi sempre definita informalmente in linguaggio naturale.

Possibile approccio formale alla semantica:
* Semantica operazionale strutturata:
  * Descriviamo il comportamento del programma mediante un insieme di regole (simili a quelle delle grammatiche) che descrivono cosa succede nella computazione
* Semantica denotazionale:
  * Associamo un oggetto matematico (una funzione) al comportamento del programma

## Analisi lessicale

La sintassi del linguaggio, come per i linguaggi naturali, non è definita sul singoo carattere, ma su dei lessemi, parole, catalogate in diverse categorie.

La prima operazione che viene eseguita sul programma, prima della analisi sintattica, è l'analisi lessicale, ch prende una stringa di caratteri e la separa in una sequenza di token.

I token sono del tipo `(Categoria: valore)` e sono quello che poi sarà l'input dell'analizzatore sintattico

Questa fase abbastanza semplice viene realizzata utilizzando le grammatiche regolari (espressioni regolari).

### Ripasso linguaggi regolari

Operazioni sui linguaggi:
* Unione $L\cup M$
* Concatenazione $LM=\{st|s\in L\land t\in M\}$
* Chiusura di Kleene $L^*=\{s_1s_2...s_n|\forall_is_i\in L\}$

A partire da queste operazioni realizziamo un algebra (algebra di Kleene), che definisce l'insieme delleespressioni regolari. Queste permettono di rappresentare sinteticamente le grammatiche regolari.

Le espressioni sono costituite a partire da:
* Un insieme di costanti
  * I simboli di un alfabeto $\mathcal{A}$
  * La stringa vuota $\varepsilon$
* L'insieme delle operazioni sui linguaggi
  * Concatenazione: $LM$ o $L\cdot M$
  * Unione: $L|M$
  * Chiusura di Kleene: $L^*$

Sintassi delle espressioni regolari:
* Parentesi tonde $()$ sono usate per indicare l'ordine di applicazione delle operazioni
* Le concatenazioni ed unioni sono associative
  * Concatenazioni: $L(MN)=(LM)N=LMN$
  * Unioni: $(L|M)|N=L|(M|N)=L|M|N$
* Le chiusure di Kleene hanno la precedenza sulle concatenazioni e le unioni hanno la precedenza su tutto
  * $LM^*|N=\{N,L,LM,LMM,LMMM,...\}$
* Sono presenti alcune estensioni per comodità. Non aumentano l'espressività, sono solo più comode
  * Chiusura positiva: $L^+=LL^*$
  * Zero od una istanza: $L?=\varepsilon|L$
  * N concatenazioni di parole in $L$: $L\{n\}=LL...L$
  * Uno tra: $[abcde]=a|b|c|d|e$
  * Range: $[a-e]=a|b|c|d|e$
  * Opposto: $[\hat\space a-e]=$tutti i caratteri tranne quelli tra $a$ e $e$
  * Ne esistono anche molte altre che sono usate da editor di testo ed altro
* Definizioni tramite equazioni
  * Permettono una scrittura più chiara, le usiamo per indicare facilmente le costanti numeriche
  * `digit:=`$[0-9]$
  * `simple:=`$\{$`digit`$\}^+$
  * `fract:=`$\{$`simple`$\}.\{$`simple`$\}|.\{$`simple`$\}$
  * `exp:=`$\{$`fract`$\}e(\varepsilon|+|-)\{$`simple`$\}$
  * `num:=`$\{$`simple`$\}|\{$`fract`$\}|\{$`exp`$\}|$

#### Teorema di equivalenza

I linguaggi regolari possono essere descritti in modi diversi equivalenti:
* Espressioni regolari
* Grammatiche regolari
* Automi a stati finiti non deterministici NFA
* Automi a stati finiti deterministici DFA

È difficile avere un programma che verifica un espressione regolare, è più semplice trasformare l'espressione regolare in un NFA, trasformare questo in un DFA, che poi può essere simulato in modo molto semplice da un programma.

#### Teorema di minimalità

Esiste un DFA minimo (nel senso col minor numero di stati possibile)

NOTA: Vedi gli appunti di fondamenti per i DFA e NFA
