# Introduzione

Professore: Pietro di Gianantonio

Trattazione generale di linguaggi di programmazione, senza parlare di linguaggi nello specifico

Obbiettivi, completare i linguaggi che conosciamo finora:
* Assembli ARM
* Scheme
* Java
* C

Sono una minuscola parte dei linguaggi disponibili, non ha senso e non è possibile impararli tutti.

Imparare i linugaggi diventa più semplice man mano che impariamo altri linguaggi perché cominciamo a notare delle similitudini tra i linguaggi. Come con i linguaggi naturali

Idee generali sui linguaggi:
* Paradigmi: come si svolge la computazione
  * Scheme funzionale
  * C sequenziale
  * Java ad oggetti
* Gestione dei nomi e dell'ambiente
  * Namespacing
* Gestione della memoria
  * Con o senza garbage collector
  * ...
* Meccanismi di controllo di flusso
  * Costrutti per cambiare l'ordine di esecuzione del codice
    * GOTO
    * While e for
    * If
* Chiamata a funzioni
  * Passaggio di parametri
* Meccanismi di implementazione
  * Compilatori ed interpreti

L'obbiettivo è quello di fornire un quadro generale senza dover imparare i singoli linguaggi. Mettendo in risalto aspetti comuni e differenze, e punti critici della comprensione dei linguaggi. Una volta compresi i concett idi base imparare un nuovo linguaggio diventa un lavoro puramente mnemonico.


Altri obbiettivi:
* Fare un uso migliore dei linguaggi
  * Avere le idee chiare su alcuni concetti complessi
  * Spesso non si utilizzano al meglio tutte le funzionalità di un linguaggio, perché anche una piccola frazione di questo è già turing completa, quindi a volte gli sviluppatori non le imparano tutte
    * Imparare ad usare i linguaggi nella loro completezza
  * Comprendere i costi di implementazione
    * A volte ad alto livello alcune cose difficili sembrano facili e si può migliorare l'implementazione con piccoli accorgimenti
* Capire come implementare le funzionalità non suportate esplicitamente
  * Alcune funzionalità non sono supportate su alcuni linguaggi, ma quando le abbiamo imparate possiamo implementarle esplicitamente
    * Ad esempio non c'è la ricorsione non di coda in FORTRAN ma quando abbiamo capito come la implementa il compilatore possiamo implementarla noi

Libro:
* Gabbrielli Martini "linguaggi di programmazione - principi e paradigmi"
  * Molto chiaro (rispetto agli altri)
  * Astratto, forse un po troppo formale
  * Mancano argomenti complessi (comunque abbastanza presenti)
  * Pochi riferimenti ai linguaggi più usati
* Alcuni articoli sul sito
* Michael Scott "programming language pragmatics"
* Sebasta "concept in programming language"

Esame:
* Scritto
  * Domante di teoria (se in presenza)
  * Esercizi
    * Più vari degli anni scorsi
    * Meno difficili degli anni scorsi
* Esercizi da svolgere a casa e discutere durante l'orale
* Orale obbligatorio

## Perché abbiamo tanti linguaggi di programmazione (ce ne sono letteralmente centinaia, forse migliaia)

* Abbiamo più paradigmi
  * Imperativi (Si basano sul dare alla macchina un elenco di comandi da eseguire in ordine):
    * Linguaggi di Von Neumann (Fortran, Pascal, C)
      * Vedi l'architettura di Von Neumann
    * Ad oggetti (Smalltalk, Eiffel, c++)
      * L'idea è quella di associare le istruzioni ai dati
      * Dati e metodi di accesso definiscono informazioni e sono chiamati oggetti
    * Linguaggi di scripting (Perl, Python, JS, PHP)
      * Semplici e veloci da usare per piccoli programmi
      * Usano interpreti
      * Si possono usare anche per programmi complessi
      * Funzionano bene per mettere insieme librerie prese da linguaggi differenti
  * Dichiarativi (Non dico al calcolatore che operazioni eseguire, è più astratto, dichiaro cosa devo ottenere; per scrivere programmi efficienti dserve comunque un idea di cosa fà la macchina):
    * Funzionali (Scheme, Lisp, ML, Haskell)
      * Dicharo delle funzioni composte da chiamate  ad altre funzioni
    * Logico, basato su vincoli (Prolog, RPG, VisiCalc)
      * Descrivo dei predicati che devono essere valutati
      * Il programma è un insieme di variabili con dei vincoli
        * Il programma cerca di istanziare le variabili garantendo i vincoli
      * Perdo il controllo di quello che fa la macchina, lavoro solamente sugli invarianti
* Evoluzione
  * Nel tempo soon stati definiti nuovi costrutti e tecniche di programmazione per possono facilitare la realizzazione di programmi più complessi
* Fattori economici
  * Interessi proprietari
    * Alcuni produttori realizzano i linguaggi che intendono usare (Swift, Go, C#)
  * Vantaggi commerciali
* Diverse priorità
  * Efficenza
  * Pulizia del codice
  * Flessibilità
* Diversi utilizzi
  * Calcolo scientifico (Fortran)
  * Analisi dei dati (R)
  * Sisetmi Embedded (C)
  * Applicazioni web (JS, PHP)
  * ...

## Cosa determina il successo di un linguaggio?

* Supporto
  * Librerie
  * Codice preesistente
  * Tool e IDE
* Sponsor importanti
  * Microsoft (C#, VB)
  * Apple (Obkective C, Swift)
  * Google (Go)
  * ...
* Diffusione a costi minimi / portabilità
  * JS, Java, Pascal
* Espressività, flessibilità e potenza
  * C, Lisp, APL, Perl
  * È facile scrivere del codice conoscendo l'algoritmo
* Possibilità di scrivere codice efficente e compatto
  * C, Fortran
  * È possibile scrivere codice efficiente
* Facile da implementare
  * Forth, BASIC
  * Era più importante anni fa, infatti questi due linguaggi sono molto vecchi
* Leggibilità
  * Chiarezza, naturalità, semplicità
    * È facile capire il codice senza commenti
    * Alcuni linguaggi richedono dei commenti formali
  * Supporto all'astrazione
  * Facilità di modifica del codice
* Scrivibilità
  * Simile alla espressività
  * Facile da imparare (Scheme, Pascal, BASIC)
  * Polimorfismo
    * Lo stesso codice si applica a più situazioni diverse
  * Ortogonalità
    * Cose diverse restano indipendenti
    * Ad esempio, il metodo passaggio di parametri non dipende dal tipo dei parametri
      * Non serve imparare diversi modi di passaggio che dipendono dal tipo dei dati
    * È facile integrarle
* Affidabilità
  * È facile verificare che non siano avvenuti errori
  * Se lo scopre direttamente il compilatore, anche meglio
* Costo
  * Efficienza di esecuzione del codice

## Aspetti di un linguaggio

Alcuni di questi aspetti si applicano anche ai linguaggi naturali, come sintassi, semantica e grammatica. Infatti, alcune cose come i diversi livelli di grammatica sono stati definiti da linguisti, non informatici.

* Sintassi:
  * Quali sequende di caratteri costituiscono programmi
  * Come sono strutturati
* Semantica:
  * Come si comporta un programma
  * Che efetto ha l'esecuzione del programma
  * Quale è il significato della frase
  * È l'aspetto più difficile da analizzare, soprattutto rispetto alle grammatiche
* Pragmatica:
  * L'uso tipico che si fa di un linguaggio e le sue convenzioni
  * Si nota molto quando si va a scrivere assembly, ad esempio quando osserviamo le regole che si devon orispettare nelle chiamate a funzione (quali registri usare, etc)
* Implementazione:
  * Come il codice che ho scritto viene trasformato a livello macchina
  * Si approfondisce a "linguaggi e compilatori" della magistrale
* Librerie:
  * Il codice che viene fornito insieme al linguaggio
  * Per usare un linguaggio conviene imparare a muoversi tra le sue librerie per trovare strumenti per risolvere meglio i problemi
* Tools:
  * Editor
  * Debugger
  * Gestione del codice

In questo corso vediamo prindipalmente i primi 4

## Macchina astratta

Concetto gia visto ad architetture e sistemi.

L'idea è di separare il sistema di calcolo in una gerarchia di macchine virtuali astratte $\mathcal{M}_i$.
Ogni macchina è costruita sulla precedente a partire da livello hardware. Ogni macchina è caratterizzata da un linguaggio $\mathcal{L}_i$ con cui scrivere il codice.

1. ...
2. ...
3. Sistema operativo (sistema operativo, interpretazione parziale)
4. Assembly (assemblatore, traduzione)
5. Linguaggio orientato al problema (compilatore, traduzione)

Ad esempio un programma scritto in $\mathcal{L}_{Java}$ (Java), viene scritto per la macchina astratta $\mathcal{M}_{Java}$

Questa macchina sfrutta una macchina sottostante $\mathcal{M}_{JVM}$ che esegue $\mathcal{L}_{JVM}$ (Java ByteCode).

Serve una sorta di trasformazione per passare da un linguaggio al successivo.

### Compilazione vs Interpretazione ed altre tecniche di traduzione (Panoramica)

Compilazione pura:
* Il compilatore traduce il programma sorgente di alto livello in un programmadi destinazione equivalente (spesso linguaggio macchina+SO, ma non necessariamente)
* Il sorgente ed il compilatore non sono necessari per l'esecuzione, solamente per la produzione degli eseguibili che poi sono autosuffucienti

Interpretazione pura:
* Abbiamo un programma interprete che prende come input il codice sorgente e l'input stesso e produce l'output del programma di cui abbiamo il sorgente per l'input dato.
* L'esecutore deve avere a disposizione sia l'interprete che il codice sorgente per usare il programma

Confronto:
* Compilazione
  * La compilazione ha migliori prestazione perche non deve effettuare traduzioni e controlli in fase di esecuzione
  * È possibile eseguire alcuni controlli prima di eseguire il programma
  * Per il debugging mi serve conservare il collegamento tra eseguibile e sorgente
* Interpretazione
  * L'interpretazione è molto flessibile
  * Più semplice da implementare
  * Più semplice il debugging
  * Il codice viene eseguito direttamente
  * Il programma diventa più lento rispetto ad un programma compilato

Nei casi reali si utilizza una soluzione ibrida tra compilazione ed interpretazione. Quindi la traduzione avviene in più passaggi.
Alcuni esempi:
* Java ed altri linguaggi (come Kotlin) sono compilati in un linguaggio intermedio (Java ByteCode) che non è linguaggio macchina ma ci assomiglia
  * Il linguaggio intermedio viene eseguito da un runtime (una macchina virtuale)
  * Il programma è più portabile (perché non è compilato per la macchina) e più verificabile (perché non è puramente linguaggio macchina)
  * Anche Pascal e DotNet fanno una cosa simile, ma con macchine virtuali
* Alcuni linguaggi sono sempre interpretati ma prima attraversano un preprocessing che li rende più facilmente eseguibili dall'interprete
  * Non è complessa come una compilazione, ma non è nemmeno così apptofondita, magari fa delle rinomine od altre operazioni simili
  * Può essere fatto localmente dall'interprete prima di eseguirlo perché è molto veloce
  * Può eseguire un controllo degli errori
* Quando faccio la compilazione di solito non produco direttamente puro codice macchina, ma utilizzo anche alcuni estruzioni virtuali, (ad esempio al posto di funzioni matematiche) che posson essere chiamate a funzioni di librerie o chiamate al sistema operativo (soprattuto per operationi di controllo dei processi o di I/O)
  * Quindi il compilatore non traduce direttamente a livello della macchina reale ma a livello di una macchina virtuale intermedia
  * Un programma linker si occupa di sostituire queste istruziuoni virtuali simboliche nel codice che permette alla macchina di eseguire la chiamata
* In alucni casi il compilatore non produce nemmeno il codice macchina, ma si ferma a livello dell'assembly per facilitare il debugging
  * Il codice prodotto deve poi essere assemblato e linkato da altri programmi
  * Separare in tanti passaggi la compilazione a volte si perde un po' in efficenza del codice prodotto
* Il codice C mette insieme diverse di queste tecniche
  * Prima attraversa un preprocessore che espande le macro e rende il codice più facilmente compilabile
  * Poi vinene tradotto in un linguaggio intermedio del compilatore
  * Poi produce il codice virtuale per la macchina
  * Poi viene linkato e prodotto l'eseguibile
* Compilatione dinamica JIT (just in time)
  * Viene fatto da java bytecode, da dotnet e anche da js
  * Mentre il programma è in eseguzione alcune porzioni del programma (più usate) vengono compilate in linguaggio macchina per renderle più veloci
  * Resta ugualmente flessibile e sicuro
  * Diventa più efficiente
  * È anche il caso di LISP (uno dei primi ad utilizzare JIT) e Prolog
    * Aveva particolarmente senso usare questa coda in LISP perché lisp ha la possibilità di usare stringe e dati come codice eseguibile
    * A livello di linguaggio macchina è facile, con C è facilissimo inserire codice macchina in un array, e castare l'array come puntatore a funzione
    * A livello di stringhe ad alto livello è difficile, e trae molto benificio da un compilatore dinamico che è pronto ad affrontare stringhe non compilare e codiche che cambia nel tempo
    * È male fare in modo che il codice modifichi se stesso, fai attenzione
  * Anche i processori CISC molto complicati (leggi x86) usano una tecnica di questo tipo trasformando le operazioni complesse in un codice RISC più facile ed efficiente da eseguire
    * A volte invece che trasformare l'operazione una per volta, prende un blocchetto di operazioni che vengono eseguite spesso in sequenza, le compila insieme e le mantiene nella cache

## Bootstrap

Prende il nome da un racconto del Barone Munchausen che si tira in piedi aggrappandosi ai lacci dei suoi stessi stivali.

Molti compilatori, in particolar modo C, sono scritti nello stesso linguaggio che compilano (quindi C stesso).
Spesso questo ci costringe spesso a compilare il compilatore due volte: la prima usando la versione vecchia del compilatore, che produce un nuovo compilatore che produce codice migliore, ma il codice del compilatore stesso non necessariamente è migliore. Quindi il nuovo compilatore compila di nuovo se stesso per ottenere il prodotto finale che non solo produce codice efficente, ma è anch'esso efficiente.

Serve avere una prima versione del compilatore in linguaggio macchina per compilare quelle successive, non serve che sia buona, serve che funzioni. Poi i compilatori successivi, scritti col nuovo linguaggio saranno migliori.

### Esempio, Pascal e P-Code

P-Code è un linguaggio intermedio come Java ByteCode.

Abbiamo tre strumenti:
* Compilatore Pascal scritto in Pascal $\mathcal{C}^{Pascal}_{Pascal}\rightarrow PCode$
* Compilatore Pascal scritto in P-Code $\mathcal{C}^{Pascal}_{PCode}\rightarrow PCode$
* Interprete P-Code scritto in Pascal $\mathcal{I}^{PCode}_{Pascal}$

Vogliamo (dato un linguaggio macchina) ottenere un interprete Pascal per quel particolare linguaggio macchina:
* Ci serve un interprete PCode scritto in linguaggio macchina: $\mathcal{I}^{PCode}_{LM}$
  * Facile perché PCode è un linguaggio molto semplice
* Prendiamo un programma Pascal $PrPa$
* Otteniamo una sua versione scritta in PCode $PrPC=\mathcal{I}^{PCode}_{LM}(\mathcal{C}^{Pascal}_{PCode}\rightarrow PCode,PrPa)$
* Eseguiamo il programma $\mathcal{I}^{PCode}_{LM}(PrPC,Dati)$

Il problema di questo metodo è che usare un linguaggio intermedio diminuisce l'efficienza, quindi vogliamo un compilatore per il linguaggio macchina:
* A mano trasformo il compilatore che produce PCode in uno che produce linguaggio macchina $\mathcal{C}^{Pascal}_{Pascal}\rightarrow LM$
  * Dato che buona parte del codice di un compilatore non dipende dal linguaggio di output, le modifiche da fare sono poche
* $\mathcal{C}^{Pascal}_{PCode}\rightarrow LM=\mathcal{I}^{PCode}_{LM}(\mathcal{C}^{Pascal}_{PCode}\rightarrow PCode,\mathcal{C}^{Pascal}_{Pascal}\rightarrow LM)$
* $\mathcal{C}^{Pascal}_{LM}\rightarrow LM=\mathcal{I}^{PCode}_{LM}(\mathcal{C}^{Pascal}_{PCode}\rightarrow LM,\mathcal{C}^{Pascal}_{Pascal}\rightarrow LM)$

A questo punto non mi servono più gli interpreti e gli artefatti intermedi, posso usare il mio nuovo compilatore per compilare i futuri compilatori come tutti gli altri programmi Pascal.

## Panoramica sulla compilazione (di nuovo)

La compilazione è divisa in due fasi:
* Front end
  * Esegue una scansione lessicale dello stream di caratteri producendo un token stream
  * Esegue un parse e una analisi sintattica del token stream producendo un albero di parsing
  * Produce un codice intermedio simil macchina partendo dall'albero di parsing
* Back end
  * (Esegue sul codice intermedio delle prime ottimizzazioni dipendenti dalla macchina producendo del codice intermedio modificiato)
  * Prododuce il codice per la macchina target partendo dal codice intermedio modificato
  * (Esegue delle altre ottimizzazioni dipendenti dalla macchina modificando il codice prodotto per la macchina target)
* Tutto questo appoggiandosi ad una tabella dei simboli per mantenere tutti i simboli che vengono definiti nel programma

### Scanner, analisi lessicale

È un lavoro semplice. Divide il programma in lessemi. In pratica esegue i DFA dei vari lessemi per vedere quali riconoscono.

Ad ogni lessema viene associato un token che lo cataloga e gli assegna un valore.

Serve più che altro a semplificare le fasi successive che altrimenti dovrebbero anche occuparsi dell'identificazione dei token.

Gli identificatori sono espressi da un linguaggio regolare che li rappresenta.
Lo scanner prova tutti i DFA in contemporanea (formalmente), in realtà li mette insieme in un solo DFA più grande che trova quale dei singoli DFA riconosce la stringa più lunga.

### Parser, analisi sintattica

Analizza l'intero programma definendo la sua struttura ad albero. Utilizza un automa a pila deterministico.

#### Analisi semantica

Esegue alcuni controlli statici sul codice come il type checking che il parser non riesce a fare.

Usa le grammatiche libere dal contesto.

Alcuni controlli devono essere fatti durante l'esecuzione, si tratta di controlli dinamici.

### Modulo intermedio

È quello che produce il codice intermedio indipendente dalla macchina.

Il modulo dell'analisi semantica produce un albero di parsing. Il modulo intermedio traduce questo albero in un linguaggio speciale simile al linguaggio macchina.

### Ottimizzazione 1

 Trasforma il programma in codice intermedio in un programma equivalente che sia più veloce o con meno memoria
.

È facoltativo.

### Traduzione in linguaggio macchina od assembly

Questo modulo trasforma il codice in linguaggio intermedio in vero codice assebly o in linguaggio macchina, a seconda del compilatore.

### Ottimizzazione 2

Stesso principio della prima, ma sul codice per la macchina.

### Tabella dei simboli

La tabella dei simboli è una struttura di supporto utilizzata da tutte le fasi. Questa tabella contiene tutti gli identificatori e quello che il compilatore sa su di loto
Le fasi successive potranno accedere a queste informazioni ed eventualmente ad arricchire la tabella con altri identificatori ed informazioni.

Per facilitare il debugging è possibile mantenere la tabella dei simboli dopo la compilazione
