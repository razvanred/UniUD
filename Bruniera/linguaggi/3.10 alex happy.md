# Alex ed Happy

Sono le alternative haskell, dei tool lex e yacc per C.
Alex si usa per lo scanner (analisi lessicale), che trasforma il flusso di caratteri in un flusso di lessemi. Happy si usa per il parser (analisi sintattica), che riconosce grammatiche libere dal contesto.

Su lex/yacc si specificavano una serie di regole lessico-sintattiche, e si associava del codice C da eseguire. Questi tool cercano di replicare questo comportamento ma per Haskell.

## Alex

In più, rispetto a lex, prevede l'utilizzo di un tipo dei token, che su lex non era presente perché poi i token venivano rappresentati come interi.

```Alex
{ -- codice da mettere in testa (non importa molto l'ordine)
  module Main (main) where
  -- Nota che solo il modulo e gli import possono stare in questa parte del codice
}

%wrapper "basic" -- definisce il tipo di scanner (ce ne sono tre, questo è quello più basilare)

-- dichiarazioni ausiliarie
$digit = 0-9
$alpha = [a-xA-Z]   -- insiemi di caratteri (iniziano col dollaro)
@num   = $digit+    -- espressioni regolari (iniziano col et)

-- nome e separatore dell'inizio delle regole (su lex si usava % come separatore)
tokens :-

-- regole nella forma `regex azione`
let {\s -> TokenLet}
$white+ ; -- non fa niente
@num {\s -> TokenInt (read s) }
[\=\+\-\*] {\s -> TokenSym (head s)}
...

{
data Token = TokenLet | TokenIn | TokenSym Char | TokenVar String | TokenInt Int
    deriving (Eq, Show)

-- Viene prodotta la funzione:
alexScanToken :: String -> [Token]

-- Il main deve essere presente se vogliamo avere un programma a se stante
main = do
    s <- getContents
    print (alexScanTokens s)
}
```

La sintassi ricorda quella di lex, ma Haskell rende alcune operazioni più facili per il programmatore.

### Parser: basic

* Più semplice
* Fornisce la funzione `alexScanTokens :: String -> [Token]`
* Tutte le azioni devono essere di tipo `String -> Token`

### Parser: posn

* Permette di sfruttare anche la posizione della stringa, non solo la stringa
  * Necessario per linguaggi in cui l'identazione conta, come Haskell o Python
* Le posizioni sono fornite col tipo `AlexPosn`
  * `data AlexPosn = AlexPn !Int !Int !Int`
  * Gli interi rappresentano (nell'ordine): offset assoluto, riga, colonna
* Il resto resta lo stesso di basic
* Le azioni devono essere di tipo `AlexPosn -> String -> Token`
* Fornisce la funzione `alexScanTokens :: String -> [Token]`
  * Quindi informazioni rilevanti sulla posizione vanno incluse nel token

## Happy

Happy è l'analizzatore sintattico, e si sostituisce a Yacc su C. Interagisce con uno scanner generato da Alex e produce l'albero di derivazione, o comunque la struttura della stringa che viene passata in input.
In un certo senso assomiglia alla funzione Read, ma quest ultima produce un automa a pila non deterministico poco efficente. Mentre Happy produce un automa deterministico LALR più efficiente.

Vuole i file che finiscono con `.y` come yacc.

Presentiamolo con un esempio:
* Scriviamo un parser che risonosca una grammatica delle espressioni aritmetiche
* Che supporti:
  * Variabili
  * Interi
  * Operatori aritmetici
  * Costrutto `let var = exp in exp`

```Happy
{
    module Main where
    import Data.Char
}

%name calc -- Nome della funzione generata
%tokentype {Token} -- Tipo di token restituito da Alex (input di Happy)
%error {parseError} -- Funzione di gestione degli errori

-- Lista dei non terminali
%token
    let {TokenLet}
    in  {TokenIn}
    int {TokenInt $$}
    var {TokenVar $$}
    '=' {TokenEq}
    '+' {TokenPlus}
    '-' {TokenMinus}
    '*' {TokenTimes}
    '/' {TokenDiv}
    '(' {TokenOb}
    ')' {TokenCb}

-- Regole
%%
Exp : let var '=' Exp in Exp    {Let $2 $4 $6}
    | exp1                      {Exp1 $1}
    
Exp1 : Exp1 '+' Term    {Plus $1 $3}
     | Exp1 '-' Term    {Minus $1 $3}
     | Term             {Term $1}

Term : Term '*' Factor  {Times $1 $3}
     | Term '/' Factor  {Div $1 $3}
     | Factor           {Factor $1}

Factor : int            {Int $1}
       | var            {Var $1}
       | '(' Exp ')'    {Brack $2}

{
-- Funzione di gestione degli errori
parseError _ = error "Parse Error"

-- Definisco i tipi utilizzati
data Exp = Let String Exp Exp
         | Exp1 Exp1
         deriving (Eq,Show)

data Exp1 = Plus Exp1 Term
          | Minus Exp1 Term
          | Term Term
          deriving (Eq,Show)

data Term = Times Term Factor
          | Div Term Factor
          | Factor Factor
          deriving (Eq,Show)

data Factor = Int Int
            | Var String
            | Brack Exp
            deriving (Eq,Show)

-- Definisco il tipo dei token
data Token = TokenLet
           | TokenIn
           | TokenInt Int
           | TokenVar String
           | TokenEq
           | TokenPlus
           | TokenMinus
           | TokenTimes
           | TokenDiv
           | TokenOB
           | TokenCB
           deriving (Eq,Show)


-- lexer è la funzione che trasforma la stringa di caratteri in una stringa di token
main = do inputString <- getContents
          print (calc (lexer inputString))

-- Il lexer posso produrlo in due modi: con Alex oppure a mano
lexer = alexScanTokens
-- Se faccio così il tipo token va inserito nel file alex, e poi importato

-- Oppure
lexer [] = []
lexer (c:cs)
      | isSpace c = lexer cs
      | isAlpha c = lexVar (c:cs)
      | isDigit c = lexNum (c:cs)
lexer ('=':cs) = TokenEq : lexer cs
...
-- Preferiamo usare Alex, visto che sarebbe lo scopo del corso
}  
```

### Valutare la stringa in ingresso

Facciamo riferimento al programma dell'esempio.

La difficoltà sta nella gestione delle variabili con let. Bisogna gestire un ambiente, implementato come lista.

```Happy
%%
Exp : let var '=' Exp in Exp    {/p -> $6 (($2,$4 p):p)}
    | exp1                      {$1}
    
Exp1 : Exp1 '+' Term    {\p -> $1 p + $3 p}
     | Exp1 '-' Term    {\p -> $1 p - $3 p}
     | Term             {$1}

Term : Term '*' Factor  {\p -> $1 p * $3 p}
     | Term '/' Factor  {\p -> $1 p `div` $3 p}
     | Factor           {$1}

Factor : int            {\p -> $1}
       | var            {\p -> case lookup $1 p of
                                    Nothing -> error "no var"
                                    Just i -> i}
       | '(' Exp ')'    {$2}

```

### Parsing sequences

Il caso tipico è quello di gestire una sequenza di comandi.
Ci sono due modi tipici molto semplici, che hanno diverse utilità.

```Happy
%%
-- left recursion
-- efficiente
-- inverte la lista
Prods : Prod        {[$1]}
      | Prods Prod  {$2 : $1}

-- Right recursion
-- usa più spazio
-- mantiene l'ordine
Prods : Prod        {[$1]}
      | Prod prods  {$1 : $2}
```

### Precedenze

Possiamo anche scrivere grammatiche ambigue, ma dobbiamo indicare le precedenze, altrimenti Happy decidera quello che gli fa più comodo, che potrabbe non essere quello che vogliamo noi.

Per decidere le precedenze si indica il metodo di associatività dei simboli, e poi si va in base all'ordine. Le regole più in basso vengono prima, mentre quelle più in alto vengono dopo.

```Happy
%right in           -- associa a destra
%nonassoc '<' '>'   -- non associa
%left '+' '-'       -- associa a sinistra
%left '*' '/'
%left NEG           -- NEG non è un token
%%
Exp   : let var '=' Exp in Exp  { Let $2 $4 $6 }
      | Exp '+' Exp             { Plus $1 $3 }
      | Exp '-' Exp             { Minus $1 $3 }
      | Exp '*' Exp             { Times $1 $3 }
      | Exp '/' Exp             { Div $1 $3 }
      | '(' Exp ')'             { $2 }
      | '-' Exp %prec NEG       { Negate $2 } -- %prec NEG indica di dare a questa operazione la precedenza di NEG
      | int                     { Int $1 }
      | var                     { Var $1 }
```
