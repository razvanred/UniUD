# Programmi paralleli con variabili condivise

Estendiamo il linguaggio dei programmi paralleli disgiunti, permettendo di condividere le variabili, ma dobbiamo aggiungere un nuovo costrutto per poter sincronizzare i programmi.

* $<S>$ è una regione atomica, avviene come un unica operazione
  * Non possono comparire while, per garantire che ogni regione atomica termini in tempi ragionevoli
  * In più, alcune operazioni semplici sono considerate atomiche
* $[S_1|...|S_n]$ è un programma parallelo senza restrizioni sulle variabili

## Semantica operazionale


Aggiungiamo le regole di transizione:

$$
\begin{align}
& \frac{\langle S,\sigma\rangle\rightarrow^*\langle E,\tau\rangle}{\langle<S>,\sigma\rangle\rightarrow\langle E,\tau\rangle} & \text{sezione atomica}\\
&\frac{\langle S_i,\sigma\rangle\rightarrow\langle S'_1,\tau\rangle}{\langle[S_1 | ... | S_i | ... | S_n],\sigma\rangle\rightarrow\langle[S_1 | ... | S'_i | ... | S_n],\tau\rangle} & \text{interleaving}
\end{align}
$$

In questo linguaggio si possono avere diversi stati finali, infatti non vale la proprieta $\diamond$. Si dimostra con un controesempio
Componenti sequenziali I/O-equivalenti tra loro $S_1,S_2$, si comportano in modo diverso quando sono eseguire in parallelo con la stessa componente $[S_1,S'],[S_2,S']$.

## Proprietà

> ***Lemma (assenza di deadlock)***: Per ogni $\langle S,\sigma\rangle$ con $S\neq E$, si ha $\exist \langle S',\sigma'\rangle.\langle S,\sigma\rangle\rightarrow\langle S',\sigma'\rangle$

> ***Lemma (non-determinismo limitato)***: Un programma può avere stati finali finiti, oppure può non terminare
>
> Si dimostra applicando il lemma di Koenig al lemma di finitezza

> ***Lemma (koenig)***: Un albero finitamente ramificato è finito (nel numero di nodi), oppure ha un cammino infinito
>
> Si dimostra per induzione su un ramo infinito

> ***Lemma (finitezza)***: Per ogni $\langle S,\sigma\rangle$, si ha un numero finito di successori. Quindi l'albero delle configurazioni è finitamente ramificato
>
> Si dimostra per casi sulla semantica

## Interferenza

Prendiamo come esempio i programmi `x:=x+2` e `x:=0`. Valgono le triple:

$$
\{x=0\}~\mathrm{x:=x+2}~\{x=2\}\\
\{true\}~\mathrm{x:=0}~\{true\}
$$

Ora consideriamo il programma `[x:=x+2 | x:=0]`. Può succedere che anche se partiamo da uno stato con $x=0$ comunque non terminiamo in uno stato con $x=2$, perché l'assegnamento `x:=0` potrebbe essere eseguito dopo di `x:=x+2`. Quindi *non* possiamo derivare la tripla $\{x=0\}~\mathrm{[x:=x+2 | x:=0]}~\{x=2\}$.

Si dice che i programmi hanno **Interferenza**.

## Proof outline

Una proof outline è un programma annotato con delle asserzioni. Le asserzioni sono posizionate tra un sottoprogramma e l'altro i e indicano una proprietà che deve essere vera eseguendo il programma fino alla posizione in cui si trova l'asserzione. In altre parole, l'asserzione deve essere vera quando il controllo di flusso arriva a quel punto del codice.
Indichiamo che un programma è annotato usando una star $^*$

Queste asserzioni sono post-condizioni dei sottoprogrammi precedenti, e pre-condizioni di quelli successivi, quindi suggeriscono un modo di separare il programma in triple di hoare derivabili indipendentemente.

> ***Definizione (outline standard)***: Una proof outline $\{p\}~S^*~\{q\}$ è in forma standard se ogni sottoprogramma di $S^*$ è preceduto e seguito da esattamente una asserzione

//TODO

## Resto di un programma

Definiamo formalmente alcuni concetti che abbiamo già descritto intuitivamente:

> ***Definizione***: Sia $T$ un sottoprogramma di $S$, definiamo $at(T,S)$ il resto del programma $S$ quando il controllo si trova all'inizio del sottoprogramma $T$ per induzione sulla struttura di $S$:
> * Se $S=S_1;S_2$
>   * Se $T$ sottoprogramma di $S_1$, allora $at(T,S)=at(T,S_1);S_2$
>   * Se $T$ sottoprogramma di $S_2$, allora $at(T,S)=at(T,S_2)$
> * Se $S=\mathrm{if}~B~\mathrm{then}~S_1~\mathrm{else}~S_2~\mathrm{fi}$, con $i\in\{1,2\}$ e $T$ sottoprogramma di $S_i$, $at(T,S)=at(T,S_i)$
> * Se $S=\mathrm{while}~B~\mathrm{do}~S'~\mathrm{od}$ e $T$ sottoprogramma di $S'$, allora $at(T,S)=at(T,S');S$
> * Se $S=T$, $at(T,S)=S$

## Correttezza forte

> ***Teorema***: Sia $\{p\}~S^*~\{q\}$ standard. Se $\langle S,\sigma\rangle\rightarrow^*\langle R,\tau\rangle$ dove $\sigma\vDash p$ allora:
> * $R\equiv at(T,S)$, $T$ sottoprogramma di $S$ $\implies\tau\vDash pre(T)$ 
> * $R\equiv E\implies\tau\vDash q$

## Non interferenza

> ***Definizione***: Sia $S$ una componente,  $\{p\}~S^*~\{q\}$ una standard proof outline, $R$ un comando con precondizione $pre(R)$. $R$ non interferisce con  $\{p\}~S^*~\{q\}$ sse per ogni asserzione $r$ in  $\{p\}~S^*~\{q\}$, la formula $\{r\lor pre(R)\}~R~\{r\}$ è vera
>
> In pratica, se per ogni asserzione nella proof outline, il comando $R$ non invalida l'asserzione

> ***Definizione***: Sia $[S_1|...|S_n]$ un programma parallelo. Gli standard proof outline  $\{p_i\}~S_i^*~\{q_i\}$ si dicono privi di interferenza se, per ogni $i\neq j$, nessuna regione atomica di $S_j$ interferisce con $\{p_i\}~S_i^*~\{q_i\}$

## Incompletezza

Il sistema PD, unito alla regola per il parallelismo non permette di derivare tutte le proof outline vere. Ad esempio non si può derivare la formula $\{true\}~[x:=x+2|x:=0]~\{x=0\lor x=2\}$ anche se è vera. Questo perché $\{true\}~x:=x+2~\{true\}$ e $\{true\}~x:=0~\{x=0\lor x=2\}$ sono interferenti.

Come abbiamo fatto per il parallelismo disgiunto, vorremmo aggiungere alcune regole per rendere il sistema completo. Partiamo dalle variabili ausiliarie.

Consideriamo l'outline $\{true\}~d:=false;[<x:=x+2;d:=true>|x:=0]~\{x=0\lor x=2\}$. Vogliamo dimostrare individualmente $\{true\}~d:=false~\{\lnot d\}$ e $\{\lnot d\}~[<x:=x+2;d:=true>|x:=0]~\{x=0\lor x=2\}$.

Quindi costruiamo le outline $\{\lnot d\}~<x:=x+2;d:=true>~\{d\}$ e $\{true\}~x:=0~\{\lnot d\rightarrow x=0\land d\rightarrow (x=0\lor x=2)\}$. La dimostrazione è diventata più complicata, ma ora è possibile. Bisogna dimostrare la non interferenza.