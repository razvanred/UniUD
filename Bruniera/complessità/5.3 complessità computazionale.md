# Complessità computazionale

Ci concentriamo su problemi di decisione. Ci sarebbero anche problemi funzionali e di ottimizzazione.

Se ho un algoritmo veloce per la parte funzionale, abbiamo anche un algoritmo veloce per la decisione. Se ne ho uno veloce per l'ottimizzazione, ne ho anche uno veloce per la parte funzionale.
Viceversa, se la parte di decisione è difficile, lo saranno anche quella funzionale e di ottimizzazione.

Parliamo di algoritmi che leggono un messaggio e dicono se appartiene o meno ad un linguaggio.
Valuteremo sia la complessità di spazio che di tempo.

## Complessità di tempo

Siano un problema $P$ ed un modello di calcolo $M$.\
Cerchiamo in $M$ la più veloce macchina/algoritmo $m$ che risolve $P$. Più veloce significa che richiede meno istruzioni.\
Bisogna definire una *dimensione dell'input*. La dimensione dovrebbe essere definita dal modello di calcolo.

Non serve cambiare la dimensione dell'input e la complessità per ogni modello di calcolo che ci interessa, perché la *tesi di Church-Turing estesa* riporta che tutti i modelli di calcolo ragionevoli sono legati polinomialmente.
Quindi Se un problema ha complessità $\Theta(f(n))$ nel modello ragionevole migliore per quel problema, sarà $\Theta(P(f(n)))$ per ogni altro modello ragionevole, dove $P$ è una qualche funzione polinomiale.

Ci serve un modello di calcolo ragionevole da usare come base.

### Unregistered Turing Machine (URM) (con prodotto)

Sono macchine con un set di registri illimitato, in ciascuno di questi registri $r_i$ si trova un naturale arbitrariamente grande.

Il set di istruzioni di queste macchine è:
* `S(i)` = incrementa il registro $r_i$
* `Z(i)` = azzera il registro $r_i$
* `T(i,j)` = copia il contenuto del registro $r_i$ nel registro $r_j$
* `J(i,j,k)` = se il contenuto di $r_i$ e $r_j$ è uguale, salta alla riga $k$

Se il problema è incrementare un intero, nelle MdT il problema ha complessità $O(n)$, nelle URM è una singola istruzione e la complessità è $O(1)$.

Questo succede perché le URM nascondono la dimensione dell'input, perché incrementare un numero ha sempre lo stesso costo a prescindere della lunghezza del numero. Per questo vengono costi troppo bassi.\
$O(n)$ e $O(1)$. sono molto diversi, ma sono comunque legati polinomialmente


Se ho una "URM con prodotto" diventa anche peggio. Aggiungiamo l'istruzione $P(i)$ che moltiplica il contenuto del registro $r_i$ a se stesso.

Possiamo scrivere il programma:
1. `T(0,1)`
2. `J(1,2,6)`
3. `P(0)`
4. `S(2)`
5. `J(3,3,2)`

Questo programma calcola $x^{2^i}$. Nelle URM con prodotto ha complessità $O(x)$, mentre nelle MdT ha costo $\Omega(2^x\log(x))$. Non sono legati polinomialmente.

Questo non significa che non possiamo usare le URM o non possiamo usare le moltiplicazioni, significa che il costo delle operazioni di base non dovrebbe essere uniforme.

#### Uniform Complexity Cost

Ogni istruzione del modello di calcolo ha complessità $\Theta(1)$.

Non è ragionevole quando una operazione di base fa crescere l'input troppo velocemente (ad esempio la moltiplicazione).\
Per le MdT è ragionevole.

#### Logarithmic Complexity Cost

Ogni istruzione del modello ha complessità che dipende dal numero di cifre che manipola.

Per le MdT questo metodo degenera nel costo uniforme, perché ogni istruzione manipola fino ad un numero costante di cifre (il numero di nastri).\
È utile quando ci sembra che il nostro modello possa essere troppo veloce.

* `S(i)` $O(\log(r_i))$
* `Z(i)` $O(1)$
* `T(i,j)` $O(\log(r_i))$
* `J(i,j,k)` $O(\min(\log(r_i),\log(r_j)))$
* `P(i)` $O((\log(r_i))^2)$

### Speed-up theorem

> Se $L\in TIME(f(n))$, allora\
> $\forall_{\varepsilon>0}~L\in TIME(\varepsilon f(n)+n+2)$\
> ($f'(n)=\varepsilon f(n)+2n+2$, non è una derivata)\
> Questo significa che possiamo ignorare le costanti moltiplicative e i termini di grado più basso.

***Dimostrazione***: Data una macchina $M$ ad 1 nastro che riconosce un linguaggio in tempo $f(n)$, esiste una macchina $M'$ a 2 nastri che lo riconosce in tempo $f'(n)$. (se fosse una macchina a più di 1 nastro, non avrei bisogno di nastri aggiuntivi)

la macchina $M'$ deve simulare $m$ passi di $M$ in un numero costante di step. 7 step di $M'$ sono un macro-step, e con questi devo simulare un numero $m$ arbitrariamente grande di step di $M$ ($\varepsilon=\frac7m$).

In $m$ step, la macchina $M$ può modificare al più $m$ simboli sul nastro. Perché la macchina $M'$ possa modificare $m$ simboli in circa un passaggio, serve che questi $m$ simboli di $M$ siano solo un macro-simbolo per $M'$. L'alfabeto di $M'$ è $\Sigma^m$. Inizio copiando i simboli in macro-simboli sul secondo nastro (entrambe le macchine devono riconoscere lo stesso linguaggio, che è scritto in $\Sigma$), le $2n+2$ operazioni servono per questa riscrittura.\
In $m$ step della macchina $M$, possono essere modificati al massimo 2 macro-simboli, quindi solo i due macro-simboli adiacenti possono influenzare la macro-operazione sul macro-simbolo corrente.\
La macchina $M'$ può prima leggere i 3 macro-simboli (corrente, a sinistra, a destra) in soli 3 passaggi, e ricorda i loro valori nello stato della macchina. Modifica al massimo 2 dei macro-simboli in altri 3 passaggi, in 1 ultimo passaggio potresti dover cambiare posizione.

## Complessità di spazio

Per la complessità di spazio serve definire le I/O-TM. È una MdT dove ho, oltre ai soliti nastri generici, due nastri speciali:
* Nastro di input:
  * Può essere letto quante volte voglio, ma mai scritto
  * Non posso andare oltre il primo blank
* Nastro di output:
  * Può essere scritto una sola volta e si può solo andare a destra
  * Non può essere letto

Per una MdT non I/O è semplicemente la somma delle lunghezze dei nastri nell'ultima configurazione. (Dopo che un certo nastro ha usato una cella, resta nella configurazione fino alla fine).\
Con questa definizione, tutte le macchine hanno costo almeno lineare. Potremmo fare di meglio, ma così non ce ne accorgeremmo mai.

Nelle I/O-TM non si contano i nastri di input ed output nella complessità di spazio.

Prendiamo come esempio i palindromi, abbiamo visto che per deciderlo con una MdT normale il costo di spazio è lineare.\
Con una I/O-TM con 4 nastri possiamo scrivere un carattere da controllare su un nastro, ed un contatore in un altro nastro per sapere quale carattere leggere. Ora il costo di spazio è logaritmico. Ovviamente il costo di tempo è aumentato, perché stavamo ottimizzando lo spazio.

Prendendo come esempio la somma, possiamo usare un metodo simile ed usare un contatore per sapere di quanto spostarci, ed il carry su un altro nastro.
Il nastro di output si può scrivere solo da sinistra a destra, quindi dobbiamo computare per ogni bit tutta la somma e poi scrivere solo il più significativo.\
Il costo è di nuovo logaritmico.

> Una I/O-k-MdT $M$ decide $L$ in spazio $f(n)$ se $\forall_x~|x|=n$, si ha che $M(x)\downarrow$ usando al massimo spazio $f(n)$.\
> $$L\in SPACE(f(n))\iff\exists_M~M~\text{decide}~L~\text{in spazio}~f(n)$$

Non è detto che esista un algoritmo efficiente sia in tempo che in spazio, a volte per ottimizzare uno bisogna rinunciare all'altro.

Esiste uno speed-up theorem per lo spazio, ma non lo vedremo. Dimostra che $L\in SPACE(f(n))\Rightarrow\forall_{\varepsilon>0}~L\in SPACE(\varepsilon f(n)+2)$.

## Random Access Machines (RAM)

Sono un modello di calcolo alternativo alle MdT, più facile da programmare.\
Una RAM ha dei set illimitati di registri illimitati: working set, ed input set.

Il set di istruzioni è:
* Input
  * `READ J` Assegna al registro 0 il contenuto del registro **di input** J
  * `READ !J` (doveva essere $\uparrow J$) Assegna al registro 0 il contenuto del registro **di input** scritto in J, indirizzamento indiretto
* Scrittura
  * `STORE J` Assegna a J il contenuto di 0
  * `STORE !J` Assegna al registro scritto in J il contenuto di 0
* Lettura
  * `LOAD J` Come `READ` ma legge dai registri di lavoro
  * `LOAD !J` Come `READ` ma legge dai registri di lavoro
  * `LOAD =J` Scrive il numero J in 0 (senza indirizzamento)
* Operazioni aritmetiche
  * `ADD J` Incrementa 0 del contenuto di J
  * `ADD !J` Incrementa 0 del contenuto del registro scritto in J
  * `ADD =J` Incrementa 0 di J
  * `SUB J` Decrementa 0 del contenuto di J
  * `SUB !J` Decrementa 0 del contenuto del registro scritto in J
  * `SUB =J` Decrementa 0 di J
  * `HALF` Dimezza (per difetto) il contenuto di 0
* Controllo di flusso
  * `JUMP J` Imposta il program counter a J
  * `JPOS J` Imposta il program counter a J se il contenuto di 0 è positivo (strettamente)
  * `JNEG J` Imposta il program counter a J se il contenuto di 0 è negativo
  * `JZERO J` Imposta il program counter a J se il contenuto di 0 è 0
  * `HALT` Imposta il program counter a 0 (stop)

In una RAM, la configurazione sono il program counter, ed il set di registri di lavoro: $C=(k,R)$. $k$ è il counter, mentre $R$ è il set di tutti i registri che sono stati modificati finora nella forma $(R_{J_i},r_{J_i})$, gli altri registri contengono 0.
I registri di input non fanno parte della configurazione.

Uno step di computazione del programma $P$ con input $I$ è una funzione che mappa $(k,R)\mapsto^{P,I}(k',R')$.
Uno step è definito dall'istruzione alla posizione $k$, ad esempio se alla posizione 4 abbiamo `ADD 7`, lo step è $(4,R)\mapsto^{P,I}(5,(R\setminus\{(R_0,r_0)\})\cup\{R_0,r_0+r_7\})$.\
Quando voglio indicare che sono eseguiti $l$ step posso scrivere $C\mapsto^{P,I^l}C'$. Quando non mi interessa il numero di step posso scrivere $C\mapsto^{P,I^*}C'$

La funzione eseguita da una RAM $P$ è $\Phi:D\mapsto\N$ dove il dominio $D\subseteq\N^h$, se $\forall_{I\in D}~(1,\emptyset)\mapsto^{P,I^l}(0,R)$ dove $l$ è finito e $(R_0,\Phi(I))\in R$.

Una RAM $P$ su un input $I$ termina in tempo $t$ se $(1,\emptyset)\mapsto^{P,I^t}(0,R)$.\
Una RAM $P$ opera in tempo $f(n)$ se per ogni input $I$ di lunghezza $n$ termina in tempo $f(n)$.\
*È un costo di tempo uniforme.*

### Simulare MdT con RAM

Una MdT opera su stringhe $\sigma_1,...,\sigma_n$ di un alfabeto $\Sigma$, devo definire $D_\Sigma=\{(i_1,...,i_n,0):n\geq0~\forall_{1\leq J\leq n}~1\leq i_J\leq l\}$. In pratica, le stringhe di $\Sigma$ sono codificate come tuple di interi e terminate da 0 (al posto del blank).

Una RAM $P$ simula la MdT $M$ (che decide $L$) se $P$ calcola $\Phi_L:D_\Sigma\mapsto\N$ dove $\Phi_L(i_1,...,i_n,0)=\begin{cases}1&\sigma_1,...,\sigma_n\in L\\0&\sigma_1,...,\sigma_n\notin L\end{cases}$.

> **Teorema**: Se $L\in TIME(f(n))$, allora esiste una RAM $P$ che calcola $\Phi_L$, che opera in tempo $O(f(n))$.
> 
> **Dimostrazione**: Sia $M=(\Sigma, K, \delta, o)$ la MdT che decide $L$ in tempo $f(n)$. Vogliamo descrivere una RAM $P$ che la simuli (codice sotto).
> $P$ deve iniziare copiando i simboli dai registri di input a quelli di lavoro, userà quelli di lavoro come il nastro di $M$.
> Dopo di che, visto che $|\Sigma|$ e $|K|$ sono prestabiliti, ad ogni step posso fare un loop che legge un simbolo ad una posizione, confronta tutti i simboli con quello corrente, aggiorna la posizione del nastro, e salta al blocco di codice che gestisce un altro stato tutto questo in tempo $O(1)$ (perché appunto le cardinalità sono fisse). Eseguo questi step fino alla fine della computazione.\
> La RAM opera in $O(f(n))+O(n)=O(f(n))+O(|x|)=O(f(n))$

1. -- (configurazione iniziale)
2. STORE 1
3. LOAD =$x$ ($x$ è il numero di registri che mi servono per decidere ogni step)
4. STORE 2
5. -- (loop che copia l'input)
6. READ !1
7. STORE !2
8. STORE 3
9. LOAD 1
10. ADD =1
11. STORE 1
12. LOAD 2
13. ADD =1
14. STORE 2
15. LOAD 3
16. SUB =$\sigma_0$ ($\sigma_0$ è il naturale che rappresenta il carattere 0)
17. JZERO 19
18. JUMP 5
19. -- (configurazione stato iniziale)
20. LOAD =k (stato iniziale di $M$)
21. STORE 1
22. LOAD =$x+1$ (posizione iniziale)
23. STORE 2
24. LOAD =$\sigma_\triangleright$ (carattere iniziale)
25. STORE 3
26. -- (blocco di codice dello stato iniziale)
27. ...
28. -- (blocco dello stato 2)
29. ...
30. ...

### Simulare RAM con MdT

> **Teorema**: Se $P$ è una RAM che calcola una funzione $\Phi$ in tempo $f(n)$, esiste una 7-I/O-TM che calcola $\Phi$ in tempo $O(f(n)^3)$.
> 
> **Dimostrazione**: Il primo nastro è input. Il secondo nastro contiene $R$ (l'insieme di coppie registro-valore che contiene i registri modificati finora), può essere codificato come un elenco di stringhe separate da blank e finisce dove ci sono due blank. Il terzo nastro contiene il program counter. Quarto, quinto e sesto sono per le operazioni aritmetiche. Settimo è output, quindi al termine della computazione conterrà $r_0$.\
> Possiamo costruire una macchina $M$ che simuli ogni istruzione di una RAM su questi nastri. Descrizione sotto.

Le operazioni più difficili sono quelle aritmetiche con indirizzamento indiretto, il resto segue. L'esempio sarà `ADD !J` che calcola $r_0=r_0+r_{r_j}$, tutte le altre impiegheranno meno tempo:
1. Scansiono il secondo nastro per trovare $r_0$ e lo copio sul nastro 4.
2. Scansiono il secondo nastro per trovare $r_j$ e lo copio sul nastro 6.
3. Scansiono il secondo nastro per trovare $r_{r_j}$ e lo copio sul nastro 5.
4. Eseguo la somma tra i nastri 4 e 5, scrivendo il risultato sul nastro 6.
5. Scansiono il secondo nastro per copiare il contenuto del nastro 6 nel registro $r_0$

Nastri:
1. $\triangleright b(\pi_1)\sqcup b(\pi_2)\sqcup... \sqcup\sqcup$ input
2. $\triangleright b(i)\sqcup b(r_i)\sqcup ... \sqcup\sqcup$ memoria
3. $\triangleright b(k)\sqcup$ program counter
4. $\triangleright (r_0)\sqcup$
5. $\triangleright b(r_{r_j})\sqcup$
6. $\triangleright b(r_j)\sqcup$ poi diventa $\triangleright b(r'_0)\sqcup$
7. $\triangleright b(r_0)\sqcup$ valore finale

Ad un passo $t$ che manipola $r_i$, la ***lunghezza*** di $i$ ed $r_i$ non può superare (per eccesso, molto grossolanamente) $l(I)+l(B)+t$, dove $l(I)$ è la lunghezza dell'input (in "bit"), ed $l(B)$ è la lunghezza della più grande costante che compare nel programma. Perché l'operazione più potente che ho è la somma, ed al massimo aggiunge un bit al valore più grande che la macchina conosce.\
Il secondo nastro di $M$ alla fine della computazione contiene al massimo $f(n)$ registri lunghi $f(n)$, quindi in totale è lungo $O(f(n)^2)$.\
In totale servono $f(n)$ macro-passi di costo $O(f(n)^2)$, per un costo complessivo di $O(f(n)^3)$.

La moltiplicazione è un'operazione pericolosa, permette ai valori dei registri di crescere troppo. Ma la nostra RAM ha solo la somma, quindi (non solo per questo) è correlata polinomialmente alle MdT.\
Se avesse la moltiplicazione non lo sarebbe.

## MdT non deterministiche

Ripasso: nelle MdT normali la funzione di transizione era una *funzione* $\delta:K\times\Sigma^k\mapsto\Sigma^k\times(K\cup\{yes,no,halt\})\times\{-,\leftarrow,\rightarrow\}^k$.\
In una macchina non deterministica non è una funzione ma una *relazione binaria di transizione*. La conseguenza è che lo stesso elemento di $K\times\Sigma^k$ non mappa ad un solo elemento di $\Sigma^k\times(K\cup\{yes,no,halt\})\times\{-,\leftarrow,\rightarrow\}^k$ ma potrebbe essere in relazione con più di uno od anche nessuno, e la macchina potrebbe passare ad uno qualsiasi di quegli stati.\
È un po' diverso da come le abbiamo viste a fondamenti.\
Le macchine non deterministiche non esistono (per ora almeno), nemmeno i computer quantistici sono non deterministici.

Non sono macchine "ragionevoli" (con la definizione di prima) ma hanno delle proprietà matematiche interessanti.

Quali sono i problemi risolvibili *efficientemente* con una ND-MdT? Per rispondere dobbiamo definire le complessità di tempo e spazio.

### Complessità di tempo

Alcune definizioni:
* La configurazione è uguale, l'unica differenza è che applicare una transizione più avere più configurazioni successive e la computazione potrebbe proseguire su una qualunque di quelle
* Il numero di configurazioni successive per una data configurazione è detto *grado di non determinismo* ed è indicato con $h$
  * Una macchina normale è una ND-MdT con $h=1$
* In questo corso trattiamo macchine che terminano sempre, quindi il grafo di computazione è aciclico, però possono esserci cross-edge e forward-edge
  * Il grafo della computazione è un DAG
* La complessità di tempo di una ND-MdT $N$ per un input $x$ è l'altezza del grafo della computazione
  * Quindi la lunghezza massima di un percorso dalla configurazione iniziale alle foglie
  * Se considerassimo il numero di nodi dell'albero sarebbe il tempo impiegato da una macchina deterministica $M$ per simulare $N$
  * Considerando come complessità l'altezza, stiamo dicendo che $N$ è in grado di seguire tutti i rami contemporaneamente, o che è così intelligente da sapere sempre quale ramo seguire
* Una macchina $N$ opera in tempo $f(n)$ se ha complessità di tempo *al massimo* $f(n)$ per ogni $x$ di lunghezza $n$
* Una macchina $N$ decide il linguaggio $L$ se
  * Per ogni $x\in L$ esiste un ramo della computazione che termina nello stato $yes$
  * Per ogni $x\notin L$ tutti i rami della computazione terminano nello stato $no$
* Se per decidere il linguaggio dovesse avere tutti $yes$ per accettare ed almeno un $no$ per rifiutare, avremmo la macchina che riconosce il linguaggio complementare
* Se per decidere il linguaggio volessimo tutti $yes$ per accettare e tutti $no$ per non accettare sarebbe un modello non ragionevole perché non potremmo sapere se la macchina è di questo tipo guardando solo la sintassi
  * Inoltre, la macchina sarebbe potente come una macchina deterministica perché devo guardare tutti i risultati in ogni caso


### P vs NP

$$
P=\bigcup_{k\in\N}TIME(n^k)
$$

L'insieme di tutti i linguaggi che possono essere riconosciuti da una k-MdT in tempo polinomiale. Li mettiamo tutti insieme perché per la tesi di Church-Turing *estesa* sappiamo che possiamo cambiare esponente cambiando modello di computazione.

$$
NP=\bigcup_{k\in\N}NTIME(n^k)
$$

Come prima, ma in tempo *non-deterministicamente polinomiale*. Dobbiamo definire $NTIME$.

$$
NTIME(f(n))=\{L:\exists_{N\text{ ND-MdT}}(N\text{ decide }L\text{ in tempo }f(n))\}
$$

Il problema P vs NP è la domanda "$P\stackrel{??}{=}NP$". è banale vedere che $P\subseteq NP$, finora nessuno è riuscito ne a dimostrare ne a confutare se $NP\subseteq P$.

Sappiamo qualcosa però: che le macchine deterministiche sono alla peggio esponenziali rispetto a quelle non deterministiche (potrebbero essere meglio però).

$$
NTIME(f(n))\subseteq\bigcup_{c\in\N}TIME(c^{f(n)})
$$

Possiamo dimostrarlo trovando un ma macchina $M$ per simulare una macchina $N$ in tempo $c^{f(n)}$.
Possiamo "facilmente" una macchina che simuli l'esecuzione di $N$ facendo una sorta di visita DFS del grafo di computazione. Nel caso peggiore la dimensione del grafo è $d^{f(n)}$ dove $d$ è il grado di non determinismo.\
Se ho un modello deterministico efficiente, la visita avverrà in tempo $O(d^{f(n)})$, altrimenti, per la tesi di Church-Turing estesa, avverrà comunque in tempo $O(d^{f(n)\cdot b})$ per un qualche $b$, quindi in tempo $c^{f(n)}$ per un qualche $c\geq d$.

### Complessità di spazio

* Supponiamo una ND-I/O-k-MdT, per un input $x$la complessità di spazio il massimo spazio usato da un ramo della computazione
* Definiamo $NSPACE(f(n))$ l'insieme di tutti i linguaggio che sono decisi in spazio $f(n)$ da una macchina non deterministica.

Alcune classi:
* $L=SPACE(\log~n),~NL=NSPACE(\log~n)$
  * $L\stackrel{??}{=}NL$ è un problema aperto
* $PSPACE=\bigcup\limits_{k\in\N}SPACE(n^k)$
* $NPSPACE=\bigcup\limits_{k\in\N}NSPACE(n^k)$
  * $SPACE=NPSPACE$ lo sappiamo, è facile

### Reachability problem

Dato un grafo diretto $G=(V,E)$, e dati $u,v\in V$. Decidi se $v$ raggiunge $u$ in $G$.
È un problema decisionale, quindi consideriamo il linguaggio $L$ di tutte le triple grafo-nodo-nodo tali che ...

$$
Reachability\in P
$$

$$
Reachability\in SPACE(??)\\
Reachability\in NSPACE(??)\\
$$

Possiamo risolverlo in tempo polinomiale con BFS o DFS. Questi algoritmi hanno complessità di spazio $O(n)$, perché devo memorizzare almeno i colori. Spazio lineare è tanto.\
Però, questa è una soluzione efficiente in tempo, se vogliamo ottimizzare lo spazio dobbiamo rinunciare al tempo.\
Scriviamo una macchina $N$ che tiene in memoria uno dei nodi, quello che vogliamo raggiungere, ed il numero di nodi attraversati. Ad ogni passo sceglie non deterministicamente un vicino del nodo e si sposta in quello. Se il nodo è quello finale, si ferma in $yes$ altrimenti se il counter supera $|V|$ si ferma in $no$.

## Relazioni tra le classi di complessità

$L\subseteq NL\stackrel{??}{\subseteq} P \subseteq NP$

Per definire una classe di complessità servono:
* Un modello computazionale (MdT)
* Una modalità di computazione (Det/NonDet)
* Una risorsa (Tempo/Spazio)
* Una funzione limite ($n$, $n^k$, $\log n$)

Che funzioni possiamo usare come limite? Ovviamente deve usare una funzione computabile, ma non è sufficiente.\
Vedremo che se usiamo la funzione $f$ sbagliata riusciamo a dimostrare che $TIME(f(n))=TIME(2^{f(n)})$ che non solo è bizzarro, ma fa collassare tutte le classi di complessità. (*GAP theorem*)

> ***Hierarchy Theory***:
> Se $f$ è una funzione di complessità *propria*, allora:
> $$TIME(f(n))\subsetneq TIME(f(n)^3)$$

Vogliamo definire una *funzione di complessità propria* in modo che se $f$ è propria, allora:
* È computabile
* $f(n)\in TIME(f(n))$ e $f(n)\in SPACE(f(n))$

**Definizione**: $f:\N\mapsto\N$ è propria se:
1. $f$ è non decrescente
2. $\exists M_f$ una I/O-k-TM tale che $\forall x~|x|=n$
   * $(s,\triangleright,x,\triangleright,\varepsilon,...,\triangleright,\varepsilon)\stackrel{M_f,t}{\rightarrow}(halt,x_1,x_2,\triangleright,\sqcup^{j_2},\triangleright,\sqcup^{j_3},...,\triangleright\sqcap^{f(|x|)},\sqcup)$
     * Dove $\sqcap^{f(|x|)}$ è la codifica unaria di $f(|x|)$ e $x_1,x_2=\triangleright x\sqcup$
   * E $t=O(n+f(|x|))$
   * E $\forall i~j_i=O(f(n))$
   * E e i valori $t$ e $j_i$ non dipendono dal valore di $x$ ma solo da $n$

È scomodo e tedioso da dimostrare, ma tutte le funzioni ragionevoli che ci vengono in mente sono proprie. Esempi:
* $n$, $n^k$, $\log n$
* $n^n$, $2^n$, $2^{n^k}$
* $n!$, $2^{2^{...^2}}$

Perché la vogliamo in unario? Perché facilita alcune dimostrazioni, ad esempio questa:

> **Definizione**: Una MdT $M$ si dice *precisa* se $\exists f,g$ tali che $\forall n\geq0~\forall x~|x|=n$, $M(x)$ termina dopo *esattamente* $f(n)$ passi usando spazio $g(n)$.

> ***Proprietà***: Se $L\in TIME(f(n))$ ed $f$ è propria.
> Allora esiste una macchina *precisa* $M$ che decide $L$ in tempo $O(f(n))$.\
> $M$ non sarà precisa in $f(n)$ ma in una funzione un po' più grande i $f$.
> 
> ***Dimostrazione***: Possiamo costruire una I/O-k-MdT $M$ che prima calcola $M_f$, e poi decide $L$ in tempo $O(f(n))$, ed in parallelo cancella una cifra di $f(n)$ che era stato calcolato prima. Se finisce prima di averlo cancellato tutto continua a cancellare.\
> 
> ***Esercizio***: Questa è la macchina del libro, non è veramente precisa, possiamo correggerla come esercizio.\
> ***Soluzione***: Bisogna sprecare anche lo spazio perché una macchina precisa lo è sia in tempo che in spazio.

## Complementi di classi non deterministiche

Sia $C$ una classe di complessità (quindi un set di linguaggi).\
$co-C=\{\overline L:L\in C\}$.\
Nota che $co-C\neq\overline C$

Per tutte le classi *deterministiche* vale $C=co-C$, perché il tempo che ci metto per verificare che una stringa *non appartiene* ad un linguaggio $L\in C$ è lo stesso che ci metto per verificare che *appartiene* ad $\overline L\in co-C$.

Per le classi *non deterministiche* non lo sappiamo. Non sappiamo se $NP\stackrel{??}{=}co-NP$. Per la definizione di decisione non deterministica, avevamo che la stringa $l$ apparteneva ad $L\in NC$ se esisteva una computazione $x$ non deterministica che terminava in $yes$ (indicata con $\varphi(x)$).\
Ma per sapere se $l$ appartiene a $\overline L\in co-NC$ serve verificare che $\lnot\exists x~\varphi(x)\equiv\forall x~\lnot\varphi(x)$.

## HIerarchy theorem

> ***Hierarchy Theorem (premessa)***:\
> Siano:
> $$H=\{M;x:M(x)\downarrow\} \text{ (halting problem)}\\H_f=\{M;x:M(x)=yes\text{ in al più }f(|x|)+5|x|+4\text{ passi}\}$$
> 
> Se $f$ è propria:
> * $H_f\in TIME(f(n)^3)$
> * $H_f\notin TIME(f(n))$
>
> Continua

***Dimostrazione 1***:
Sia la macchina universale $U_f$, che prende in input $\triangleright bin(M);bin(x)\sqcup$ e la esegue per al più $f(n)$ passi.
$f$ è una funzione propria, quindi anche $f'(n)=f(n)+5n+4$ è propria può essere calcolata in unario in $f(|x|)+5|x|+4$ passi.\
Possiamo calcolare prima $f'(n)$ su un nastro $f$, possiamo copiare $x$ dall'alfabeto di $M$ a quello di $U_f$ su un nastro $Input$ e poi cominciare a simulare $M(x)$ sugli altri nastri, mantenendo la configurazione attuale su un altro nastro $*$.\
Per simulare un singolo passo di $M$, la macchina $U_f$ richiede un numero costante di scansioni del nastro $Input$ e del nastro $*$, ad ogni passo decrementiamo il numero sul nastro $f$.\
Siccome $U_f$ simula solo $f'(n)$ passi di $M(x)$, la lunghezza di $*$ è sempre al più $f'(n)$. Quindi la simulazione di un passo ha sempre costo $O(k_M\cdot f(n))$\
Quindi in totale la simulazione costa qualcosa più di $f'(n)^2$ a cui bisogna aggiungere dei costi iniziali che dipendono da $M$ ed altro. Ma si può dimostrare che insieme sono inferiori a $k\cdot f(n)^3=O()$ (tenendoci larghi, si può dimostrare anche un limite più stringente).

***Dimostrazione 2***:
La dimostrazione di prima funzionava anche usando $f$ al posto di $f'$, questa no.\
È facile vedere che $H(f)\notin TIME(f(\lfloor\frac{n}2\rfloor))$, per contraddizione supponiamo che $\exists M_{H_f}$ che decide $H_f$ in al più $f(\lfloor\frac{n}2\rfloor))$ passi. Consideriamo la macchina $D$ tale che $D(M)=yes\iff M_{H_f}(M;M)=no$.\
Allora $D(M)=yes\iff M(M)=no\lor M(M)\uparrow\lor (M(M)=yes\text{ in più di }f'(n)\text{ passaggi})$.\
Per computare $D$ serve computare $M_{H_f}$, quindi serve $f(\lfloor\frac{2n+1}2\rfloor)$, che quando $f$ è propria equivale a $f'$.\
Se fosse $D(D)=no$ allora $M_{H_f}(D;D)=yes$ quindi $D;D\in H_f$ quindi dovremmo avere $D(D)=yes$. Se fosse $D(D)=yes$ allora $M_{H_f}(D;D)=no$, quindi $D;D\notin H_f$, che significa o che $D(D)=no$, o $D(D)\uparrow$, o $D(D)=yes$ ma in più di $f'(n)$ passaggi.

> ***Hierarchy theorem (enunciato)***:
> Se $f(n)\geq n$ ed $f$ è propria, allora:
> $$TIME(f(n))\subsetneq TIME(f(2n+1)^3)\\TIME(f(\left\lfloor\frac{n}2\right\rfloor))\subsetneq TIME(f(n)^3)$$

Questo permette di provare l'esistenza di diversi livelli di complessità.
Se il hierarchy theorem non fosse vero, tutte le classi di complessità collasserebbero in un'unica classe.

## Gap theorem

> ***Gap theorem***:\
> $\exists f$ ricorsiva, tale che $TIME(f(n))=TIME(2^{f(n)})$. Segue che $f$ non è propria, quindi non basta che una funzione sia ricorsiva perché sia propria.
> Dimostra l'esistenza di una funzione ricorsiva non propria.

***Dimostrazione***: Definiamo $f$ in modo che tutte le computazioni che terminano in meno di $2^{f(n)}$ terminano anche in meno di $f(n)$ passi. In altre parole, una $f$ per cui non c'è nessuna macchina che termina con un numero di passi compreso nell'intervallo $(f(n),2^{f(n)}]$\
Prendiamo un'enumerazione di MdT (anche quelle che non terminano) $M_0,M_1,...$. Definiamo la relazione $P(i,k)\iff\forall M_h$ con $h\leq i$, $\forall x$ con $|x|=i$ termina in al più $k$ passi, o termina in più di $2^k$ passi, o non termina affatto.\
$P$ è decidibile, servono molti controlli, ma è decidibile.\
Sia $N(i)$ il numero di possibili input di lunghezza $i$ per le macchine $M_0,...,M_i$. Quindi $\sum\limits^i_{h=0}|\Sigma_h|^i$.\
Per ogni input $x$ di lunghezza $i$, la macchina $M_h$ o non termina, o termina in $s_{x,h}$ passi, che cade in uno degli intervalli $(k_1=2i,k_2=2^{k_1}+1]$,...,$(k_j=2^{k_{j-1}}+1,k_{j+1}],...$.
Se consideriamo $N(i)+1$ intervalli, ce n'è almeno un intervallo $(k_e,2^{k_e}+1]$ dove non cade nessuna $s_{x,h}$.\
Possiamo scrivere la funzione $f(i)=k_e$ che trova questi intervalli vuoti. Questa funzione è computabile.
Per definizione, non c'è nessuna macchina che termina nell'intervallo $(f(n),2^{f(n)}+1]$

## Teoremi importanti generici

> Se $f$ è propria, allora:
> 1. $SPACE{f(n)}\subseteq NSPACE(f(n))$
> 2. $TIME{f(n)}\subseteq NTIME(f(n))$
> 3. $TIME{f(n)}\subseteq SPACE(f(n))$
> 4. $SPACE{f(n)}\subseteq TIME(c^{f(n)+\log(n)})$
> 5. $NTIME{f(n)}\subseteq SPACE(f(n))$
> 6. $NSPACE{f(n)}\subseteq TIME(c^{f(n)+\log(n)})$

***Dimostrazioni 1, 2***: Possiamo avere una macchina non deterministica che esegua la stessa computazione di quella deterministica.

***Dimostrazione 3***: Conseguenza di 5.

***Dimostrazione 4***: Conseguenza di 6.

***Dimostrazione 5***: In precedenza abbiamo dimostrato che se $L\in NTIME(f(n))$, allora $L\in TIME(c^{f(n)})$, e lo abbiamo dimostrato utilizzando una MdT che simulava la macchina non deterministica.
Questa macchina usava un nastro per il contenuto dei nastri della macchina originale (di dimensione al massimo $O(f(n))$), ed uno per memorizzare le scelte non deterministiche (sempre di dimensione al massimo $O(f(n))$).

***Dimostrazione 6***: Pensiamo di avere un grafo diretto di configurazioni della macchina non deterministica, dove gli archi indicano una possibile transizione. Il problema è diventato una reachability nel grafo (polinomiale sulla dimensione del grafo). Ogni nastro della macchina originale è lungo al massimo $f(n)$, tranne quello di input. Le configurazioni possibili sono $(|K|+2)*(n+2)*\prod\limits_{i=2}^{k-1}(|\Sigma|^{f(n)}\times|\Sigma|^{f(n)})=O(b^{f(n)+\log(n)})$ (abbiamo portato $n+2$ all'esponente).
Possiamo scrivere una macchina che risolva la reachability in tempo polinomiale sulla dimensione del grafo, quindi $O(c^{f(n)+\log(n)})$

> ***Corollario***: 
> $$L\subseteq NL\subseteq P\subseteq NP\subseteq PSPACE\subseteq NPSPACE\subseteq EXP\subseteq NEXP\subseteq...$$\
> $$P\neq EXP$$\
> $$L\neq PSPACE$$\
> $$PSPACE=NPSPACE$$

## Savich theorem

> ***Savich theorem***:
> $$Reachability\in SPACE((\log(n))^2)$$

***Dimostrazione***: $Path(x,y,i)$ significa $x$ arriva ad $y$ in al più $2^i$ passi.

$$
Path(x,y,1)\iff x=y\lor x\rightarrow y\\
Path(x,y,i+1)\iff\exists z~Path(x,z,i)\land Path(z,y,i)
$$

Definiamo una macchina ricorsiva che verifica $Path(x,y,\log|V|)$, ad ogni passo ricorsivo cerca un nodo $z$ intermedio. Ad un certo punto arriva un caso base tipo $Path(a,b,1)$.
Serve un nastro di tuple con $O(\log|V|)$ tuple di lunghezza $O(\log|V|)$, quindi il nastro è di dimensione $O((\log|V|)^2)$.
Questa dimostrazione funziona solo se non ho bisogno di generare il grafo dall'input.

\\TODO