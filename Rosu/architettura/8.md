# Architetture per il calcolo parallelo

Anche se non è possibile realizzare un calcolatore con una sola CPU e un ciclo di 0.001 ns, sarebbe sicuramente possibile costruirne uno con 1000 CPU, ciascuna con un ciclo di clock di 1ns. Sebbene il secondo progetto si avvalga di CPU più lente in teoria la sua capacità totale di calcolo è la stessa del primo.

L'obiettivo è quello di migliorare le prestazioni in ambiti in cui:

* un algoritmo richiede più potenza di calcolo possibile
* un programma tende a sfruttare tutte le risorse disponibili
* l'aumento delle prestazioni non può più pesare sull'integrazione nel chip

Inoltre:

* un'architettura parallela può aumentare la tolleranza ai guasti attraverso la **ridondanza dei componenti**
* abbiamo un aumento proporzionale delle prestazioni aggiungendo nuove unità di calcolo (**scalabilità**)

Il parallelismo può essere introdotto a vari livelli

* a quello più basso possiamo ottenere un incremento prestazionale per un fattore di 10 rispetto ad un progetto puramente sequenziale
  * può essere incorporato nel chip della CPU attraverso un progetto superscalare a pipeline con molteplici utili funzionalità
  * può essere introdotto con l'adozione di istruzioni basate su parole molto lunghe e dotate di parallelismo implicito
  * può essere equipaggiata la CPU con caratteristiche speciali che le consentano di gestire il controllo di più thread alla volta
  * possono essere integrate più CPU nello stesso chip
* al livello successivo è possibile ottenere un incremento prestazionale per un fattore che va da 5 a 10, ma **solo nel caso di applicazioni specializzate**
  * è possibile aggiungere al sistema delle schede dotate di CPU che arricchiscano le sue capacità di calcolo (CPU plug-in che svolgono funzioni specializzate, come l'elaborazione multimediale o la crittografia)
* L'unico modo per ottenere un incremento prestazionale nell'ordine delle centinaia, delle migliaia o dei milioni è di replicare il numero delle CPU facendole cooperare in modo efficiente (idea base dei multiprocessori e dei multicomputer)
  * Oggi su Internet è possibile strutturare intere organizzazioni di computer come reti di calcolo con connessioni lasche (le **griglie**)

Due CPU o elementi di calcolo si possono dire legati:

* **strettamente** se svolgono calcoli in modo molto interrativo e la cui connessione ha un'elevata larghezza di banda e un ritardo trascurabile
* **debolmente** se si trovano molto distanti, hanno una banda ridotta, un ritardo elevato e svolgono i loro calcoli in modo poco interattivo

## Parallelismo nel chip

Un modo per incrementare la produttività di un chip è di fargli svolgere più compiti alla volta, in altre parole, sfruttare il parallelismo:

* parallelismo a livello delle istruzioni
* multithreading
* coabitazione di più CPU sullo stesso chip

### Parallelismo a livello di istruzioni

Un modo per ottenere il parallelismo è di emettere più istruzioni per ciclo di clock. Ci sono due tipi di CPU a emissione multipla, i processori:

* **superscalari** c'è un momento lungo la pipeline in cui l'istruzione è pronta per essere eseguita. Queste CPU sono in grado di emettere veso le unità di esecuzione più istruzioni in un solo ciclo, che dipende dal progetto del processore e dalle circostanze contingenti (il numero massimo in generale va da 2 a 6 in base all'hardware). In ogni caso un'istruzione non verrà emessa se attende un calcolo che non è stato ancora completato o se necessita di un'unita funzionale non disponibile.

* **Very Long Instruction Word** queste macchine avevano parole molto lunghe per contenere istruzioni che usavano diverse unità funzionali
  * nel caso in cui la macchina disponga di 5 unità funzionali (due operazioni intere, una in virgola mobile, un caricamento e una memorizzazione) un'istruzione VLIW conterrebbe 5 codici operativi e 5 coppie di operandi: un codice e una coppia di operandi per ogni unità funzionale
  * il progetto si rivelò troppo rigido perché non tutte le istruzioni riuscivano a sfruttare tutte le unità funzionali, il che conduceva all'utilizzo di molte inutili0 NO-OP (no operation)
  * per questo motivo le macchine moderne di questo tipo dispongono di una modalità di costruzione dei pacchetti (bundle) d'istruzioni, conclusi per esempio dal bit di fine pacchetto. Il processore è in grado di effettuare il fetch e l'emissione di un intero pacchetto per volta, spetta al compilatore preparare pacchetti d'istruzioni compatibili
  * questa tecnica sposta dall'esecuzione alla compilazione il difficile compito di stabilire quali istruzioni possono essere avviate alla esecuzione contemporanea
    * consente di avere un hardware più semplice e veloce
    * il compilatore può far durare l'ottimizzazione per tutto il tempo necessario, permettte di assemblare pacchetti d'istruzioni migliori di quanto potrebbe fare l'hardware durante l'esecuzione
    * questo progetto comporta un cambio radicale nell'architettura delle CPU difficile da accettare (dimostrato dalla scarsa accoglienza suscitata dall'Italium)

#### CPU VLIW TriMedia

Processore progettato da Philips